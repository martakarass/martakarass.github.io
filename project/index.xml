<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Home</title>
    <link>/project/</link>
      <atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 22 Apr 2019 11:54:53 -0400</lastBuildDate>
    <image>
      <url>/images/icon_hufdd866d90d76849587aac6fbf27da1ac_464_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>/project/</link>
    </image>
    
    <item>
      <title>&#39;adeptdata&#39; R package: Raw Accelerometry Data Sets and Their Derivatives</title>
      <link>/project/project_adeptdata/</link>
      <pubDate>Mon, 22 Apr 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_adeptdata/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;adeptdata&lt;/code&gt; was created to host raw accelerometry data sets and their derivatives. Some of them are used in the corresponding &lt;code&gt;adept&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Package CRAN index is located &lt;a href=&#34;https://cran.r-project.org/web/packages/adeptdata/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Package GitHub repo is located &lt;a href=&#34;https://github.com/martakarass/adeptdata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;Install from CRAN.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;adeptdata&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;data-objects&#34;&gt;Data objects&lt;/h1&gt;
&lt;h2 id=&#34;outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_walking_IU&lt;/code&gt; is a sample of raw accelerometry data collected during outdoor continuous walking from 32 healthy participants between 23 and 52 years of age. Data were collected at frequency 100 Hz simultaneously with four wearable accelerometers located at left wrist, left hip and both ankles. See &lt;code&gt;?acc_walking_IU&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(adeptdata)
library(dplyr)
library(ggplot2)
library(reshape2)
library(lubridate)

acc_walking_IU %&amp;gt;%
  filter(time_s &amp;lt; 6, subj_id == acc_walking_IU$subj_id[1]) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_wrist&amp;quot;, &amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;, &amp;quot;right_ankle&amp;quot;),
    labels = c(&amp;quot;Left wrist&amp;quot;, &amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;, &amp;quot;Right ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;subj_id&amp;quot;, &amp;quot;loc_id&amp;quot;, &amp;quot;time_s&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = time_s, y = value, color = variable)) + 
  geom_line() + 
  facet_wrap(~ loc_id, ncol = 2) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Exercise time [s]&amp;quot;, 
       y = &amp;quot;Amplitude [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data of walking (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;plot_acc_walking_IU.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_running&lt;/code&gt; is a sample raw accelerometry data collected during 25 minutes of an outdoor run. Data were collected at frequency 100 Hz with two ActiGraph GT9X Link sensors located at left hip and left ankle. See &lt;code&gt;?acc_running&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t1 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:07:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t2 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:20:30&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t3 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:22:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 

acc_running %&amp;gt;%
  filter((date_time &amp;gt;= t1 &amp;amp; date_time &amp;lt; t1 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t2 &amp;amp; date_time &amp;lt; t2 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t3 &amp;amp; date_time &amp;lt; t3 + as.period(4, &amp;quot;seconds&amp;quot;)) ) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;),
    labels = c(&amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;date_time&amp;quot;, &amp;quot;loc_id&amp;quot;)) %&amp;gt;%
  mutate(date_time_floor = paste0(
    &amp;quot;Minute start: &amp;quot;, floor_date(date_time, unit = &amp;quot;minutes&amp;quot;))) %&amp;gt;%
  ggplot(aes(x = date_time, y = value, color = variable)) + 
  geom_line(size = 0.5) + 
  facet_grid(loc_id ~ date_time_floor, scales = &amp;quot;free_x&amp;quot;) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Acceleration [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;acc_running.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;stride_template&lt;/code&gt; is a list containing walking stride pattern templates derived from accelerometry data collected at four body locations: left wrist, left hip, left ankle, and right ankle. See &lt;code&gt;?stride_template&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data.frame(
  x = rep(seq(0, 1, length.out = 200), 2),
  y = c(stride_template$left_ankle[[2]][1, ],
        stride_template$left_ankle[[2]][2, ]),
  group = c(rep(1, 200), rep(2, 200))) %&amp;gt;%
  ggplot(aes(x = x, y = y, group = group)) + 
  geom_line() +
  facet_grid(group ~ .) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Vector magnitude [g]&amp;quot;, 
       title = &amp;quot;Walking stride templates (left ankle)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;stride_template.jpeg&#34; width=&#34;50%&#34;&gt;
</description>
    </item>
    
    <item>
      <title>&#39;runstats&#39; R package: Fast Computation of Running Statistics for Time Series</title>
      <link>/project/project_runstats/</link>
      <pubDate>Fri, 15 Mar 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_runstats/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;runstats&lt;/code&gt; provides methods for fast computation of running sample statistics for time series. The methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT). Implemented running statistics include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mean,&lt;/li&gt;
&lt;li&gt;standard deviation,&lt;/li&gt;
&lt;li&gt;variance,&lt;/li&gt;
&lt;li&gt;covariance,&lt;/li&gt;
&lt;li&gt;correlation,&lt;/li&gt;
&lt;li&gt;euclidean distance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session info&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;website&#34;&gt;Website&lt;/h1&gt;
&lt;p&gt;Package website is located &lt;a href=&#34;https://martakarass.github.io/runstats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;runstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(runstats)

## Example: running correlation
x0 &amp;lt;- sin(seq(0, 2 * pi * 5, length.out = 1000))
x  &amp;lt;- x0 + rnorm(1000, sd = 0.1)
pattern &amp;lt;- x0[1:100]
out1 &amp;lt;- RunningCor(x, pattern)
out2 &amp;lt;- RunningCor(x, pattern, circular = TRUE)

## Example: running mean
x &amp;lt;- cumsum(rnorm(1000))
out1 &amp;lt;- RunningMean(x, W = 100)
out2 &amp;lt;- RunningMean(x, W = 100, circular = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;running-statistics&#34;&gt;Running statistics&lt;/h1&gt;
&lt;p&gt;To better explain the details of running statistics, package&amp;rsquo;s function &lt;code&gt;runstats.demo(func.name)&lt;/code&gt; allows to visualize how the output of each running statistics method is generated. To run the demo, use &lt;code&gt;func.name&lt;/code&gt; being one of the methods&#39; names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningMean&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningSd&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningVar&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCov&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCor&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningL2Norm&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running correlation method  
runstats.demo(&amp;quot;RunningCor&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_1.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running mean method 
runstats.demo(&amp;quot;RunningMean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_2.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;performance&#34;&gt;Performance&lt;/h1&gt;
&lt;p&gt;We use &lt;code&gt;rbenchmark&lt;/code&gt; to measure elapsed time of &lt;code&gt;RunningCov&lt;/code&gt; execution, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter pattern &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rbenchmark)
library(ggplot2)

set.seed (20190315)
x.N.seq &amp;lt;- 10^(3:7)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))
y &amp;lt;- runif(100)

## Benchmark execution time of RunningCov 
out.df &amp;lt;- data.frame()
for (x.tmp in x.list){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df.tmp$pattern_length &amp;lt;- length(y)
  out.df &amp;lt;- rbind(out.df, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;knitr::kable(out.df)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;test&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;replications&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;elapsed&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;relative&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;user.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;sys.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;x_length&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;pattern_length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.003&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.023&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.019&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.183&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.148&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.035&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.700&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.592&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.107&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;19.852&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;17.185&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2.576&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/h2&gt;
&lt;p&gt;To compare &lt;code&gt;runstats&lt;/code&gt; performance with &amp;ldquo;conventional&amp;rdquo; loop-based way of computing running covariance in &lt;code&gt;R&lt;/code&gt;, we use &lt;code&gt;rbenchmark&lt;/code&gt; package to measure elapsed time of &lt;code&gt;runstats::RunningCov&lt;/code&gt; and running covariance implemented with &lt;code&gt;sapply&lt;/code&gt; loop, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter time-series &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Conventional approach 
RunningCov.sapply &amp;lt;- function(x, y){
  l_x &amp;lt;- length(x)
  l_y &amp;lt;- length(y)
  sapply(1:(l_x - l_y + 1), function(i){
    cov(x[i:(i+l_y-1)], y)
  })
}

out.df2 &amp;lt;- data.frame()
for (x.tmp in x.list[c(1:4)]){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;conventional&amp;quot; = RunningCov.sapply(x.tmp, y),
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df2 &amp;lt;- rbind(out.df2, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plt1 &amp;lt;- 
  ggplot(out.df2, aes(x = x_length, y = elapsed, color = test)) + 
  geom_line() + geom_point(size = 3) + scale_x_log10() + 
  theme_minimal(base_size = 14) + 
  labs(x = &amp;quot;Vector length of x&amp;quot;,
       y = &amp;quot;Elapsed [s]&amp;quot;, color = &amp;quot;Method&amp;quot;, 
       title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;, 
       subtitle = &amp;quot;Vector length of y = 100&amp;quot;) + 
  theme(legend.position = &amp;quot;bottom&amp;quot;)
plt2 &amp;lt;- 
  plt1 + 
  scale_y_log10() + 
  labs(y = &amp;quot;Log of elapsed [s]&amp;quot;, title = &amp;quot;&amp;quot;)

cowplot::plot_grid(plt1, plt2, nrow = 1, labels = c(&#39;A&#39;, &#39;B&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_conventional_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dvmisc&lt;/code&gt; package (&lt;a href=&#34;https://github.com/vandomed/dvmisc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/dvmisc/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;) is a package for &lt;em&gt;Convenience Functions, Moving Window Statistics, and Graphics&lt;/em&gt;, and includes functions for calculating moving-window statistics efficiently via c++, written by &lt;a href=&#34;https://vandomed.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dane Van Domelen&lt;/a&gt;. Here, we compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; performance with c++ implementation from &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt;. Dane contributed the code in its large part.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# devtools::install_github(&amp;quot;vandomed/dvmisc&amp;quot;)
library(dvmisc)

set.seed(20100315)
x.N.seq &amp;lt;- 10^(3:6)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))

get.out.df &amp;lt;- function(y){
  out.df &amp;lt;- data.frame()
  for (x.tmp in x.list){
    if (length(x.tmp) &amp;lt; length(y)){
      out.df.tmp &amp;lt;- data.frame(
        test = NA,  replications = NA, elapsed = NA, relative = NA,
        user.self = NA, sys.self = NA)
    } else {
      out.df.tmp &amp;lt;- benchmark(
        &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
        &amp;quot;dvmisc&amp;quot; = dvmisc::sliding_cov(y, x.tmp), 
        replications = 10,
        columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                    &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
    }
    out.df.tmp$x_length &amp;lt;- length(x.tmp)
    out.df &amp;lt;- rbind(out.df, out.df.tmp)
  }
  return(out.df)
}

out.df_y10    &amp;lt;- get.out.df(runif(10^1))
out.df_y100   &amp;lt;- get.out.df(runif(10^2))
out.df_y1000  &amp;lt;- get.out.df(runif(10^3))
out.df_y10000 &amp;lt;- get.out.df(runif(10^4))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get.plt &amp;lt;- function(data, subtitle){
  ggplot(data, aes(x = x_length, y = elapsed, color = test)) + 
    geom_line() + geom_point(size = 3) + scale_x_log10() + 
    theme_minimal(base_size = 14) +  scale_y_log10() + 
    labs(x = &amp;quot;Vector length of x&amp;quot;,
         y = &amp;quot;Log of elapsed [s]&amp;quot;, 
         color = &amp;quot;Method&amp;quot;, 
         subtitle = subtitle) + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)
}

plt1 &amp;lt;- get.plt(out.df_y10, &amp;quot;Vector length of y = 10&amp;quot;) + 
  labs(title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;)
plt2 &amp;lt;- get.plt(out.df_y100,   &amp;quot;Vector length of y = 100&amp;quot;)
plt3 &amp;lt;- get.plt(out.df_y1000,  &amp;quot;Vector length of y = 1,000&amp;quot;)
plt4 &amp;lt;- get.plt(out.df_y10000, &amp;quot;Vector length of y = 1,0000&amp;quot;)

cowplot::plot_grid(plt1, plt2, plt3, plt4, nrow = 2, labels = c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_dvmisc_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;session-info&#34;&gt;Session info&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessioninfo::session_info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    ## ─ Session info ───────────────────────────────────────────────────────────────
    ##  setting  value                       
    ##  version  R version 3.5.2 (2018-12-20)
    ##  os       macOS Mojave 10.14.2        
    ##  system   x86_64, darwin15.6.0        
    ##  ui       X11                         
    ##  language (EN)                        
    ##  collate  en_US.UTF-8                 
    ##  ctype    en_US.UTF-8                 
    ##  tz       America/New_York            
    ##  date     2019-11-14                  
    ## 
    ## ─ Packages ───────────────────────────────────────────────────────────────────
    ##  package     * version date       lib source        
    ##  assertthat    0.2.1   2019-03-21 [1] CRAN (R 3.5.2)
    ##  cli           1.1.0   2019-03-19 [1] CRAN (R 3.5.2)
    ##  colorspace    1.4-1   2019-03-18 [1] CRAN (R 3.5.2)
    ##  crayon        1.3.4   2017-09-16 [1] CRAN (R 3.5.0)
    ##  digest        0.6.22  2019-10-21 [1] CRAN (R 3.5.2)
    ##  dplyr         0.8.3   2019-07-04 [1] CRAN (R 3.5.2)
    ##  evaluate      0.14    2019-05-28 [1] CRAN (R 3.5.2)
    ##  fftwtools     0.9-8   2017-03-25 [1] CRAN (R 3.5.0)
    ##  ggplot2     * 3.2.1   2019-08-10 [1] CRAN (R 3.5.2)
    ##  glue          1.3.1   2019-03-12 [1] CRAN (R 3.5.2)
    ##  gtable        0.3.0   2019-03-25 [1] CRAN (R 3.5.2)
    ##  htmltools     0.3.6   2017-04-28 [1] CRAN (R 3.5.0)
    ##  knitr         1.26    2019-11-12 [1] CRAN (R 3.5.2)
    ##  lazyeval      0.2.2   2019-03-15 [1] CRAN (R 3.5.2)
    ##  magrittr      1.5     2014-11-22 [1] CRAN (R 3.5.0)
    ##  munsell       0.5.0   2018-06-12 [1] CRAN (R 3.5.0)
    ##  pillar        1.4.2   2019-06-29 [1] CRAN (R 3.5.2)
    ##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 3.5.2)
    ##  purrr         0.3.3   2019-10-18 [1] CRAN (R 3.5.2)
    ##  R6            2.4.1   2019-11-12 [1] CRAN (R 3.5.2)
    ##  rbenchmark  * 1.0.0   2012-08-30 [1] CRAN (R 3.5.0)
    ##  Rcpp          1.0.3   2019-11-08 [1] CRAN (R 3.5.2)
    ##  rlang         0.4.1   2019-10-24 [1] CRAN (R 3.5.2)
    ##  rmarkdown     1.15    2019-08-21 [1] CRAN (R 3.5.2)
    ##  rstudioapi    0.10    2019-03-19 [1] CRAN (R 3.5.2)
    ##  runstats    * 1.1.0   2019-11-14 [1] CRAN (R 3.5.2)
    ##  scales        1.0.0   2018-08-09 [1] CRAN (R 3.5.0)
    ##  sessioninfo   1.1.1   2018-11-05 [1] CRAN (R 3.5.0)
    ##  stringi       1.4.3   2019-03-12 [1] CRAN (R 3.5.2)
    ##  stringr       1.4.0   2019-02-10 [1] CRAN (R 3.5.2)
    ##  tibble        2.1.3   2019-06-06 [1] CRAN (R 3.5.2)
    ##  tidyselect    0.2.5   2018-10-11 [1] CRAN (R 3.5.0)
    ##  withr         2.1.2   2018-03-15 [1] CRAN (R 3.5.0)
    ##  xfun          0.11    2019-11-12 [1] CRAN (R 3.5.2)
    ##  yaml          2.2.0   2018-07-25 [1] CRAN (R 3.5.0)
    ## 
    ## [1] /Library/Frameworks/R.framework/Versions/3.5/Resources/library
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Brain connectivity-informed regularization methods for regression</title>
      <link>/project/project_mdpeer/</link>
      <pubDate>Wed, 06 Dec 2017 11:54:53 -0400</pubDate>
      <guid>/project/project_mdpeer/</guid>
      <description>&lt;p&gt;We proposed a method to estimate association between the brain structure features and a scalar outcome in a regression model &amp;ndash; while utilizing additional information about structural connectivity between the brain regions.&lt;/p&gt;
&lt;p&gt;Specifically, we propose a novel regularization method that defines a regularization penalty term based on the structural connectivity-derived Laplacian matrix.&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to quantify the association between alcohol abuse phenotypes (outcome) and cortical thickness of the brain (covariates) in a study sample of young social-to-heavy drinking males. The data included measurements of average cortical thickness estimated for 68 brain regions.&lt;/p&gt;
&lt;p&gt;The excellent image (see images credit &lt;a href=&#34;#custom&#34;&gt;below&lt;/a&gt;) visualizes process of obtaining cortical thickness measurements from structural MRI images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;MRI_sequence.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;Commonly shared issues in such settings are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;high dimensionality of the data - we typically parcel the brain into tens, or hundreds of units from which we take measurements, and each unit may then correspond to a covariate in the data set,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;correlation of the covariates - measurements from spatially neighbouring or otherwise connected brain regions are likely to be correlated,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;small sample size - brain imaging studies often recruit a few tens of participants only.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose penalized regression method riPEER to estimate a linear model: $$y =  Zb + X\beta + \varepsilon$$ where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y$ - response (&lt;em&gt;here: alcohol abuse phenotypes&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$Z$ - input data matrix (&lt;em&gt;here: cortical thickness measurements&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$X$ - input data matrix (&lt;em&gt;here: demographics data&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\beta$ - regression coefficients, not penalized in estimation process&lt;/li&gt;
&lt;li&gt;$b$ - regression coefficients, penalized in estimation process and for whom there is a prior graph of similarity / graph of connections. available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The riPEER estimation method uses a penalty being a linear combination of a graph-based and ridge penalty terms:
$$
\hat{\beta}, \hat{b}
= \underset{\beta,b}{\text{arg min}} \left[ (y - X\beta - Zb)^T(y - X\beta - Zb)  + \lambda_Qb^TQb +  \lambda_Rb^Tb  \right ]
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Q$ - a graph-originated penalty matrix; typically: a graph Laplacian matrix (&lt;em&gt;here: a graph Laplacian derived from structural connectivity of brain regions&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\lambda_Q$ - regularization parameter for a graph-based penalty term,&lt;/li&gt;
&lt;li&gt;$\lambda_R$ - regularization parameter for ridge penalty term.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;ripeer-penalty-term&#34;&gt;riPEER penalty term&lt;/h5&gt;
&lt;p&gt;In the riPEER penalty term  $(\lambda_Qb^TQb +  \lambda_Rb^Tb)$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A graph-originated penalty matrix $Q$ allows imposing similarity between coefficients of variables which are &lt;em&gt;connected&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A ridge penalty term, $\lambda_Rb^Tb$, even with very small $\lambda_R$, eliminates computational issues arising from singularity of $Q$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regularization parameters $\lambda_R$, $\lambda_Q$ are estimated automatically as ML estimators of equivalent Linear Mixed Models optimization problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We published the proposed riPEER method in work &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6583926/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brain connectivity-informed regularization methods for regression&lt;/a&gt; (Karas, M., Brzyski, D., Dzemidzic, M., Goni, J., Kareken, D.A., Randolph, T., Harezlak (2017)). &lt;/br&gt; &lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The riPEER extension to generalized linear regression, addressing both theoretical and computational issues, is available in preprint &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/322420v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connectivity-informed adaptive regularization for generalized outcomes&lt;/a&gt; (Brzyski, D., Karas, M., Ances, B., Dzemidzic, M., Goni, J., Randolph, T.W., Harezlak, J. (2018)).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed riPEER estimation method in R package mdpeer (&lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The package provides functions for graph-constrained regression methods in which regularization parameters are selected automatically via estimation of equivalent Linear Mixed Model formulation.&lt;/p&gt;
&lt;p&gt;The R package is accompanied by &lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/vignettes/Intro_and_usage_examples.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intro and usage examples&lt;/a&gt; vignette.&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top left component. Cortical thickness. Resources of Neurorecovery Laboratory at MGH/MIT/HMS Athinoula A. Martinos Center for Biomedical Imaging. Accessed at: &lt;a href=&#34;https://www.nmr.mgh.harvard.edu/neurorecovery/technology.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top middle component. Diffusion MRI Tractography in the brain white matter. Xavier Gigandet et. al. - Gigandet X, Hagmann P, Kurant M, Cammoun L, Meuli R, et al. (2008) Estimating the Confidence Level of White Matter Connections Obtained with MRI Tractography. PLoS ONE 3(12): e4006. doi:10.1371/journal.pone.0004006. Accessed at: &lt;a href=&#34;https://en.wikipedia.org/wiki/Connectome#/media/File:White_Matter_Connections_Obtained_with_MRI_Tractography.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top right component. Databases of Statistical Information. Resources of Berkeley Advanced Media Institute
Graduate School of Journalism. Accessed at: &lt;a href=&#34;https://multimedia.journalism.berkeley.edu/tutorials/databases-of-statistical-information/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
