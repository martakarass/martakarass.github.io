<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Home</title>
    <link>/project/</link>
      <atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Sep 2021 11:54:53 -0400</lastBuildDate>
    <image>
      <url>/images/icon_hufdd866d90d76849587aac6fbf27da1ac_464_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>/project/</link>
    </image>
    
    <item>
      <title>Upstrap for estimating power and sample size in complex models</title>
      <link>/project/project_upstrap/</link>
      <pubDate>Wed, 01 Sep 2021 11:54:53 -0400</pubDate>
      <guid>/project/project_upstrap/</guid>
      <description>&lt;p&gt;Power and sample size calculation are major components of statistical analyses. The upstrap resampling method was proposed as a general solution to this problem.&lt;/p&gt;
&lt;p&gt;We evaluate power estimation properties of the upstrap and provide a series of &amp;ldquo;read, adapt and use&amp;rdquo; R code examples for power estimation in simple and complex settings (&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bioRxiv preprint&lt;/a&gt;).&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#code-example-testing-for-significance-of-lm-coefficient&#34;&gt;Code example: testing for significance of LM coefficient&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#contributions&#34;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;We consider the following problem: given an observed data sample $\mathbf{x}$ of sample size $N$, given specific null and alternative hypothesis, and a test statistic, assuming significance level $\alpha$, estimate sample size $M$ required to achieve power $1 -\beta$ (i.e., to achieve probability $1 -\beta$ of rejecting the null hypothesis when the null is true).&lt;/p&gt;
&lt;p&gt;Here, we consider the tasks to estimate the power to detect:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;an effect size observed in the data;&lt;/li&gt;
&lt;li&gt;an effect size chosen by a researcher.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We aim to ddress complex settings, including testing significance of model coefficients in: LM, GLM, LMM, GLMM, GEE, and others.&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;For multilevel data settings, the existing approaches tend to fall into two categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First are theoretical results for estimating power in specific multilevel data setups; these often use assumptions about the intra-class correlation coefficient, and/or assume a particular study design (e.g., that
the data are balanced). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Another class is based on simulations. Such may require specifying a population model for the data, simulating data from the assumed model, and estimating the power via Monte Carlo simulations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The former arguably lacks flexibility; in addition, finding and then determining applicability of a theoretical result may be difficult. The latter is flexible but involves potentially complex programming task.&lt;/p&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;h4 id=&#34;upstrap&#34;&gt;Upstrap&lt;/h4&gt;
&lt;p&gt;The upstrap resampling method (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7868048/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crainiceanu, C.M., Crainiceanu, A. (2020)&lt;/a&gt;) was proposed as a general
solution to this problem.&lt;/p&gt;
&lt;p&gt;Upstrap starts with a sample (observed data) and resamples with replacement either fewer or more samples than in the original data set. The below example shows difference between bootstrap and upstrap resample.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# simulate data 
x &amp;lt;- rnorm(n = 10)

# bootstrap resample
x_b &amp;lt;- sample(x, size = 10, replace = TRUE)

# upstrap resample (case: more samples than in original x) 
x_u &amp;lt;- sample(x, size = 20, replace = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;upstrap-for-estimating-power&#34;&gt;Upstrap for estimating power&lt;/h4&gt;
&lt;p&gt;Given observed data sample $\mathbf{x}$, to estimate power for a target sample size, we propose:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Generate $B$ resamples of target sample size by sampling with replacement from $\mathbf{x}$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perform  hypothesis test on each resample.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Estimate power as the proportion of $B$ resamples where the null hypothesis was rejected.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above procedure estimates power corresponding to the effect size &lt;em&gt;observed&lt;/em&gt; in the sample $\mathbf{x}$. For example, for one-sample t-test, the above procedure estimates:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;power.t.test(delta = mean(x), sd = sd(x), ...)$power
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;upstrap-for-estimating-power-specific-effect-size&#34;&gt;Upstrap for estimating power: specific effect size&lt;/h4&gt;
&lt;p&gt;In practice, one is often is interested in estimating power for a &lt;em&gt;specific&lt;/em&gt; effect size. For example, for one-sample t-test, a specific effect size could be set to 0.3:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;power.t.test(delta = 0.3, sd = sd(x), ...)$power
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To address such cases, we propose to update  response variable values in the observed sample $\mathbf{x}$ to ensure the effect size in this updated data is our target effect size. Details are provided in the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;code-example-testing-for-significance-of-lm-coefficient&#34;&gt;Code example: testing for significance of LM coefficient&lt;/h3&gt;
&lt;p&gt;Below, we demonstrate the upstrap power estimation method for testing for significance of LM coefficient. In the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint&lt;/a&gt;, we provide more R code examples, including testing for significance of coefficient in LM, GLM, LMM, GLMM.&lt;/p&gt;
&lt;p&gt;We define simulation parameters and simulate a sample of size $N = 50$.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see setup definition and R code.)
&lt;/summary&gt;
&lt;h4 id=&#34;setup&#34;&gt;Setup&lt;/h4&gt;
&lt;p&gt;Consider a random sample with $N = 50$ independent observations (e.g., 50 subjects, 1 observation per subject). Assume a continuous response variable $Y$ and two covariates: dichotomous $X_1$, continuous $X_2$. We are interested in estimating power of test for significance of the coefficient $\beta_{1}$ in linear model $Y_{i}=\beta_{0}+\beta_{1} X_{1 i}+\beta_{2} X_{2 i}+\varepsilon_{i}$, where $i=1, \ldots, N$ and $\varepsilon_{i} \sim_{\text {iid }} N\left(0, \sigma^{2}\right)$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# simulation parameters
N &amp;lt;- 50
coef_x0 &amp;lt;- 0
coef_x1 &amp;lt;- 0.2
coef_x2 &amp;lt;- 0.1
sigma2  &amp;lt;- 1

# simulate sample
set.seed(1)
subjid_i &amp;lt;- 1 : N # subject ID unique in data set
x1_i  &amp;lt;- rbinom(n = N, size = 1, prob = 0.5)
x2_i  &amp;lt;- rbinom(n = N, size = 1, prob = 0.5)
eps_i &amp;lt;- rnorm(N, sd = sqrt(sigma2))
y_i   &amp;lt;- coef_x0 + (coef_x1 * x1_i) + (coef_x2 * x2_i)  + eps_i
dat   &amp;lt;- data.frame(y = y_i, x1 = x1_i, x2 = x2_i, subjid = subjid_i)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(dat)
# &#39;data.frame&#39;:	50 obs. of  4 variables:
#  $ y     : num  0.398 -0.512 0.541 -0.929 1.433 ...
#  $ x1    : int  0 0 1 1 0 1 1 1 1 0 ...
#  $ x2    : int  0 1 0 0 0 0 0 1 1 0 ...
#  $ subjid: int  1 2 3 4 5 6 7 8 9 10 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get the observed effect size.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit &amp;lt;- lm(y ~ x1 + x2, data = dat)
coef(fit)[&amp;quot;x1&amp;quot;]
# 0.5585879 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We estimate the test power via the upstrap.&lt;/p&gt;
&lt;h4 id=&#34;case-target-sample-size-m--n--50-target-effect-size-as-observed-in-the-sample&#34;&gt;Case: target sample size M = N = 50, target effect size as observed in the sample&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# number of upstrap resamples
B_boot &amp;lt;- 1000
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- rep(NA, B_boot)
for (rr in 1 : B_boot){
  dat_rr_idx &amp;lt;- sample(1 : nrow(dat), replace = TRUE)
  dat_rr &amp;lt;- dat[dat_rr_idx, ]
  fit_rr &amp;lt;- lm(y ~ x1 + x2, data = dat_rr)
  pval_rr &amp;lt;- summary(fit_rr)$coef[&amp;quot;x1&amp;quot;, 4]
  out[rr] &amp;lt;- (pval_rr &amp;lt; 0.05)
}
mean(out)
# [1] 0.493
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;case-target-sample-size-m--100-target-effect-size-as-observed-in-the-sample&#34;&gt;Case: target sample size M = 100, target effect size as observed in the sample&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- rep(NA, B_boot)
for (rr in 1 : B_boot){
  dat_rr_idx &amp;lt;- sample(1 : nrow(dat), size = 100, replace = TRUE)
  dat_rr &amp;lt;- dat[dat_rr_idx, ]
  fit_rr &amp;lt;- lm(y ~ x1 + x2, data = dat_rr)
  pval_rr &amp;lt;- summary(fit_rr)$coef[&amp;quot;x1&amp;quot;, 4]
  out[rr] &amp;lt;- (pval_rr &amp;lt; 0.05)
}
mean(out)
# [1] 0.773
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;case-target-sample-size-m--100-target-effect-size-set-to-08&#34;&gt;Case: target sample size M = 100, target effect size set to 0.8&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# update the outcome in the sample to represent the target effect size
dat_upd &amp;lt;- dat
dat_upd$y &amp;lt;- dat_upd$y + (0.8 - coef(fit)[&amp;quot;x1&amp;quot;]) * dat_upd$x1
out &amp;lt;- rep(NA, B_boot)
for (rr in 1 : B_boot){
  dat_rr_idx &amp;lt;- sample(1 : nrow(dat_upd), size = 80, replace = TRUE)
  dat_rr &amp;lt;- dat_upd[dat_rr_idx, ]
  fit_rr &amp;lt;- lm(y ~ x1 + x2, data = dat_rr)
  pval_rr &amp;lt;- summary(fit_rr)$coef[&amp;quot;x1&amp;quot;, 4]
  out[rr] &amp;lt;- (pval_rr &amp;lt; 0.05)
}
mean(out)
# [1] 0.92
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;contributions&#34;&gt;Contributions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Our preprint: Karas, M., Crainiceanu, C.M. (2021) &lt;em&gt;Upstrap for estimating power and sample size in complex models&lt;/em&gt; &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;is available on bioRxiv&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive empirical pattern transformation (ADEPT)</title>
      <link>/project/project_adept/</link>
      <pubDate>Fri, 06 Dec 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_adept/</guid>
      <description>&lt;p&gt;We propose adaptive empirical pattern transformation (ADEPT), a fast, scalable, and accurate method for pattern segmentation in time-series.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to provide fast and accurate open-source method for pattern segmentation from raw accelerometry data.&lt;/p&gt;
&lt;p&gt;The methods were needed for automated walking strides segmentation from accelerometry recordings collected during continuous walking that we had across a number of health studies.&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;The plot below shows an example of raw accelerometry data &amp;ndash; three-dimensional time-series of acceleration [&lt;em&gt;g&lt;/em&gt;] measurements. Data showed were collected 5 s of walking for two different individuals, with 4 wearable sensors worn simultaneously at wrist, hip, left, and right ankle.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;intro_3d_acc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;While the repetitive patterns of walking are relatively clear to a human observer, there are a few challenges in segmenting them accurately with an algorithm:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There are variations in shape, magnitude and duration of a pattern within individual&amp;rsquo;s data. These might be e.g. due to terrain elevation changes, or temporal changes of step length and cadence (think about slowing down when approaching the turn of the corridor, or basically walking slower during an evening stroll versus morning rush to work). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is variability of walking data between individuals (e.g. see the plot above).  &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A sensor can move, or be worn on different hands by the same person on different days.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose adaptive empirical pattern transformation (ADEPT) to segment walking stride patterns in vector magnitude of raw accelerometry data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The ADEPT algorithm uses a predefined template and detects its repetitions by maximizing the local distance (i.e. correlation) between (a) collection of scale-transformed templates and (b) the observed data signal. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The scale-transformation adjusts the duration of the dictionary template, allowing for the detection of patterns that are shorter or longer than the original dictionary template. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple distinct baseline templates can be used simultaneously to account for various shape patterns occurring in the data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The GIF below demonstrates the big picture of the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;adept_concept3.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The underlying template&amp;rsquo;s scaling and translating along the observed data signal is closely related to the Continuous Wavelet Transform (CWT), $$W_{\Psi}(s, \tau)  =
\int_{-\infty}^{\infty} x(t) \frac{1}{\sqrt{s}}\Psi \left(\frac{t - \tau}{s} \right)dt.$$
Conversely to CWT&amp;rsquo;s mother wavelet $\Psi(\cdot)$, ADEPT  uses a data-based pattern function (not required to satisfy the wavelet admissibility condition) and comes with a number of other algorithm features tailored for its target application.&lt;/p&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We published the proposed ADEPT method in work &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/5572661&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation&lt;/a&gt; Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331â€“347.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed ADEPT  method in R package adept (&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The R package is accompanied by two vignettes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/vignettes/adept-intro.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to adept package&lt;/a&gt;,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/vignettes/adept-strides-segmentation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Walking strides segmentation with adept&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ðŸŽ‰ The adept R package was selected in Top 40 new CRAN packages in May 2019 (&lt;a href=&#34;https://rviews.rstudio.com/2019/06/25/may-2019-top-40-new-cran-packages/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;list link&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image. Figure 2 in the manuscript: Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331â€“347. &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/557266&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt; (last accessed on May 26, 2021).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Three-dimensional time-series image. Figure 1 in the manuscript: Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331â€“347. &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/557266&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt; (last accessed on May 26, 2021).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>&#39;adeptdata&#39; R package: Raw Accelerometry Data Sets and Their Derivatives</title>
      <link>/project/project_adeptdata/</link>
      <pubDate>Mon, 22 Apr 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_adeptdata/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;adeptdata&lt;/code&gt; was created to host raw accelerometry data sets and their derivatives. Some of them are used in the corresponding &lt;code&gt;adept&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Package CRAN index is located &lt;a href=&#34;https://cran.r-project.org/web/packages/adeptdata/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Package GitHub repo is located &lt;a href=&#34;https://github.com/martakarass/adeptdata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;Install from CRAN.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;adeptdata&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;data-objects&#34;&gt;Data objects&lt;/h1&gt;
&lt;h2 id=&#34;outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_walking_IU&lt;/code&gt; is a sample of raw accelerometry data collected during outdoor continuous walking from 32 healthy participants between 23 and 52 years of age. Data were collected at frequency 100 Hz simultaneously with four wearable accelerometers located at left wrist, left hip and both ankles. See &lt;code&gt;?acc_walking_IU&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(adeptdata)
library(dplyr)
library(ggplot2)
library(reshape2)
library(lubridate)

acc_walking_IU %&amp;gt;%
  filter(time_s &amp;lt; 6, subj_id == acc_walking_IU$subj_id[1]) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_wrist&amp;quot;, &amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;, &amp;quot;right_ankle&amp;quot;),
    labels = c(&amp;quot;Left wrist&amp;quot;, &amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;, &amp;quot;Right ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;subj_id&amp;quot;, &amp;quot;loc_id&amp;quot;, &amp;quot;time_s&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = time_s, y = value, color = variable)) + 
  geom_line() + 
  facet_wrap(~ loc_id, ncol = 2) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Exercise time [s]&amp;quot;, 
       y = &amp;quot;Amplitude [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data of walking (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;plot_acc_walking_IU.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_running&lt;/code&gt; is a sample raw accelerometry data collected during 25 minutes of an outdoor run. Data were collected at frequency 100 Hz with two ActiGraph GT9X Link sensors located at left hip and left ankle. See &lt;code&gt;?acc_running&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t1 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:07:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t2 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:20:30&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t3 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:22:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 

acc_running %&amp;gt;%
  filter((date_time &amp;gt;= t1 &amp;amp; date_time &amp;lt; t1 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t2 &amp;amp; date_time &amp;lt; t2 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t3 &amp;amp; date_time &amp;lt; t3 + as.period(4, &amp;quot;seconds&amp;quot;)) ) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;),
    labels = c(&amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;date_time&amp;quot;, &amp;quot;loc_id&amp;quot;)) %&amp;gt;%
  mutate(date_time_floor = paste0(
    &amp;quot;Minute start: &amp;quot;, floor_date(date_time, unit = &amp;quot;minutes&amp;quot;))) %&amp;gt;%
  ggplot(aes(x = date_time, y = value, color = variable)) + 
  geom_line(size = 0.5) + 
  facet_grid(loc_id ~ date_time_floor, scales = &amp;quot;free_x&amp;quot;) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Acceleration [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;acc_running.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;stride_template&lt;/code&gt; is a list containing walking stride pattern templates derived from accelerometry data collected at four body locations: left wrist, left hip, left ankle, and right ankle. See &lt;code&gt;?stride_template&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data.frame(
  x = rep(seq(0, 1, length.out = 200), 2),
  y = c(stride_template$left_ankle[[2]][1, ],
        stride_template$left_ankle[[2]][2, ]),
  group = c(rep(1, 200), rep(2, 200))) %&amp;gt;%
  ggplot(aes(x = x, y = y, group = group)) + 
  geom_line() +
  facet_grid(group ~ .) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Vector magnitude [g]&amp;quot;, 
       title = &amp;quot;Walking stride templates (left ankle)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;stride_template.jpeg&#34; width=&#34;50%&#34;&gt;
</description>
    </item>
    
    <item>
      <title>&#39;runstats&#39; R package: Fast Computation of Running Statistics for Time Series</title>
      <link>/project/project_runstats/</link>
      <pubDate>Fri, 15 Mar 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_runstats/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;runstats&lt;/code&gt; provides methods for fast computation of running sample statistics for time series. The methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT). Implemented running statistics include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mean,&lt;/li&gt;
&lt;li&gt;standard deviation,&lt;/li&gt;
&lt;li&gt;variance,&lt;/li&gt;
&lt;li&gt;covariance,&lt;/li&gt;
&lt;li&gt;correlation,&lt;/li&gt;
&lt;li&gt;euclidean distance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session info&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;website&#34;&gt;Website&lt;/h1&gt;
&lt;p&gt;Package website is located &lt;a href=&#34;https://martakarass.github.io/runstats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;runstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(runstats)

## Example: running correlation
x0 &amp;lt;- sin(seq(0, 2 * pi * 5, length.out = 1000))
x  &amp;lt;- x0 + rnorm(1000, sd = 0.1)
pattern &amp;lt;- x0[1:100]
out1 &amp;lt;- RunningCor(x, pattern)
out2 &amp;lt;- RunningCor(x, pattern, circular = TRUE)

## Example: running mean
x &amp;lt;- cumsum(rnorm(1000))
out1 &amp;lt;- RunningMean(x, W = 100)
out2 &amp;lt;- RunningMean(x, W = 100, circular = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;running-statistics&#34;&gt;Running statistics&lt;/h1&gt;
&lt;p&gt;To better explain the details of running statistics, package&amp;rsquo;s function &lt;code&gt;runstats.demo(func.name)&lt;/code&gt; allows to visualize how the output of each running statistics method is generated. To run the demo, use &lt;code&gt;func.name&lt;/code&gt; being one of the methods&#39; names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningMean&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningSd&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningVar&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCov&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCor&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningL2Norm&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running correlation method  
runstats.demo(&amp;quot;RunningCor&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_1.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running mean method 
runstats.demo(&amp;quot;RunningMean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_2.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;performance&#34;&gt;Performance&lt;/h1&gt;
&lt;p&gt;We use &lt;code&gt;rbenchmark&lt;/code&gt; to measure elapsed time of &lt;code&gt;RunningCov&lt;/code&gt; execution, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter pattern &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rbenchmark)
library(ggplot2)

set.seed (20190315)
x.N.seq &amp;lt;- 10^(3:7)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))
y &amp;lt;- runif(100)

## Benchmark execution time of RunningCov 
out.df &amp;lt;- data.frame()
for (x.tmp in x.list){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df.tmp$pattern_length &amp;lt;- length(y)
  out.df &amp;lt;- rbind(out.df, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;knitr::kable(out.df)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;test&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;replications&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;elapsed&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;relative&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;user.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;sys.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;x_length&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;pattern_length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.003&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.023&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.019&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.183&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.148&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.035&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.700&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.592&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.107&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;19.852&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;17.185&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2.576&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/h2&gt;
&lt;p&gt;To compare &lt;code&gt;runstats&lt;/code&gt; performance with &amp;ldquo;conventional&amp;rdquo; loop-based way of computing running covariance in &lt;code&gt;R&lt;/code&gt;, we use &lt;code&gt;rbenchmark&lt;/code&gt; package to measure elapsed time of &lt;code&gt;runstats::RunningCov&lt;/code&gt; and running covariance implemented with &lt;code&gt;sapply&lt;/code&gt; loop, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter time-series &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Conventional approach 
RunningCov.sapply &amp;lt;- function(x, y){
  l_x &amp;lt;- length(x)
  l_y &amp;lt;- length(y)
  sapply(1:(l_x - l_y + 1), function(i){
    cov(x[i:(i+l_y-1)], y)
  })
}

out.df2 &amp;lt;- data.frame()
for (x.tmp in x.list[c(1:4)]){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;conventional&amp;quot; = RunningCov.sapply(x.tmp, y),
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df2 &amp;lt;- rbind(out.df2, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plt1 &amp;lt;- 
  ggplot(out.df2, aes(x = x_length, y = elapsed, color = test)) + 
  geom_line() + geom_point(size = 3) + scale_x_log10() + 
  theme_minimal(base_size = 14) + 
  labs(x = &amp;quot;Vector length of x&amp;quot;,
       y = &amp;quot;Elapsed [s]&amp;quot;, color = &amp;quot;Method&amp;quot;, 
       title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;, 
       subtitle = &amp;quot;Vector length of y = 100&amp;quot;) + 
  theme(legend.position = &amp;quot;bottom&amp;quot;)
plt2 &amp;lt;- 
  plt1 + 
  scale_y_log10() + 
  labs(y = &amp;quot;Log of elapsed [s]&amp;quot;, title = &amp;quot;&amp;quot;)

cowplot::plot_grid(plt1, plt2, nrow = 1, labels = c(&#39;A&#39;, &#39;B&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_conventional_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dvmisc&lt;/code&gt; package (&lt;a href=&#34;https://github.com/vandomed/dvmisc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/dvmisc/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;) is a package for &lt;em&gt;Convenience Functions, Moving Window Statistics, and Graphics&lt;/em&gt;, and includes functions for calculating moving-window statistics efficiently via c++, written by &lt;a href=&#34;https://vandomed.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dane Van Domelen&lt;/a&gt;. Here, we compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; performance with c++ implementation from &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt;. Dane contributed the code in its large part.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# devtools::install_github(&amp;quot;vandomed/dvmisc&amp;quot;)
library(dvmisc)

set.seed(20100315)
x.N.seq &amp;lt;- 10^(3:6)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))

get.out.df &amp;lt;- function(y){
  out.df &amp;lt;- data.frame()
  for (x.tmp in x.list){
    if (length(x.tmp) &amp;lt; length(y)){
      out.df.tmp &amp;lt;- data.frame(
        test = NA,  replications = NA, elapsed = NA, relative = NA,
        user.self = NA, sys.self = NA)
    } else {
      out.df.tmp &amp;lt;- benchmark(
        &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
        &amp;quot;dvmisc&amp;quot; = dvmisc::sliding_cov(y, x.tmp), 
        replications = 10,
        columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                    &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
    }
    out.df.tmp$x_length &amp;lt;- length(x.tmp)
    out.df &amp;lt;- rbind(out.df, out.df.tmp)
  }
  return(out.df)
}

out.df_y10    &amp;lt;- get.out.df(runif(10^1))
out.df_y100   &amp;lt;- get.out.df(runif(10^2))
out.df_y1000  &amp;lt;- get.out.df(runif(10^3))
out.df_y10000 &amp;lt;- get.out.df(runif(10^4))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get.plt &amp;lt;- function(data, subtitle){
  ggplot(data, aes(x = x_length, y = elapsed, color = test)) + 
    geom_line() + geom_point(size = 3) + scale_x_log10() + 
    theme_minimal(base_size = 14) +  scale_y_log10() + 
    labs(x = &amp;quot;Vector length of x&amp;quot;,
         y = &amp;quot;Log of elapsed [s]&amp;quot;, 
         color = &amp;quot;Method&amp;quot;, 
         subtitle = subtitle) + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)
}

plt1 &amp;lt;- get.plt(out.df_y10, &amp;quot;Vector length of y = 10&amp;quot;) + 
  labs(title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;)
plt2 &amp;lt;- get.plt(out.df_y100,   &amp;quot;Vector length of y = 100&amp;quot;)
plt3 &amp;lt;- get.plt(out.df_y1000,  &amp;quot;Vector length of y = 1,000&amp;quot;)
plt4 &amp;lt;- get.plt(out.df_y10000, &amp;quot;Vector length of y = 1,0000&amp;quot;)

cowplot::plot_grid(plt1, plt2, plt3, plt4, nrow = 2, labels = c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_dvmisc_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;session-info&#34;&gt;Session info&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessioninfo::session_info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    ## â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ##  setting  value                       
    ##  version  R version 3.5.2 (2018-12-20)
    ##  os       macOS Mojave 10.14.2        
    ##  system   x86_64, darwin15.6.0        
    ##  ui       X11                         
    ##  language (EN)                        
    ##  collate  en_US.UTF-8                 
    ##  ctype    en_US.UTF-8                 
    ##  tz       America/New_York            
    ##  date     2019-11-14                  
    ## 
    ## â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ##  package     * version date       lib source        
    ##  assertthat    0.2.1   2019-03-21 [1] CRAN (R 3.5.2)
    ##  cli           1.1.0   2019-03-19 [1] CRAN (R 3.5.2)
    ##  colorspace    1.4-1   2019-03-18 [1] CRAN (R 3.5.2)
    ##  crayon        1.3.4   2017-09-16 [1] CRAN (R 3.5.0)
    ##  digest        0.6.22  2019-10-21 [1] CRAN (R 3.5.2)
    ##  dplyr         0.8.3   2019-07-04 [1] CRAN (R 3.5.2)
    ##  evaluate      0.14    2019-05-28 [1] CRAN (R 3.5.2)
    ##  fftwtools     0.9-8   2017-03-25 [1] CRAN (R 3.5.0)
    ##  ggplot2     * 3.2.1   2019-08-10 [1] CRAN (R 3.5.2)
    ##  glue          1.3.1   2019-03-12 [1] CRAN (R 3.5.2)
    ##  gtable        0.3.0   2019-03-25 [1] CRAN (R 3.5.2)
    ##  htmltools     0.3.6   2017-04-28 [1] CRAN (R 3.5.0)
    ##  knitr         1.26    2019-11-12 [1] CRAN (R 3.5.2)
    ##  lazyeval      0.2.2   2019-03-15 [1] CRAN (R 3.5.2)
    ##  magrittr      1.5     2014-11-22 [1] CRAN (R 3.5.0)
    ##  munsell       0.5.0   2018-06-12 [1] CRAN (R 3.5.0)
    ##  pillar        1.4.2   2019-06-29 [1] CRAN (R 3.5.2)
    ##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 3.5.2)
    ##  purrr         0.3.3   2019-10-18 [1] CRAN (R 3.5.2)
    ##  R6            2.4.1   2019-11-12 [1] CRAN (R 3.5.2)
    ##  rbenchmark  * 1.0.0   2012-08-30 [1] CRAN (R 3.5.0)
    ##  Rcpp          1.0.3   2019-11-08 [1] CRAN (R 3.5.2)
    ##  rlang         0.4.1   2019-10-24 [1] CRAN (R 3.5.2)
    ##  rmarkdown     1.15    2019-08-21 [1] CRAN (R 3.5.2)
    ##  rstudioapi    0.10    2019-03-19 [1] CRAN (R 3.5.2)
    ##  runstats    * 1.1.0   2019-11-14 [1] CRAN (R 3.5.2)
    ##  scales        1.0.0   2018-08-09 [1] CRAN (R 3.5.0)
    ##  sessioninfo   1.1.1   2018-11-05 [1] CRAN (R 3.5.0)
    ##  stringi       1.4.3   2019-03-12 [1] CRAN (R 3.5.2)
    ##  stringr       1.4.0   2019-02-10 [1] CRAN (R 3.5.2)
    ##  tibble        2.1.3   2019-06-06 [1] CRAN (R 3.5.2)
    ##  tidyselect    0.2.5   2018-10-11 [1] CRAN (R 3.5.0)
    ##  withr         2.1.2   2018-03-15 [1] CRAN (R 3.5.0)
    ##  xfun          0.11    2019-11-12 [1] CRAN (R 3.5.2)
    ##  yaml          2.2.0   2018-07-25 [1] CRAN (R 3.5.0)
    ## 
    ## [1] /Library/Frameworks/R.framework/Versions/3.5/Resources/library
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Brain connectivity-informed regularization methods for regression</title>
      <link>/project/project_mdpeer/</link>
      <pubDate>Wed, 06 Dec 2017 11:54:53 -0400</pubDate>
      <guid>/project/project_mdpeer/</guid>
      <description>&lt;p&gt;We propose to estimate association between the brain structure features and a scalar outcome in a regression model while utilizing additional information about structural connectivity between the brain regions.&lt;/p&gt;
&lt;p&gt;Specifically, we propose a novel regularization method &amp;ndash; riPEER (ridgified Partially Empirical Eigenvectors for Regression) &amp;ndash; that defines a regularization penalty term based on the structural connectivity-derived Laplacian matrix.&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to quantify the association between alcohol abuse phenotypes (outcome) and cortical thickness of the brain (covariates) in a study sample of young social-to-heavy drinking males. The data included measurements of average cortical thickness estimated for 68 brain regions.&lt;/p&gt;
&lt;p&gt;This image (see images credit &lt;a href=&#34;#custom&#34;&gt;below&lt;/a&gt;) visualizes process of obtaining cortical thickness measurements from structural MRI images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;MRI_sequence.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;Commonly shared issues in such settings are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;high dimensionality of the data - we typically parcel the brain into tens, or hundreds of units from which we take measurements, and each unit may then correspond to a covariate in the data set,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;correlation of the covariates - measurements from spatially neighbouring or otherwise connected brain regions are likely to be correlated,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;small sample size - brain imaging studies often recruit a few tens of participants only.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose penalized regression method riPEER to estimate a linear model: $$y =  Zb + X\beta + \varepsilon$$ where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y$ - response (&lt;em&gt;here: alcohol abuse phenotypes&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$Z$ - input data matrix (&lt;em&gt;here: cortical thickness measurements&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$X$ - input data matrix (&lt;em&gt;here: demographics data&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\beta$ - regression coefficients, not penalized in estimation process&lt;/li&gt;
&lt;li&gt;$b$ - regression coefficients, penalized in estimation process and for whom there is a prior graph of similarity / graph of connections. available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The riPEER estimation method uses a penalty being a linear combination of a graph-based and ridge penalty terms:
$$
\hat{\beta}, \hat{b}
= \underset{\beta,b}{\text{arg min}} \left[ (y - X\beta - Zb)^T(y - X\beta - Zb)  + \lambda_Qb^TQb +  \lambda_Rb^Tb  \right ]
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Q$ - a graph-originated penalty matrix; typically: a graph Laplacian matrix (&lt;em&gt;here: a graph Laplacian derived from structural connectivity of brain regions&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\lambda_Q$ - regularization parameter for a graph-based penalty term,&lt;/li&gt;
&lt;li&gt;$\lambda_R$ - regularization parameter for ridge penalty term.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;ripeer-penalty-term&#34;&gt;riPEER penalty term&lt;/h5&gt;
&lt;p&gt;In the riPEER penalty term  $(\lambda_Qb^TQb +  \lambda_Rb^Tb)$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A graph-originated penalty matrix $Q$ allows imposing similarity between coefficients of variables which are &lt;em&gt;connected&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A ridge penalty term, $\lambda_Rb^Tb$, allows for L2 regularization component; in addition, even with very small $\lambda_R$, eliminates computational issues arising from singularity of $Q$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regularization parameters $\lambda_R$, $\lambda_Q$ are estimated automatically as ML estimators of equivalent Linear Mixed Models optimization problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We published the proposed riPEER method in work &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6583926/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brain connectivity-informed regularization methods for regression&lt;/a&gt; (Karas, M., Brzyski, D., Dzemidzic, M., Goni, J., Kareken, D.A., Randolph, T., Harezlak J. (2017)).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We published the riPEER extension to generalized linear regression, addressing both theoretical and computational issues, in work &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connectivityâ€informed adaptive regularization for generalized outcomes&lt;/a&gt; (Brzyski, D., Karas, M., Ances, B.M., Dzemidzic, M., Goni, J., Randolph, T., Harezlak J. (2021)).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed riPEER estimation method in R package mdpeer (&lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The package provides functions for graph-constrained regression methods in which regularization parameters are selected automatically via estimation of equivalent Linear Mixed Model formulation.&lt;/p&gt;
&lt;p&gt;The R package is accompanied by &lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/vignettes/Intro_and_usage_examples.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intro and usage examples&lt;/a&gt; vignette.&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top left component. Cortical thickness. Resources of Neurorecovery Laboratory at MGH/MIT/HMS Athinoula A. Martinos Center for Biomedical Imaging. Accessed at: &lt;a href=&#34;https://www.nmr.mgh.harvard.edu/neurorecovery/technology.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top middle component. Diffusion MRI Tractography in the brain white matter. Xavier Gigandet et. al. - Gigandet X, Hagmann P, Kurant M, Cammoun L, Meuli R, et al. (2008) Estimating the Confidence Level of White Matter Connections Obtained with MRI Tractography. PLoS ONE 3(12): e4006. doi:10.1371/journal.pone.0004006. Accessed at: &lt;a href=&#34;https://en.wikipedia.org/wiki/Connectome#/media/File:White_Matter_Connections_Obtained_with_MRI_Tractography.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top right component. Databases of Statistical Information. Resources of Berkeley Advanced Media Institute
Graduate School of Journalism. Accessed at: &lt;a href=&#34;https://multimedia.journalism.berkeley.edu/tutorials/databases-of-statistical-information/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
