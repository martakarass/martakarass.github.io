<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Home</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 15 Feb 2021 17:59:50 -0400</lastBuildDate>
    <image>
      <url>/images/icon_hufdd866d90d76849587aac6fbf27da1ac_464_512x512_fill_lanczos_center_2.png</url>
      <title>Home</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Connectivity-Informed Adaptive Regularization for Generalized Outcomes</title>
      <link>/publication/brain-connectivity-informed-regularization-generalized/</link>
      <pubDate>Mon, 15 Feb 2021 17:59:50 -0400</pubDate>
      <guid>/publication/brain-connectivity-informed-regularization-generalized/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Estimation of free-living walking cadence from wrist-worn sensor accelerometry data and its association with SF-36 quality of life scores</title>
      <link>/talk/2020-12-20-cmsstatistics/</link>
      <pubDate>Sun, 20 Dec 2020 11:30:00 +0000</pubDate>
      <guid>/talk/2020-12-20-cmsstatistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>arctools R package: Processing and physical activity summaries of minute level activity data</title>
      <link>/talk/2020-12-17-wit_arctools/</link>
      <pubDate>Thu, 17 Dec 2020 14:30:00 +0000</pubDate>
      <guid>/talk/2020-12-17-wit_arctools/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Predicting Subjective Recovery from Lower Limb Surgery Using Consumer Wearables</title>
      <link>/publication/predicting-subjective-recovery/</link>
      <pubDate>Wed, 09 Dec 2020 18:08:38 -0400</pubDate>
      <guid>/publication/predicting-subjective-recovery/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Predicting subjective recovery from lower limb surgery using consumer wearables</title>
      <link>/talk/2020-12-08-krager_workshop/</link>
      <pubDate>Tue, 08 Dec 2020 11:00:00 +0000</pubDate>
      <guid>/talk/2020-12-08-krager_workshop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent developments in R tidyverse</title>
      <link>/talk/2020-12-01-computing_club/</link>
      <pubDate>Tue, 01 Dec 2020 12:15:00 +0000</pubDate>
      <guid>/talk/2020-12-01-computing_club/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Summer internship project: Predicting subjective recovery from lower limb surgery using consumer wearables</title>
      <link>/talk/2020-09-31-wit_summer_project_evidation/</link>
      <pubDate>Wed, 30 Sep 2020 14:30:00 -0400</pubDate>
      <guid>/talk/2020-09-31-wit_summer_project_evidation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Novel approach for precise walking cadence estimation from high-density tri-axial accelerometry data collected at wrist in free-living</title>
      <link>/talk/2020-08-17-iscb_krakow/</link>
      <pubDate>Thu, 27 Aug 2020 15:50:50 -0400</pubDate>
      <guid>/talk/2020-08-17-iscb_krakow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>All past updates</title>
      <link>/resources/recently-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 -0400</pubDate>
      <guid>/resources/recently-all/</guid>
      <description>&lt;h4 id=&#34;2020&#34;&gt;2020&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Connectivity‐informed adaptive regularization for generalized outcomes&amp;rdquo;&lt;/a&gt; is published. We proposed riPEER (ridgified Partially Empirical Eigenvectors for Regression) extension to generalized linear regression, addressing both theoretical and computational issues. See the relevant &lt;a href=&#34;https://martakarass.github.io/project/project_mdpeer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project page&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://www.karger.com/Article/FullText/511531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Predicting Subjective Recovery from Lower Limb Surgery Using Consumer Wearables&amp;rdquo;&lt;/a&gt; is published. We showed that passively collected wearable PGHD can capture post-surgery physical activity changes relative to individual&amp;rsquo;s baseline, and baseline data can improve prediction of self-reported recovery time at 4 weeks post surgery.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;During the upcoming workshop &amp;ldquo;The Future of Digital Health&amp;rdquo;, I will give a talk highlighting &amp;ldquo;Predicting subjective recovery from lower limb surgery using consumer wearables&amp;rdquo; paper I co-authored. This workshop will highlight key papers from the newly released &lt;a href=&#34;https://pages.evidation.com/karger-special-issue&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Special Issue of Digital Biomarkers&lt;/a&gt;, sponsored by &lt;a href=&#34;https://evidation.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evidation Health&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/company/dime-society/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DiMe&lt;/a&gt;. Register for the workshop &lt;a href=&#34;https://us02web.zoom.us/webinar/register/WN_ugdWjno7S5ummYWYPX_s3w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;During summer of 2020, I am working as a Data Science Intern in Digital Measures team @ &lt;a href=&#34;https://evidation.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evidation Health&lt;/a&gt;. My main project aims at estimating medical procedure recovery trajectories and predicting recovery time from wearable patient-generated health data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why R? Foundation awards a &lt;a href=&#34;http://whyr.pl/foundation/supporting-grant/#scientific-committee&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;supporting grant for Women in Data Science&lt;/a&gt; to aid exceptional female data scientists in Poland. I serve as a member of Scientific committee for this initiative.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2019&#34;&gt;2019&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I passed my preliminary schoolwide oral exam. My Committee consisted of three faculty from the Dept. of Biostatistics, one faculty from Dept. of Epidemiology, and one faculty from the Dept. of Medicine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I received Leadership, Empowerment and Learning Culture &lt;a href=&#34;/docs/certificates/2019-10-09-Novartis_LELC_US_Bios_Award_Certificate_Marta_Karas.pdf&#34;&gt;Award&lt;/a&gt; during Novartis US Analytics Conference 2019. My conference talk presented the work done as a Sensor Data Analytics Intern with Novartis in Basel, Switzerland during summer 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our paper &amp;ldquo;&lt;em&gt;Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation&lt;/em&gt;&amp;rdquo; just got published in
&lt;em&gt;Biostatistics&lt;/em&gt; with the journal&amp;rsquo;s highest reproducibility status! See &lt;a href=&#34;https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz033/5572661?guestAccessKey=f3abdf65-a94d-4509-b7e9-cca2ff384528&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ADEPT article&lt;/a&gt; online.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our R package &lt;code&gt;adept&lt;/code&gt; that implements ADEPT pattern-segmentation method is out on CRAN (&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;. The vignette shows example of strides segmentation from raw accelerometry data of 25min outdoor run w/ walking and resting bouts. Listed May 2019 top 40 new CRAN packages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am working as Sensor Data Analytics Intern with Novartis pharmaceutical company in Basel, Switzerland this summer. I am also &lt;a href=&#34;https://martakarass.github.io/talk/2019-06-26-icampam/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;presenting&lt;/a&gt; at ICAMPAM 2019 conference on Jun 26 in Maastricht, the Netherlands.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our R package &lt;code&gt;runstats&lt;/code&gt; that provides methods for fast computation of running sample statistics for time series is out on CRAN (&lt;a href=&#34;https://cran.r-project.org/web/packages/runstats/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). Use &lt;code&gt;runstats&lt;/code&gt; to compute  (1) mean, (2) standard deviation, and (3) variance over a fixed-length window of time-series, (4) correlation, (5) covariance, and (6) Euclidean distance (L2 norm) between short-time pattern and time-series. Implemented methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our recent article &amp;ldquo;Accelerometry Data in Health Research: Challenges and Opportunities&amp;rdquo; is now published and &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6874221/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available online&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2018&#34;&gt;2018&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Interested in statistical methodology for singal processing in physical activity research? Come to JSM &lt;a href=&#34;https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/ActivityDetails.cfm?SessionID=215216&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;session&lt;/a&gt; on Wednesday (8/1/2018), 2:00 PM - 3:50 PM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://whyr2018.pl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WhyR? 2018&lt;/a&gt; conference starts on July 2nd in Wroclaw, Poland. Both academia and industry professionals meet and discuss experiences in R software development and analysis applications.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am working as a Research Assistant with Drs. &lt;a href=&#34;https://jacekurbanek.wordpress.com/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jacek Urbanek&lt;/a&gt; and &lt;a href=&#34;http://www.ciprianstats.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ciprian Crainiceanu&lt;/a&gt; this summer at a novel approach for identifying individual working strides from subsecond accelerometry data of walking.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Teaching experience</title>
      <link>/resources/teaching-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 -0400</pubDate>
      <guid>/resources/teaching-all/</guid>
      <description>&lt;h2 id=&#34;academic-year-2020-21&#34;&gt;Academic year 2020-21&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Term&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course Number&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course title&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Teaching role&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2020-21 Term 1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.651&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/25922/2018/140.651.01/methods-in-biostatistics-i&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics I&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lead TA (lab)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2020-21 Term 2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.651&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/17639/2013/140.652.01/methods-in-biostatistics-ii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics II&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lead TA (lab)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;academic-year-2019-20&#34;&gt;Academic year 2019-20&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Term&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course Number&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course title&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Teaching role&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2019-20 Term 1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.651&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/25922/2018/140.651.01/methods-in-biostatistics-i&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics I&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lead TA (lab, office hours)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2019-20 Term 2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.652&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/17639/2013/140.652.01/methods-in-biostatistics-ii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics II&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lead TA (lab, office hours)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2019-20 Term 1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.850&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://martakarass.github.io/resources/specialtopics/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Special topics course: Biostatistical Methods for Wearable Computing&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Co-instructor&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;academic-year-2018-19&#34;&gt;Academic year 2018-19&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Term&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course Number&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Course title&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Teaching role&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2018-19 Term 1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.651&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/25922/2018/140.651.01/methods-in-biostatistics-i&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics I&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lab TA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2018-19 Term 2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.652&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/17639/2013/140.652.01/methods-in-biostatistics-ii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methods in Biostatistics II&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Lab TA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2018-19 Term 3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.623&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/courses/course/24892/2017/140.623.01/statistical-methods-in-public-health-iii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Statistical Methods in Public Health III&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2018-19 Term 4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;140.624&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;http://biostat.jhsph.edu/courses/bio624/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Statistical Methods in Public Health IV&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>arctools: R software for computing summaries of minute-level physical activity data</title>
      <link>/talk/2020-06-04-engage_arcstats/</link>
      <pubDate>Thu, 04 Jun 2020 11:00:00 -0400</pubDate>
      <guid>/talk/2020-06-04-engage_arcstats/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Precise walking strides segmentation from raw accelerometry data: ADEPT method</title>
      <link>/talk/2020-03-11-kth-oss-webinar-adept/</link>
      <pubDate>Wed, 11 Mar 2020 14:00:50 -0400</pubDate>
      <guid>/talk/2020-03-11-kth-oss-webinar-adept/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards precise walking strides segmentation from accelerometry data in free-living: ADEPT method and further developments</title>
      <link>/talk/2020-02-25-banff/</link>
      <pubDate>Tue, 25 Feb 2020 02:15:00 -0500</pubDate>
      <guid>/talk/2020-02-25-banff/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1NTzmMksT8yo0awtZseVjN4XufwVzOtLUn86SxTW1XWY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;. .&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional registration of walking strides in high-density accelerometry data for estimation of gait asymmetry</title>
      <link>/talk/2019-12-03-cmstatistics-london/</link>
      <pubDate>Mon, 16 Dec 2019 08:40:00 -0500</pubDate>
      <guid>/talk/2019-12-03-cmstatistics-london/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Methods for fast processing of time-series: runstats R package</title>
      <link>/talk/2019-11-05-3rd-oss-webinar/</link>
      <pubDate>Tue, 05 Nov 2019 15:00:50 -0500</pubDate>
      <guid>/talk/2019-11-05-3rd-oss-webinar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Considerations in statistical modeling of walking features derived from wrist-worn sensor in free-living</title>
      <link>/talk/2019-10-31-wit-novartis/</link>
      <pubDate>Thu, 31 Oct 2019 14:30:00 -0400</pubDate>
      <guid>/talk/2019-10-31-wit-novartis/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1o-2GPXTglKrAjRtp2SeHupr8hMykeHneJ12LZgxB6AY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;. .&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>When to use t distribution versus normal distribution quantiles in constructing confidence interval for the mean</title>
      <link>/post/2019-10-28-ttest-versus-ztest/</link>
      <pubDate>Mon, 28 Oct 2019 17:19:28 -0400</pubDate>
      <guid>/post/2019-10-28-ttest-versus-ztest/</guid>
      <description>&lt;p&gt;To construct confidence interval for the mean, we often use quantiles of standardized sample mean distribution. Here, I include a list of cases where I&amp;rsquo;d use quantiles of t-distribution versus quantiles of normal distribution for that purpose.&lt;/p&gt;
&lt;p&gt;Note: the below text could be directly translated to answer when to use t-test versus z-test in testing hypothesis about the mean parameter.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkblueexample-1-constructing-confidence-interval-for-mu-with-z-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 1: constructing confidence interval for $\mu$ with $z$-quantiles&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkblueexample-2-constructing-confidence-interval-for-mu-with-t-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 2: constructing confidence interval for $\mu$ with $t$-quantiles&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-1-observations-from-normal-distribution-sigma-known-any-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 1: observations from normal distribution, $\sigma$ known, any $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-2-observations-from-normal-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 2: observations from normal distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-3-observations-from-normal-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 3: observations from normal distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-4-observations-from-any-distribution-sigma-known-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 4: observations from any distribution, $\sigma$ known, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-5-observations-from-any-distribution-sigma-known-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 5: observations from any distribution, $\sigma$ known, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-6-observations-from-any-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 6: observations from any distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-7-observations-from-any-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 7: observations from any distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;standardized-sample-mean&#34;&gt;Standardized sample mean&lt;/h1&gt;
&lt;p&gt;Consider $X_1, \ldots, X_n$ &amp;ndash; a sequence of i.i.d. random variables with mean $E(X_i) = \mu$ and  variance $\text{var}(X_i) = \sigma^2$. To construct confidence intervals for $\mu$ parameter, we often use a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}},
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;or its version where $S_n$ &amp;ndash; a consistent estimator of true standard deviation $\sigma$ &amp;ndash; is used, $\frac{\overline{X}_n - \mu}{S_n/\sqrt{n}}$; the latter is common in practice as we typically do not know $\sigma$ and must estimate it from the data. Knowing distribution of a standardized sample mean allows us to construct confidence interval for a mean $\mu$ parameter.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkblueexample-1-constructing-confidence-interval-for-mu-with-z-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 1: constructing confidence interval for $\mu$ with $z$-quantiles&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Assume $X_1, \ldots, X_n$ are i.i.d. $\sim N(\mu,\sigma^2)$ and $\sigma$ is known. Then we have an exact distributional result for a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \sim N(0,1).
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Let us denote $z_{ 1-\frac{\alpha}{2}}$ to be $(1-\frac{\alpha}{2})$-th quantile of standard normal distribution $N(0,1)$. Since  $N(0,1)$ is symmetric around $0$, we have $z_{\frac{\alpha}{2}} = -z_{1-\frac{\alpha}{2}}$ and we can write&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
1-\alpha = P\left(-z_{1-\frac{\alpha}{2}} \leq \frac{\overline{X}_n-\mu}{\sigma/\sqrt{n}} \leq z_{1-\frac{\alpha}{2}} \right)
=  P\left(\bar{X}_n-z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n+z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}} \right),
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;which yields that $\left[ \bar{X}_n-z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, ; \bar{X}_n+z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}}\right]$ is a $(1-\alpha )$-confidence interval for a mean parameter $\mu$.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkblueexample-2-constructing-confidence-interval-for-mu-with-t-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 2: constructing confidence interval for $\mu$ with $t$-quantiles&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Assume $X_1, \ldots, X_n$ are i.i.d. $\sim N(\mu,\sigma^2)$ and $\sigma$ is &lt;strong&gt;unknown&lt;/strong&gt;. We use $S_n$ &amp;ndash; a consistent sample estimator of true standard deviation &amp;ndash; to approximate $\sigma$, and have an exact distributional result for a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{S_n/\sqrt{n}} \sim t_{n-1}.
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Let us denote $t_{n-1,1-\frac{\alpha}{2}}$ to be a $(n-1,1-\frac{\alpha}{2})$-th quantile of $t$-distributuon with $n-1$ degrees of freedom. Since $t$ is symmetric around $0$, we have&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
1-\alpha =P\left(-t_{n-1,1-\frac{\alpha}{2}} \leq \frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \leq t_{n-1,1-\frac{\alpha}{2}}\right)
= P\left(\bar{X}_n-t_{n-1, 1-\frac{\alpha}{2}}\frac{S_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n+t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}} \right),
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;which yields that $\left[ \bar{X}_n-t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}}, ; \bar{X}_n+t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}}\right]$ is a $(1-\alpha )$-confidence interval for a mean parameter $\mu$.&lt;/p&gt;
&lt;h1 id=&#34;cases&#34;&gt;Cases&lt;/h1&gt;
&lt;p&gt;In many cases, whether to use quantiles of $t$-student distribution versus standard normal distribution is based on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distribution of $X_1, \ldots, X_n$ variables,&lt;/li&gt;
&lt;li&gt;whether  $\sigma$ is known or not (and we need to estimate it i.e. with $S_n$),&lt;/li&gt;
&lt;li&gt;what is sample size $n$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: the below cases could be directly translated to answer when to use $t$-test versus $z$-test in testing hypothesis about the mean $\mu$ parameter, i.e. test for $H_0: \mu = \mu_0$ versus $H_1: \mu &amp;lt; \mu_0$, or $H_1: \mu \neq \mu_0$, or $H_1: \mu &amp;gt; \mu_0$.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-1-observations-from-normal-distribution-sigma-known-any-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 1: observations from normal distribution, $\sigma$ known, any $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Any sample size $n$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We have exact result that  $\frac{\bar{X}_{n}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)$ and hence we use quantiles of normal distribution in constructing the CI.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-2-observations-from-normal-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 2: observations from normal distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We use $S_{n}$ to approximate $\sigma$. We have exact result that  $\frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \sim t_{n-1}$ and hence we use quantiles of $t$ distribution with $n-1$ degrees of freedom in constructing the CI.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-3-observations-from-normal-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 3: observations from normal distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We use $S_{n}$ to approximate $\sigma$. Because of $n$ large enough, Slutsky&amp;rsquo;s theorem asymptotic ``kicks in&#39;&#39; and allows to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation, and to write that $\frac{\bar{X}_{n}-\mu}{S_n / \sqrt{n}} \approx \sim N(0,1)$. Because of $n$ large enough, we assume $N(0,1)$ is approximated ($\approx$) well enough to use quantiles of normal distribution in constructing the CI.&lt;/p&gt;
&lt;p&gt;$\Rightarrow$ Another way to think about this case is that, as in Case 2, we have an exact result that $\frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \sim t_{n-1}$, and with large $n$, quantiles of $t$-distribution with $n-1$ degrees of freedom are almost equvalent to quantiles of normal distribution.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-4-observations-from-any-distribution-sigma-known-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 4: observations from any distribution, $\sigma$ known, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ Use CLT to get that standardized sample mean is approximately normal, $\frac{\bar{X}_{n}-\mu}{\sigma / \sqrt{n}} \approx \sim N(0,1)$. Since there is CLT approximation and we have a small sample size, in practice, we typically use quantiles of $t$ distribution with $n-1$ degrees of freedom to get more conservative (wider) CI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: when $X_1, \ldots, X_n$ distribution of is very skewed (i.e. Poisson) it may be not plausible that CLT already ``kicks in&#39;&#39; and other techniques may be needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-5-observations-from-any-distribution-sigma-known-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 5: observations from any distribution, $\sigma$ known, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal. We have $\frac{\bar{X}_{n}-\mu}{\sigma/ \sqrt{n}} \approx \sim N(0,1)$. Since we have a moderate to small sample size, we assume that CLT ``kicks in&#39;&#39; and the approximation ($\approx$) is good enough to use quantiles of normal distribution.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-6-observations-from-any-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 6: observations from any distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal  and we also use Slutsky&amp;rsquo;s theorem to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation. We have $\frac{\bar{X}_{n}-\mu}{S_n/ \sqrt{n}} \approx \sim N(0,1)$. Since there is CLT and Slutsky&amp;rsquo;s theorem approximation and we have a small sample size, in practice, we typically use quantiles of $t$ distribution with $n-1$ degrees of freedom to get more conservative (wider) CI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: two approximations are happening here!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: when $X_1, \ldots, X_n$ distribution of is very skewed (i.e. Poisson) it may be not plausible that CLT already ``kicks in&#39;&#39; and other techniques may be needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-7-observations-from-any-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 7: observations from any distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal  and we also use Slutsky&amp;rsquo;s theorem to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation. We have $\frac{\bar{X}_{n}-\mu}{S_n/ \sqrt{n}} \approx \sim N(0,1)$. Since we have a moderate to small sample size, we assume that both CLT and Slutsky asymptotics ``kicks in&#39;&#39; and the approximation ($\approx$) is good enough to use quantiles of normal distribution.&lt;/p&gt;
&lt;h1 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h1&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt;The views, thoughts, and opinions expressed in the text belong solely to the author, and not necessarily to the author’s employer, organization, committee or other group or individual.&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1]: Methods in Biostatistics with R. Ciprian Crainiceanu, Brian Caffo, John Muschelli (2019). Available online at &lt;a href=&#34;https://leanpub.com/biostatmethods&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://leanpub.com/biostatmethods&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Overview of JHU Biostat Wearable and Implantable Technology (WIT) working group research</title>
      <link>/talk/2019-10-15-journal-club-wit/</link>
      <pubDate>Tue, 15 Oct 2019 12:15:00 -0400</pubDate>
      <guid>/talk/2019-10-15-journal-club-wit/</guid>
      <description>&lt;p&gt;Slides &lt;a href=&#34;https://docs.google.com/presentation/d/1TAPuMzQmeB9GP06FNKmoXAcPDt9A9_h4NhJSRtoapMY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Walking measurements derived from free-living wrist-worn sensor as novel digital endpoints</title>
      <link>/talk/2019-10-06-novartis-internal/</link>
      <pubDate>Tue, 08 Oct 2019 09:40:00 -0400</pubDate>
      <guid>/talk/2019-10-06-novartis-internal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Special Topics course 2018-19: Biostatistical Methods for Wearable Computing</title>
      <link>/resources/specialtopics/</link>
      <pubDate>Mon, 30 Sep 2019 19:17:23 -0400</pubDate>
      <guid>/resources/specialtopics/</guid>
      <description>&lt;p&gt;Materials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Oct 1, 2019: &lt;a href=&#34;../../resources/specialtopics_materials/intro&#34;&gt;Introduction to raw accelerometry data. Introduction to project raw accelerometry data set&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oct 17, 2019: &lt;a href=&#34;https://docs.google.com/presentation/d/1W1PYSI9LvW2pqVCqvBR-xbIeB87diaQPNXhVAnNSyZI/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Time-series processing and pattern segmentation methods for high-dimensional time-series&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oct 24, 2019: &lt;a href=&#34;https://docs.google.com/presentation/d/14DpPvt_SA3g4rUWlWP0PoHugRSS_VKWsagB_opDUxAQ/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;my class project slides&lt;/a&gt; and &lt;a href=&#34;https://github.com/martakarass/JHU-coursework/tree/master/PH-140-850-Wearables-Computing/class-project&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation</title>
      <link>/publication/adept/</link>
      <pubDate>Mon, 23 Sep 2019 18:08:38 -0400</pubDate>
      <guid>/publication/adept/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automatic estimation of step asymmetry in a split-belt treadmill experiment using high-resolution accelerometry data</title>
      <link>/talk/2019-06-26-icampam/</link>
      <pubDate>Wed, 26 Jun 2019 15:05:00 -0400</pubDate>
      <guid>/talk/2019-06-26-icampam/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Physical activity monitoring with wearable accelerometers: strides segmentation, gait pattern estimation and walking detection from free-living data in R. Also: highlights from RStudio 2019 conference.</title>
      <link>/talk/2019-05-23-stwur-meeting-talk/</link>
      <pubDate>Thu, 23 May 2019 18:00:00 -0400</pubDate>
      <guid>/talk/2019-05-23-stwur-meeting-talk/</guid>
      <description>&lt;p&gt;Slides from the talk part about RStudio 2019 conference can be found &lt;a href=&#34;https://martakarass.github.io/resources/computing_club_materials/2019-02-12-seen-at-rstudio2019-conf/#/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stride segmentation and stride pattern estimation based on accelerometry data</title>
      <link>/talk/2019-05-14-motion-lab-talk/</link>
      <pubDate>Tue, 14 May 2019 09:00:00 -0400</pubDate>
      <guid>/talk/2019-05-14-motion-lab-talk/</guid>
      <description>&lt;p&gt;Some picture from the talk was posted &lt;a href=&#34;https://twitter.com/jurbane2/status/1128290019217637376&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#39;adeptdata&#39; R package: Raw Accelerometry Data Sets and Their Derivatives</title>
      <link>/project/project_adeptdata/</link>
      <pubDate>Mon, 22 Apr 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_adeptdata/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;adeptdata&lt;/code&gt; was created to host raw accelerometry data sets and their derivatives. Some of them are used in the corresponding &lt;code&gt;adept&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Package CRAN index is located &lt;a href=&#34;https://cran.r-project.org/web/packages/adeptdata/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Package GitHub repo is located &lt;a href=&#34;https://github.com/martakarass/adeptdata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;Install from CRAN.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;adeptdata&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;data-objects&#34;&gt;Data objects&lt;/h1&gt;
&lt;h2 id=&#34;outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_walking_IU&lt;/code&gt; is a sample of raw accelerometry data collected during outdoor continuous walking from 32 healthy participants between 23 and 52 years of age. Data were collected at frequency 100 Hz simultaneously with four wearable accelerometers located at left wrist, left hip and both ankles. See &lt;code&gt;?acc_walking_IU&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(adeptdata)
library(dplyr)
library(ggplot2)
library(reshape2)
library(lubridate)

acc_walking_IU %&amp;gt;%
  filter(time_s &amp;lt; 6, subj_id == acc_walking_IU$subj_id[1]) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_wrist&amp;quot;, &amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;, &amp;quot;right_ankle&amp;quot;),
    labels = c(&amp;quot;Left wrist&amp;quot;, &amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;, &amp;quot;Right ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;subj_id&amp;quot;, &amp;quot;loc_id&amp;quot;, &amp;quot;time_s&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = time_s, y = value, color = variable)) + 
  geom_line() + 
  facet_wrap(~ loc_id, ncol = 2) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Exercise time [s]&amp;quot;, 
       y = &amp;quot;Amplitude [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data of walking (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;plot_acc_walking_IU.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_running&lt;/code&gt; is a sample raw accelerometry data collected during 25 minutes of an outdoor run. Data were collected at frequency 100 Hz with two ActiGraph GT9X Link sensors located at left hip and left ankle. See &lt;code&gt;?acc_running&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t1 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:07:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t2 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:20:30&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 
t3 &amp;lt;- ymd_hms(&amp;quot;2018-10-25 18:22:00&amp;quot;, tz = &amp;quot;UTC&amp;quot;) 

acc_running %&amp;gt;%
  filter((date_time &amp;gt;= t1 &amp;amp; date_time &amp;lt; t1 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t2 &amp;amp; date_time &amp;lt; t2 + as.period(4, &amp;quot;seconds&amp;quot;)) | 
           (date_time &amp;gt;= t3 &amp;amp; date_time &amp;lt; t3 + as.period(4, &amp;quot;seconds&amp;quot;)) ) %&amp;gt;%
  mutate(loc_id = factor(
    loc_id, 
    levels = c(&amp;quot;left_hip&amp;quot;, &amp;quot;left_ankle&amp;quot;),
    labels = c(&amp;quot;Left hip&amp;quot;, &amp;quot;Left ankle&amp;quot;))) %&amp;gt;%
  melt(id.vars = c(&amp;quot;date_time&amp;quot;, &amp;quot;loc_id&amp;quot;)) %&amp;gt;%
  mutate(date_time_floor = paste0(
    &amp;quot;Minute start: &amp;quot;, floor_date(date_time, unit = &amp;quot;minutes&amp;quot;))) %&amp;gt;%
  ggplot(aes(x = date_time, y = value, color = variable)) + 
  geom_line(size = 0.5) + 
  facet_grid(loc_id ~ date_time_floor, scales = &amp;quot;free_x&amp;quot;) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Acceleration [g]&amp;quot;, 
       color = &amp;quot;Sensor\naxis&amp;quot;,
       title = &amp;quot;Raw accelerometry data (100 Hz)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;acc_running.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;stride_template&lt;/code&gt; is a list containing walking stride pattern templates derived from accelerometry data collected at four body locations: left wrist, left hip, left ankle, and right ankle. See &lt;code&gt;?stride_template&lt;/code&gt; for details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data.frame(
  x = rep(seq(0, 1, length.out = 200), 2),
  y = c(stride_template$left_ankle[[2]][1, ],
        stride_template$left_ankle[[2]][2, ]),
  group = c(rep(1, 200), rep(2, 200))) %&amp;gt;%
  ggplot(aes(x = x, y = y, group = group)) + 
  geom_line() +
  facet_grid(group ~ .) + 
  theme_bw(base_size = 9) + 
  labs(x = &amp;quot;Time [s]&amp;quot;, 
       y = &amp;quot;Vector magnitude [g]&amp;quot;, 
       title = &amp;quot;Walking stride templates (left ankle)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;stride_template.jpeg&#34; width=&#34;50%&#34;&gt;
</description>
    </item>
    
    <item>
      <title>Simulation experiment project for Seminar on Adaptive Clinical Trials</title>
      <link>/talk/2019-04-16-adaptive-trials-semminar/</link>
      <pubDate>Wed, 17 Apr 2019 12:30:50 -0400</pubDate>
      <guid>/talk/2019-04-16-adaptive-trials-semminar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>&#39;runstats&#39; R package: Fast Computation of Running Statistics for Time Series</title>
      <link>/project/project_runstats/</link>
      <pubDate>Fri, 15 Mar 2019 11:54:53 -0400</pubDate>
      <guid>/project/project_runstats/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;runstats&lt;/code&gt; provides methods for fast computation of running sample statistics for time series. The methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT). Implemented running statistics include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mean,&lt;/li&gt;
&lt;li&gt;standard deviation,&lt;/li&gt;
&lt;li&gt;variance,&lt;/li&gt;
&lt;li&gt;covariance,&lt;/li&gt;
&lt;li&gt;correlation,&lt;/li&gt;
&lt;li&gt;euclidean distance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session info&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h1 id=&#34;website&#34;&gt;Website&lt;/h1&gt;
&lt;p&gt;Package website is located &lt;a href=&#34;https://martakarass.github.io/runstats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;runstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(runstats)

## Example: running correlation
x0 &amp;lt;- sin(seq(0, 2 * pi * 5, length.out = 1000))
x  &amp;lt;- x0 + rnorm(1000, sd = 0.1)
pattern &amp;lt;- x0[1:100]
out1 &amp;lt;- RunningCor(x, pattern)
out2 &amp;lt;- RunningCor(x, pattern, circular = TRUE)

## Example: running mean
x &amp;lt;- cumsum(rnorm(1000))
out1 &amp;lt;- RunningMean(x, W = 100)
out2 &amp;lt;- RunningMean(x, W = 100, circular = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;running-statistics&#34;&gt;Running statistics&lt;/h1&gt;
&lt;p&gt;To better explain the details of running statistics, package&amp;rsquo;s function &lt;code&gt;runstats.demo(func.name)&lt;/code&gt; allows to visualize how the output of each running statistics method is generated. To run the demo, use &lt;code&gt;func.name&lt;/code&gt; being one of the methods&#39; names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningMean&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningSd&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningVar&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCov&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCor&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningL2Norm&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running correlation method  
runstats.demo(&amp;quot;RunningCor&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_1.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Example: demo for running mean method 
runstats.demo(&amp;quot;RunningMean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;gif_2.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;performance&#34;&gt;Performance&lt;/h1&gt;
&lt;p&gt;We use &lt;code&gt;rbenchmark&lt;/code&gt; to measure elapsed time of &lt;code&gt;RunningCov&lt;/code&gt; execution, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter pattern &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rbenchmark)
library(ggplot2)

set.seed (20190315)
x.N.seq &amp;lt;- 10^(3:7)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))
y &amp;lt;- runif(100)

## Benchmark execution time of RunningCov 
out.df &amp;lt;- data.frame()
for (x.tmp in x.list){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df.tmp$pattern_length &amp;lt;- length(y)
  out.df &amp;lt;- rbind(out.df, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;knitr::kable(out.df)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;test&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;replications&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;elapsed&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;relative&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;user.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;sys.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;x_length&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;pattern_length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.003&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.023&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.019&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.183&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.148&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.035&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.700&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.592&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.107&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;19.852&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;17.185&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2.576&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/h2&gt;
&lt;p&gt;To compare &lt;code&gt;runstats&lt;/code&gt; performance with &amp;ldquo;conventional&amp;rdquo; loop-based way of computing running covariance in &lt;code&gt;R&lt;/code&gt;, we use &lt;code&gt;rbenchmark&lt;/code&gt; package to measure elapsed time of &lt;code&gt;runstats::RunningCov&lt;/code&gt; and running covariance implemented with &lt;code&gt;sapply&lt;/code&gt; loop, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter time-series &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Conventional approach 
RunningCov.sapply &amp;lt;- function(x, y){
  l_x &amp;lt;- length(x)
  l_y &amp;lt;- length(y)
  sapply(1:(l_x - l_y + 1), function(i){
    cov(x[i:(i+l_y-1)], y)
  })
}

out.df2 &amp;lt;- data.frame()
for (x.tmp in x.list[c(1:4)]){
  out.df.tmp &amp;lt;- benchmark(
    &amp;quot;conventional&amp;quot; = RunningCov.sapply(x.tmp, y),
    &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
    replications = 10,
    columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
  out.df.tmp$x_length &amp;lt;- length(x.tmp)
  out.df2 &amp;lt;- rbind(out.df2, out.df.tmp)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plt1 &amp;lt;- 
  ggplot(out.df2, aes(x = x_length, y = elapsed, color = test)) + 
  geom_line() + geom_point(size = 3) + scale_x_log10() + 
  theme_minimal(base_size = 14) + 
  labs(x = &amp;quot;Vector length of x&amp;quot;,
       y = &amp;quot;Elapsed [s]&amp;quot;, color = &amp;quot;Method&amp;quot;, 
       title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;, 
       subtitle = &amp;quot;Vector length of y = 100&amp;quot;) + 
  theme(legend.position = &amp;quot;bottom&amp;quot;)
plt2 &amp;lt;- 
  plt1 + 
  scale_y_log10() + 
  labs(y = &amp;quot;Log of elapsed [s]&amp;quot;, title = &amp;quot;&amp;quot;)

cowplot::plot_grid(plt1, plt2, nrow = 1, labels = c(&#39;A&#39;, &#39;B&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_conventional_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dvmisc&lt;/code&gt; package (&lt;a href=&#34;https://github.com/vandomed/dvmisc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/dvmisc/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;) is a package for &lt;em&gt;Convenience Functions, Moving Window Statistics, and Graphics&lt;/em&gt;, and includes functions for calculating moving-window statistics efficiently via c++, written by &lt;a href=&#34;https://vandomed.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dane Van Domelen&lt;/a&gt;. Here, we compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; performance with c++ implementation from &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt;. Dane contributed the code in its large part.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# devtools::install_github(&amp;quot;vandomed/dvmisc&amp;quot;)
library(dvmisc)

set.seed(20100315)
x.N.seq &amp;lt;- 10^(3:6)
x.list  &amp;lt;- lapply(x.N.seq, function(N) runif(N))

get.out.df &amp;lt;- function(y){
  out.df &amp;lt;- data.frame()
  for (x.tmp in x.list){
    if (length(x.tmp) &amp;lt; length(y)){
      out.df.tmp &amp;lt;- data.frame(
        test = NA,  replications = NA, elapsed = NA, relative = NA,
        user.self = NA, sys.self = NA)
    } else {
      out.df.tmp &amp;lt;- benchmark(
        &amp;quot;runstats&amp;quot; = runstats::RunningCov(x.tmp, y),
        &amp;quot;dvmisc&amp;quot; = dvmisc::sliding_cov(y, x.tmp), 
        replications = 10,
        columns = c(&amp;quot;test&amp;quot;, &amp;quot;replications&amp;quot;, &amp;quot;elapsed&amp;quot;,
                    &amp;quot;relative&amp;quot;, &amp;quot;user.self&amp;quot;, &amp;quot;sys.self&amp;quot;))
    }
    out.df.tmp$x_length &amp;lt;- length(x.tmp)
    out.df &amp;lt;- rbind(out.df, out.df.tmp)
  }
  return(out.df)
}

out.df_y10    &amp;lt;- get.out.df(runif(10^1))
out.df_y100   &amp;lt;- get.out.df(runif(10^2))
out.df_y1000  &amp;lt;- get.out.df(runif(10^3))
out.df_y10000 &amp;lt;- get.out.df(runif(10^4))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get.plt &amp;lt;- function(data, subtitle){
  ggplot(data, aes(x = x_length, y = elapsed, color = test)) + 
    geom_line() + geom_point(size = 3) + scale_x_log10() + 
    theme_minimal(base_size = 14) +  scale_y_log10() + 
    labs(x = &amp;quot;Vector length of x&amp;quot;,
         y = &amp;quot;Log of elapsed [s]&amp;quot;, 
         color = &amp;quot;Method&amp;quot;, 
         subtitle = subtitle) + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)
}

plt1 &amp;lt;- get.plt(out.df_y10, &amp;quot;Vector length of y = 10&amp;quot;) + 
  labs(title = &amp;quot;Running covariance (x,y) rbenchmark&amp;quot;)
plt2 &amp;lt;- get.plt(out.df_y100,   &amp;quot;Vector length of y = 100&amp;quot;)
plt3 &amp;lt;- get.plt(out.df_y1000,  &amp;quot;Vector length of y = 1,000&amp;quot;)
plt4 &amp;lt;- get.plt(out.df_y10000, &amp;quot;Vector length of y = 1,0000&amp;quot;)

cowplot::plot_grid(plt1, plt2, plt3, plt4, nrow = 2, labels = c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;benchmark_compare_dvmisc_plot_results-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;session-info&#34;&gt;Session info&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessioninfo::session_info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    ## ─ Session info ───────────────────────────────────────────────────────────────
    ##  setting  value                       
    ##  version  R version 3.5.2 (2018-12-20)
    ##  os       macOS Mojave 10.14.2        
    ##  system   x86_64, darwin15.6.0        
    ##  ui       X11                         
    ##  language (EN)                        
    ##  collate  en_US.UTF-8                 
    ##  ctype    en_US.UTF-8                 
    ##  tz       America/New_York            
    ##  date     2019-11-14                  
    ## 
    ## ─ Packages ───────────────────────────────────────────────────────────────────
    ##  package     * version date       lib source        
    ##  assertthat    0.2.1   2019-03-21 [1] CRAN (R 3.5.2)
    ##  cli           1.1.0   2019-03-19 [1] CRAN (R 3.5.2)
    ##  colorspace    1.4-1   2019-03-18 [1] CRAN (R 3.5.2)
    ##  crayon        1.3.4   2017-09-16 [1] CRAN (R 3.5.0)
    ##  digest        0.6.22  2019-10-21 [1] CRAN (R 3.5.2)
    ##  dplyr         0.8.3   2019-07-04 [1] CRAN (R 3.5.2)
    ##  evaluate      0.14    2019-05-28 [1] CRAN (R 3.5.2)
    ##  fftwtools     0.9-8   2017-03-25 [1] CRAN (R 3.5.0)
    ##  ggplot2     * 3.2.1   2019-08-10 [1] CRAN (R 3.5.2)
    ##  glue          1.3.1   2019-03-12 [1] CRAN (R 3.5.2)
    ##  gtable        0.3.0   2019-03-25 [1] CRAN (R 3.5.2)
    ##  htmltools     0.3.6   2017-04-28 [1] CRAN (R 3.5.0)
    ##  knitr         1.26    2019-11-12 [1] CRAN (R 3.5.2)
    ##  lazyeval      0.2.2   2019-03-15 [1] CRAN (R 3.5.2)
    ##  magrittr      1.5     2014-11-22 [1] CRAN (R 3.5.0)
    ##  munsell       0.5.0   2018-06-12 [1] CRAN (R 3.5.0)
    ##  pillar        1.4.2   2019-06-29 [1] CRAN (R 3.5.2)
    ##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 3.5.2)
    ##  purrr         0.3.3   2019-10-18 [1] CRAN (R 3.5.2)
    ##  R6            2.4.1   2019-11-12 [1] CRAN (R 3.5.2)
    ##  rbenchmark  * 1.0.0   2012-08-30 [1] CRAN (R 3.5.0)
    ##  Rcpp          1.0.3   2019-11-08 [1] CRAN (R 3.5.2)
    ##  rlang         0.4.1   2019-10-24 [1] CRAN (R 3.5.2)
    ##  rmarkdown     1.15    2019-08-21 [1] CRAN (R 3.5.2)
    ##  rstudioapi    0.10    2019-03-19 [1] CRAN (R 3.5.2)
    ##  runstats    * 1.1.0   2019-11-14 [1] CRAN (R 3.5.2)
    ##  scales        1.0.0   2018-08-09 [1] CRAN (R 3.5.0)
    ##  sessioninfo   1.1.1   2018-11-05 [1] CRAN (R 3.5.0)
    ##  stringi       1.4.3   2019-03-12 [1] CRAN (R 3.5.2)
    ##  stringr       1.4.0   2019-02-10 [1] CRAN (R 3.5.2)
    ##  tibble        2.1.3   2019-06-06 [1] CRAN (R 3.5.2)
    ##  tidyselect    0.2.5   2018-10-11 [1] CRAN (R 3.5.0)
    ##  withr         2.1.2   2018-03-15 [1] CRAN (R 3.5.0)
    ##  xfun          0.11    2019-11-12 [1] CRAN (R 3.5.2)
    ##  yaml          2.2.0   2018-07-25 [1] CRAN (R 3.5.0)
    ## 
    ## [1] /Library/Frameworks/R.framework/Versions/3.5/Resources/library
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Some of the topics seen at RStudio conference 2019</title>
      <link>/talk/2019-02-12-computing_club/</link>
      <pubDate>Tue, 12 Feb 2019 12:15:50 -0500</pubDate>
      <guid>/talk/2019-02-12-computing_club/</guid>
      <description>&lt;p&gt;Ben&amp;rsquo;s tweet thread with some pics from the talk: &lt;a href=&#34;https://twitter.com/backerman150/status/1095373237641449473&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[link]&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JH Biostat Computing Club 2018-19</title>
      <link>/resources/computing-club/</link>
      <pubDate>Sat, 26 Jan 2019 19:17:23 -0400</pubDate>
      <guid>/resources/computing-club/</guid>
      <description>&lt;p&gt;I and &lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/directory/students/phd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Guoqing Wang&lt;/a&gt; hosted the Department of Biostatistics students Computing Club in 2018-19 academic year.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Computing Club is one-hour session which gives students opportunities to share and develop computing skills useful for biostatisticians. It is held every other Tuesday 12:15-1:15 PM at JH SPH. Importantly, food 🍕🍌 is provided in every session!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Past and upcoming topics and locations for 2018-19 academic year are listed below.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Date (Location)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Topic&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Presenter&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sep 18, 2018 (E9519)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Data science project workflow (&lt;a href=&#34;http://www.benjaminackerman.com/files/biostat_computing_club_slides.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;http://www.benjaminackerman.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ben Ackerman&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Oct 16, 2018 (W2029)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The JHPCE Cluster: What does it do? Does it do things? Let&amp;rsquo;s find out! (&lt;a href=&#34;https://github.com/jfiksel/cluster-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cluster-example GitHub repo&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://github.com/jfiksel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jacob Fiksel&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nov 13, 2018 (E9519)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;R Packages for the first year PhD curriculum (useful for non-phd students too!)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/directory/students/phd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lacey Etzkorn&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nov 27, 2018 (W4030)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Speeding up R with Rcpp (&lt;a href=&#34;https://github.com/scristia/ComputingClubRcpp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;talk GitHub repo&lt;/a&gt;, &lt;a href=&#34;https://github.com/scristia/ComputingClubRcpp/blob/master/slides/rcpp_presentation.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;talk slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/directory/students/phd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stephen Cristiano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Jan 29, 2019 (W2029)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Intro to Deep Learning (&lt;a href=&#34;../../resources/computing_club_materials/2019-01-29-deep-learning&#34;&gt;slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/directory/students/phd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Guoqing Wang&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Feb 12, 2019 (E9519)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Some topics seen at RStudio 2019 conference (&lt;a href=&#34;../../resources/computing_club_materials/2019-02-12-seen-at-rstudio2019-conf&#34;&gt;slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://martakarass.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Marta Karas&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Feb 26, 2019 (W2029)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Blogdown tutorial: how to make your own personal academic website! (&lt;a href=&#34;http://www.benjaminackerman.com/talk/computing_club_website_tutorial/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;abstract and slides link&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;http://www.benjaminackerman.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ben Ackerman&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Apr 16, 2019 (W4030)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Computational and statistical methods in single-cell genomics (&lt;a href=&#34;/docs/slides/2019-04-16-comouting-club-ji_slides.pdf&#34;&gt;slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~zji4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zhicheng (Jason) Ji&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Apr 30, 2019 (W4030)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Simulation studies on the cluster, and parallel computing in R with limited memory (&lt;a href=&#34;/docs/slides/2019-04-20-LamarComputingClub.pdf&#34;&gt;slides&lt;/a&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://lamarhuntiii.com/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lamar Hunt&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Links to the previous years&#39; Computing Club could be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2017-18: -&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~ydu/comp_club.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2016-17&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.junruidi.com/compclub.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-16&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014-15: - (overwritten by 2016-17)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~jbai/compclub.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2013-14&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~afisher/ComputingClub/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2012-13&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~afrazee/old/computingclub.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2011-12&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2010-11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/index_0910.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2009-10&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/index_0809.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2008-09&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/index_0708.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2007-08&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/index_0607.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2006-07&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/bit/compintro/index_0506.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2005-06&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Some of the topics seen at RStudio conference 2019</title>
      <link>/post/2019-01-26-favs-of-rstudio2019-conference/</link>
      <pubDate>Sat, 26 Jan 2019 19:17:23 -0400</pubDate>
      <guid>/post/2019-01-26-favs-of-rstudio2019-conference/</guid>
      <description>&lt;p&gt;I spent the last days of 2018-19 winter break in Austin, TX where I traveled for RStudio 2019 conference. I attended e-poster session and two days of the conference: Jan 17-18. Below I list some of the topics from the talks that I particularly liked and I think I am likely to benefit from in the future.&lt;/p&gt;
&lt;p&gt;Also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The official repo with abstracts for every session, workshop (together with &lt;strong&gt;workshop files free to download&lt;/strong&gt; for most if not all of them), and e-poster can be accessed &lt;a href=&#34;https://github.com/rstudio/rstudio-conf/tree/master/2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;&lt;/nav&gt;
&lt;h1 id=&#34;data-visualization&#34;&gt;Data visualization&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tyler Morgan-Wall (&lt;a href=&#34;http://www.tylermw.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/tylermorganwall&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) showing stunning gifs and pics while presenting &amp;ldquo;&lt;em&gt;3D mapping, plotting, and printing with rayshader&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Features showed include shadowing, rotating, water transparency, visualization of a simulation of different water levels. The talk had possibly the most exciting &amp;ldquo;future work&amp;rdquo; announced - because who doesn&amp;rsquo;t get excited about the idea of &amp;ldquo;rotating 3D ggplots&amp;rdquo;? 💘 The &lt;code&gt;rayshader&lt;/code&gt; package is available on GitHub (&lt;a href=&#34;https://github.com/tylermorganwall/rayshader&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;).&lt;/p&gt;
  &lt;table style=&#34;table-layout:fixed&#34;&gt;
  &lt;col style=&#34;width:100%&#34; span=&#34;2&#34; /&gt;
  &lt;tr&gt;
  &lt;td&gt; &lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/tyler.gif&#34; alt=&#34;Drawing&#34; style=&#34;width: 100%;&#34;/&gt; &lt;/td&gt;
  &lt;td&gt; &lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/tyler2.png&#34;  alt=&#34;Drawing&#34; style=&#34;weight: 100%;&#34;/&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;/table&gt;
&lt;p&gt;&lt;sub&gt;&lt;sup&gt;(The gif on the left and the image on the right are both sourced from &amp;lsquo;rayshader&amp;rsquo; package GitHub website (&lt;a href=&#34;https://github.com/tylermorganwall/rayshader&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), as accessed on Jan 26, 2019.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Thomas Lin Pedersen (&lt;a href=&#34;https://www.data-imaginist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/thomasp85&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) giving a &amp;ldquo;&lt;em&gt;gganimate live cookbook&lt;/em&gt;&amp;rdquo; speech (and joining Tyler&amp;rsquo;s talk on the podium of most fun presentations, I guess 😂)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;gganimate&lt;/code&gt; package was introduced per &amp;ldquo;&lt;em&gt;extension to ggplot2&lt;/em&gt;&amp;rdquo; providing &amp;ldquo;&lt;em&gt;implementation of the grammar of animated graphics&lt;/em&gt;&amp;rdquo;. Presentation slides are available online  &lt;a href=&#34;https://www.data-imaginist.com/slides/rstudioconf2019/assets/player/keynotedhtmlplayer#1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;; IMHO worth checking out for inspiring ways of presenting data over time! Besides, &lt;a href=&#34;https://gganimate.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gganimate.com&lt;/a&gt; comes with a bunch of examples, like the one below.&lt;/p&gt;
  &lt;table style=&#34;table-layout:fixed&#34;&gt;
  &lt;col style=&#34;width:100%&#34;  /&gt;
  &lt;tr&gt; 
   &lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/thomas.gif&#34;  alt=&#34;Drawing&#34; style=&#34;weight: 100%;&#34;/&gt; 
  &lt;/tr&gt;
  &lt;/table&gt;
&lt;p&gt;&lt;sub&gt;&lt;sup&gt;(The gif sourced from &amp;lsquo;gganimate&amp;rsquo; package website (&lt;a href=&#34;https://gganimate.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), as accessed on Jan 26, 2019.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;documents-building&#34;&gt;Documents building&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Yihui Xie (&lt;a href=&#34;https://yihui.name/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/xieyihui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) leaving the audience very enthusiastic (or maybe more like: blown away) with all the recent development in document building.&lt;/p&gt;
&lt;p&gt;The presentation starts with &amp;ldquo;In HTML and the Web I trust&amp;rdquo; (😍 I share like 99% of my work summaries with advisors and colleagues in a form HTML). With &lt;code&gt;pagedown&lt;/code&gt; we can now go ahead and get &lt;em&gt;&lt;strong&gt;paged&lt;/strong&gt;&lt;/em&gt; HTML documents, e.g. business card, resume, poster. Fairly 👶 development (&amp;quot;&lt;em&gt;status: experimental&lt;/em&gt;&amp;quot;).
Presentation slides are available &lt;a href=&#34;https://slides.yihui.name/2019-rstudio-conf-pagedown.html#1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/yihui.jpg&#34; alt=&#34;&#34;&gt;
&lt;sub&gt;&lt;sup&gt;(Slides 10, 11, 15, 17 from RStudio 2019 conference talk &amp;ldquo;pagedown: Creating Beautiful PDFs with R Markdown + CSS + Your Web Browser&amp;rdquo; by Yihui Xie and Romain Lesur on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich Iannone (&lt;a href=&#34;http://rich-iannone.github.io/DiagrammeR/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/riannone&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) introducing the &lt;code&gt;gt&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;gt&lt;/code&gt; package (&lt;a href=&#34;https://github.com/rstudio/gt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), one can turn a data table into &amp;ldquo;&lt;em&gt;information-rich, publication-quality&lt;/em&gt;&amp;rdquo; 🎯 table outputs. The table outputs can be in HTML, LaTeX, and RTF. The &amp;ldquo;modular&amp;rdquo; way of building these reminds me of ggplot2 plots construction. Presentation slides are available &lt;a href=&#34;https://github.com/rich-iannone/presentations/tree/master/2019_01-19-rstudio_conf_gt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/rich2.png&#34; alt=&#34;&#34;&gt;
&lt;sub&gt;&lt;sup&gt;(Slide 5. from RStudio 2019 conference talk &amp;ldquo;Introducing the &amp;lsquo;gt&amp;rsquo; package&amp;rdquo; by Rich Iannone on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;community-and-personal-development&#34;&gt;Community and personal development&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;David Robinson (&lt;a href=&#34;http://varianceexplained.org/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/drob&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) delivering a keynote talk &amp;ldquo;The unreasonable effectiveness of public work&amp;rdquo; (&lt;a href=&#34;https://bit.ly/drob-rstudio-2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;IMHO a phenomenal speech: a kind and resonating talk after which one not only wants to stand up and change the world right now 🔥 but also maintains the same feeling a week after 💪. Review the slides to: (a) learn Author&amp;rsquo;s points on why it so worth it to spend time on public work, (b) for a pack of actual how-to examples and guidelines on building a public portfolio, (c) for a bunch of interesting points made about a value of work (Author&amp;rsquo;s work, but fairly generalizable IMHO); my favorite is copy-pasted below! I particularly appreciated that all stages of advancement in building online portfolio were addressed, 👶-steps including!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/david1.png&#34; alt=&#34;&#34;&gt;
&lt;sub&gt;&lt;sup&gt;(Slide 63. from RStudio 2019 conference keynote talk &amp;ldquo;The unreasonable effectiveness of public work&amp;rdquo; by David Robinson on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jesse Mostipak (&lt;a href=&#34;https://www.jessemaegan.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/kierisi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) talking about the experience of building R4DS online learning community.&lt;/p&gt;
&lt;p&gt;Some empowering messages came in the lines of this talk - just look at the slides pics below to get the flavor 🙌. My take-home ones include a description of a data scientist: &amp;ldquo;&lt;em&gt;constantly learning, constantly making mistakes, constantly learning from them&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/2019-01-26-favs-of-rstudio2019-conference/jesse_b.jpg&#34; alt=&#34;&#34;&gt;
&lt;sub&gt;&lt;sup&gt;(Pictures I took during RStudio 2019 conference talk &amp;ldquo;R4DS online learning community&amp;rdquo; by Jesse Mostipak on Jan 17, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Accelerometry Data in Health Research - Challenges and Opportunities. Review and Examples</title>
      <link>/publication/accelerometry-data-in-health-research/</link>
      <pubDate>Sat, 12 Jan 2019 18:08:38 +0000</pubDate>
      <guid>/publication/accelerometry-data-in-health-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[in Polish] Aplikacja na studia doktoranckie (Biostatystyka) w USA: notatki nt. procesu rekrutacji</title>
      <link>/post/2018-09-02-applying-for-phd-in-usa/</link>
      <pubDate>Sun, 02 Sep 2018 19:17:23 -0400</pubDate>
      <guid>/post/2018-09-02-applying-for-phd-in-usa/</guid>
      <description>&lt;p&gt;W 2015 roku zdobylam tytul Magister na kierunku Matematyka na Politechnice Wroclawskiej. W sierpniu 2016 rozpoczelam aplikacje na programy doktoranckie na kierunku Biostatystyka w Stanach Zjednoczonych rozpoczynajace sie jesienia 2017. Dostalam i zaakeptowalam oferte z &lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Departamentu Biostatystyki&lt;/a&gt; na &lt;a href=&#34;https://www.jhsph.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Johns Hopkins Bloomberg School of Public Health&lt;/a&gt; w Baltimore (stan Maryland), oferujacego jeden z 3 najlepszych (ex aequo) programow na kierunku Biostatystyka w USA wg &lt;a href=&#34;https://www.usnews.com/best-graduate-schools/top-science-schools/statistics-rankings&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rankingu usnews.com&lt;/a&gt; z 2018 roku. W notatce opisuje etapy rekrutacji i podaje swoje obserwacje i wskazowki.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;&lt;/nav&gt;
&lt;h1 id=&#34;uwagi-wstepne&#34;&gt;Uwagi wstepne&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w kontekscie aplikacji na kierunek Biostatystyka.&lt;/strong&gt; &lt;em&gt;Spodziewam sie&lt;/em&gt;, ze aplikacje na inne (w szczegolnosci: zblizone tematycznie) programy moga przebiegac &lt;em&gt;podobnie&lt;/em&gt;, jednoczesnie nigdy nie zrobilam porownania. Przykladowa roznica o ktorej wiem, ze istnieje: na programy PhD na kierunku Biostatystyka &lt;em&gt;aplikuje sie ogolnie&lt;/em&gt; na program i po 0-2 latach &lt;em&gt;okresla lub zaweza&lt;/em&gt; obszar badawczy i jednoczesnie decyduje na konkretnych opiekunow naukowych (w tym: promotora/promotorow); typowe dla niektorych innych kierunkow STEM jest z kolei &lt;em&gt;aplikowanie do konkretnego laboratorium (czesto: pod opieke naukowa konkretnego profesora)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w oparciu o tylko i wylacznie moje doswiadczenia&lt;/strong&gt; (za wyjatkiem miejsc, gdzie zaznaczam explicite, ze wiem cos ze slyszenia od innych studentow).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w kontekscie aplikacji na programy rozpoczynajace sie jesienia 2017&lt;/strong&gt;, wypelnianymi zgodnie z wymaganiami i terminami, ktorych pilnowalam aplikujac w 2016. Nie sprawdzilam, czy i co zmienilo sie od tego czasu.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wyodrebniam nastepujace glowne komponenty procesu aplikacji:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wstepny wybor uczelni i zbudowanie planu czasowego procesu aplikacji&lt;/li&gt;
&lt;li&gt;Przygotowanie do egzaminow: GRE + TOEFL&lt;/li&gt;
&lt;li&gt;Przygotowanie Personal Statement&lt;/li&gt;
&lt;li&gt;Zorganizowanie listow rekomendacyjnych&lt;/li&gt;
&lt;li&gt;Networking&lt;/li&gt;
&lt;li&gt;Aplikowanie: wykonanie i nadzorowanie post-procesu&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;1-wstepny-wybor-uczelni-i-zbudowanie-planu-czasowego-timeline-aplikacji&#34;&gt;1. Wstepny wybor uczelni i zbudowanie planu czasowego timeline aplikacji&lt;/h1&gt;
&lt;p&gt;Generalne ramy czasowe.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uczelnie roznia sie datami ostatecznego terminu aplikacji, jednoczesnie daty te  zjezdzaja sie na przestrzeni ok. 1,5 miesiaca: od 1. grudnia roku N do polowy stycznia roku (N+1) na programy rozpoczynajace sie jesienia roku (N+1). 60% terminow to wlasnie 1. grudnia. 📣&lt;/li&gt;
&lt;li&gt;Stad &lt;strong&gt;prace nad aplikacjami zaczynamy &lt;em&gt;najpozniej&lt;/em&gt; 12-14 miesiecy przed&lt;/strong&gt; faktycznym rozpoczeciem studiow.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wstepny wybor uczelni.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wybieralam uczelnie na podstawie: a) rankingow programu Biostatystyka (podzbior &amp;ldquo;Biostatystyka&amp;rdquo;  z &lt;a href=&#34;https://www.usnews.com/best-graduate-schools/top-science-schools/statistics-rankings&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;usnews.com&lt;/a&gt;; w 2016 korzystalam glownie z &lt;a href=&#34;http://www.amstat.org/asa/files/pdfs/OGRP-USNews_BioStatisticsRankings.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tego&lt;/a&gt; dokumentu); b) rozmow z profesorami i studentami w USA w czasie pracy jako Research Assistant na Indiana University w pierwszej polowie 2016; c) przegladania grup naukowych i zainteresowan profesorow na stronach uczelni; d) lokalizacji; tu: zarowno ogolny obszar USA jak i konkretne miasto (przyklad: nie chcialam studiowac w NYC).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bylo mi ciezko ocenic a priori, w jaki sposob moja aplikacja bedzie ewaluowana przez komitety rekrutacyjne na uczelniach w USA.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aplikacja studenta z Polski na Biostatystyke u USA to wciaz egzotyczna sprawa. Komisje rekrutacyjne sa najczesniej niezaznajomione z polskim systemem szkolnictwa wyzszego (gdzie sa np. z chinskimi i hinduskimi), stad ocena &amp;ldquo;5.0&amp;rdquo; z Analizy matematycznej I na Politechnice Wroclawskiej  nie mowi im bardzo duzo na temat tego, co w zwiazku z tym powinnam umiec. (Przyklad: w czasie etapu rekrutacji &amp;ldquo;on site&amp;rdquo; na jednej z uczelni Ivy League, dziekan departamentu Biostatystyki, z ktorym mialam 20-minutowe spotkanie, poprosil mnie o chocby ogolny opis tego &amp;ldquo;jak wygladaly moje studia w Polsce&amp;rdquo; 👽).  &lt;br/&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aplikowalam do 16 uczelni&lt;/strong&gt; (relatywnie wielu), &lt;strong&gt;wg nastepujacego schematu&lt;/strong&gt;:  1/3 uczelni na liscie to &amp;ldquo;dream schools&amp;rdquo; - uczelnie z czolowki rankingow programu Biostatystyka; 1/3 to uczelnie &amp;ldquo;safe&amp;rdquo; - spodziewam sie, ze mam spore szanse sie tam dostac; 1/3 to uczelnie &amp;ldquo;po srodku&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dostalam sie / dostalam zaproszenie do 2. etapu rekrutacji od nieco &lt;strong&gt;ponad 50% z uczelni&lt;/strong&gt;, do ktorych aplikowalam (2. etap to zaproszenie na rozmowe &amp;ldquo;on site&amp;rdquo; lub jego odpowiednik dla studentow przebywajacych poza USA: rozmowa telefoniczna z czlonkami komitetu rekrutacyjnego; w kilku przypadkach nie kontynuowalam procesu do 2. etapu wiedzac, ze dostalam sie juz do miejsca wyzej na liscie moich preferencji).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Co interesujace, uczelnie, ktore byly mna zainteresowanie, to niemal dokladnie: polowa uczelni z grupy &amp;ldquo;dream schools&amp;rdquo; + polowa z &amp;ldquo;safe&amp;rdquo; + polowa z &amp;ldquo;po srodku&amp;rdquo; 👏👍&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Plan czasowy procesu aplikacji powinien zawierac:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Daty &lt;strong&gt;ostatecznego terminu aplikacji&lt;/strong&gt; (&amp;ldquo;deadline&amp;rdquo;) do wybranych uczelni, tzn. daty, po ktorych zamykaja sie systemy online umozliwiajace wykonanie aplikacji.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Liste &lt;strong&gt;wymaganych egzaminow&lt;/strong&gt; i najdalszy termin ich realizacji (np. w Polsce), ktory zapewnia bezpieczne okno czasowe na przeslanie wynikow do uczelni. Najczesciej beda to dwa egzaminy: TOEFL i GRE General.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wyniki TOEFL i GRE General wysylane sa automatycznie do uczelni, ktorych liste zadeklarujemy przy zapisie na egzamin lub ktore dodamy kiedykolwiek pozniej przy uzyciu systemow online do zarzadzania wynikami. Zwyczajnie trzeba przypilnowac, czy dni robocze, ktore organizator daje sobie na a) sprawdzenie egzaminu + b) wyslanie wynikow do uczelni, dodaja nam sie z ostatecznymi terminami aplikacji. &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Okno czasowe na &lt;strong&gt;tlumaczenie przysiegle&lt;/strong&gt; oraz &lt;strong&gt;przeewaluowanie i/lub wyslanie poczta transkryptow ocen&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Przyklady tego, co moze nas &amp;ldquo;zaskoczyc&amp;rdquo;. a) ~5 uczelni wymagalo wyslania tlumaczonych (tl. przysiegly) transkryptow ocen fizycznie na adres uczelni w USA (w kilku przypadkach: w terminie wczesniejszym, niz generalny ostateczny termin aplikacji podany na stronie uczelni). b) ~7 uczelni realizowalo aplikacje przez system &lt;a href=&#34;https://sophas.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOPHAS&lt;/a&gt; - jednolity system aplikacji na wydzialy Zdrowia Publicznego (&amp;ldquo;School of Public Health&amp;rdquo;) w USA, z ktorych korzysta czesc uczelni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SOPHAS jest dla aplikanta wygodny o tyle, ze duza czesc dokumentow ladujemy do systemu tylko raz, niezaleznie od liczby uczelni na ktore aplikujemy via SOPHAS. Z drugiej strony, SOPHAS akceptuje zagraniczne transkrypty ocen tylko i wylacznie po przeewaluowaniu ich na system amerykanski przez World Education Services (&lt;a href=&#34;https://www.wes.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WES&lt;/a&gt;). Musimy wiec wyslac do WES komplet swoich przetlumaczonych (tl. przysiegly 👼) transkryptow, a WES je ewaluuje i wysyla wyniki do SOPHAS. (To byl dla mnie najbardziej stresujacy element tego etapu rekrutacji: WES nie zrealizowal ewaluacji moich ocen w oknie czasowym, ktore deklaruje od momentu zmiany statusu mojej sprawy na &amp;ldquo;otrzymalismy twoje transkrypty&amp;rdquo;; pomimo moich prosb, &amp;ldquo;grozb&amp;rdquo; i placzu, dokumenty zostaly wyslane dopiero na kilka dobrych dni po deklarowanym terminie 🐢, szczesliwie dokladnie &amp;ldquo;na styk&amp;rdquo; z ostatecznymi terminami aplikacji do kilku uczelni. 🎣)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wybor uczelni i organizowanie planu czasowy procesu aplikacji sa ze soba powiazane: specyficzne wymagania i terminy poszczegolnych uczelni wymuszaja plan czasowy, natomiast wymagania czasowe modyfikowaly moje wybory uczelni (przyklad: widzialam, ze nie dam rady czasowo przygotowac sie do egzaminu GRE Mathematics; z drugiej strony, jako ze duza czesc moich dokumentow typowo potrzebnych do aplikacji byla juz w SOPHAS, zaaplikowalam do kilku dodatkowych uczelni via SOPHAS).&lt;/p&gt;
&lt;h1 id=&#34;2-przygotowanie-do-egzaminow-gre-general--toefl&#34;&gt;2. Przygotowanie do egzaminow: GRE General + TOEFL&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GRE General jest niezbedny&lt;/strong&gt; do aplikowania na studia &amp;ldquo;graduate&amp;rdquo; (Masters / PhD) w USA. W nielicznych przypadkach &lt;em&gt;wymagany&lt;/em&gt; jest rowniez GRE specjalistyczny (Stanford: GRE Mathematics Subject Test). &lt;strong&gt;Egzamin jezykowy&lt;/strong&gt; jest wymagany dla absolwentow uczelni, na ktorych jezyk angielski nie jest podstawowym jezykiem wykladowym. W USA wymaganym standardowo egzaminem jezykowym jest TOEFL (w niektorych szkolach zamienny z IELTS, w niektorych nie).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zdawalam GRE General i TOEFL. Oba egzaminy zdawalam w Polsce (najpierw GRE General w Krakowie, tydzien pozniej: TOEFL w Poznaniu).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Przejscie przez przewodnik po typach zadan&lt;/strong&gt; na obu egzaminach &lt;strong&gt;to absolutne minimum&lt;/strong&gt; w przygotowaniach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje przeznaczyc 90-95% czasu przygotowan do obu egzaminow na GRE General.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GRE General sklada sie z ~5 komponentow testujacych dwa obszary: j. angielski i matematyke. Czesc matematyczna jest prosta (poziom matury podstawowej z matematyki), jednoczesnie nalezy zalozyc duzo czasu na przygotowanie sie pod bardzo konkretna forme tego egzaminu. Jest &lt;em&gt;bardzo&lt;/em&gt; malo miejsca na jakiekolwiek pomylki, w szczegolnosci: bledy przy pierwszych zadaniach (poziom trudnosci zadan rosnie z biegiem czasu egzaminu), stad trzeba wyklepac do stanu &amp;ldquo;rozwiazuje z automatu&amp;rdquo; problemy pojawiajace sie na czesci matematycznej. Wlasnosci katow w trojkacie wpisanym i opisanym na okregu 💘, zadania &amp;ldquo;z dwoma pociagami&amp;rdquo;, te sprawy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GRE General cz. jezykowa sklada sie zadan testujacych umiejetnosc krytycznego myslenia i argumentowania w formie pisemnej oraz z zadan testujacych slownictwo. Czesc testujaca slownictwo jest moim zdaniem zwyczajnie nierobialna i ze swojej perspektywy oceniam, ze nie ma duzej roznicy, czy przeznaczy sie na nauke slowek 10h czy 300h przed egzaminem, tu trzeba isc do kosciola i pomodlic sie o celnosc strzalow w odpowiedziach. Na serio: przygotowanie do GRE General cz. jezykowa jest  czasochlonne. 😐 Pomocne: w internecie sa dostepne roznej dlugosci listy &amp;ldquo;slownictwa na GRE&amp;rdquo; oraz dedykowane aplikacje do nauki &amp;ldquo;slowek na GRE&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Po napisaniu GRE General cz. jezykowa, poziom TOEFL wydaje sie latwy, a sam egzamin - przyjemny 😌.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje nie zdawac obu egzaminow w jeden weekend; w szczegolnosci GRE jest bardzo wyczerpujacy (mysle, ze to byl najbardziej wyczerpujacy egzamin w moim zyciu; po wyjsciu z sali przez kilka minut zbieralam mysli o tym co to sie robilo zeby zamowic Ubera) 🚀.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;3-przygotowanie-personal-statement&#34;&gt;3. Przygotowanie Personal Statement&lt;/h1&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt;Nota bene: transkrypty ocen i wyniki z egzaminow sluza glownie do wyznaczenia punktu odciecia, ponizej ktorego &amp;ldquo;uczelnia generalnie nie rozmawia z potencjalnym studentem&amp;rdquo;.&lt;/span&gt; Latwo wyobrazic sobie, ze punkt odciecia przekracza wielu bardzo dobrych studentow (podpowiadam przypomniec sobie populacje np. Chin i Indii). &lt;span style=&#34;color:red&#34;&gt;To, czym &amp;ldquo;kupujemy&amp;rdquo; sobie przychylnosc komisji rekrutacyjnej i zdobywamy oferte programu, to &lt;strong&gt;kombinacja zawartosci CV, Personal Statement, listow rekomendacyjnych i naszego networkingu&lt;/strong&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Personal Statement (zamiennie: Statement of Purpose) to wazny dokument, ktorego szablon - wersje beta tworzylam przez kilka dni z rzedu.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Szablon mojego Personal Statement mial 2 pelne strony A4 i skladal sie z  nastepujacych paragrafow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;chwytliwe otwarcie, w ktorym wzbudzam zainteresowanie swoja motywacja i indywidualna historia,&lt;/li&gt;
&lt;li&gt;notka biograficzna, skupiajaca sie na doswiadczeniu w badaniach naukowych (poparte konkretnymi przykladami),&lt;/li&gt;
&lt;li&gt;notka biograficzna, skupiajaca sie na cechach osobowosciowych, ktore predestynuja mnie do bycia odnoszacym sukcesy studentem (poparte konkretnymi przykladami),&lt;/li&gt;
&lt;li&gt;motywacja do studiowania kierunku Biostatystyka,&lt;/li&gt;
&lt;li&gt;&amp;ldquo;big-picture&amp;rdquo; tego, co chce osiagnac dzieki studiom PhD - na przestrzeni studiow i calego zycia,&lt;/li&gt;
&lt;li&gt;motywacja do studiowania kierunku Biostatystyka na tej konkretnej uczelni,&lt;/li&gt;
&lt;li&gt;zgrabne zakonczenie.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sugestie:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;W Personal Statement nie ma miejsca na &amp;ldquo;chcialem byc marynarzem chcialem miec tatuaze podrozowac&amp;rdquo;. Wszystko, co tam wrzucamy tytulem osiagniec i aktywnosci, powinno byc poparte/umotywowane konkretnymi wydarzeniami z zycia akademickiego/poza-akademickiego.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;W Personal Statement nie ma miejsca na bycie skromnym. Inni aplikanci nie beda skromni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Warto zgooglowac, jakie elementy &lt;em&gt;powinny zawsze&lt;/em&gt; znalezc sie w tym dokumencie - czesto uczelnie zamieszczaja te infromacje na swoich podstronach dot. rekrutacji. Jednoczesnie sugeruje NIE szukac i NIE &amp;ldquo;inspirowac sie&amp;rdquo; gotowymi dokumentami instniejacymi w sieci; im bardziej &amp;ldquo;twoj&amp;rdquo; jest Personal Statement, tym lepiej.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje szablon &lt;strong&gt;dac do sprawdzenia 3-5 znajomym&lt;/strong&gt; 🙏 pod katem tresci; wyszlifowana tresciowo wersje sugeruje dac do sprawdzenia pod wzgledem jezykowym dobremu tlumaczowi. Do sprawdzenia (i do tlumaczenia transkryptow) polecam Panie z &lt;a href=&#34;http://www.btcentrum.pl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BT Centrum we Wroclawiu&lt;/a&gt; - absolutnie profesjonale i elastyczne, de facto &amp;ldquo;uratowaly&amp;rdquo; moje aplikacje (a mogly wysmiac mnie w progu za termin, w ktorym potrzebowalam miec gotowe tlumaczenia: &amp;ldquo;na jutro&amp;rdquo; 🐩).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;4-listy-rekomendacyjne&#34;&gt;4. Listy rekomendacyjne&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Potrzebowalam &lt;strong&gt;3 listy rekomendacyjne&lt;/strong&gt;. Szczegolny przypadek: SOPHAS (wspomniany wyzej) &lt;em&gt;bardzo mocno&lt;/em&gt; sugerowal zadbanie o co najmniej jeden list pochodzacy od osoby spoza akademickiego srodowiska; w tym przypadku zalaczylam 4 listy rekomendacyjne.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Uwagi:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;W dobrym guscie jest zwrocenie sie z prosba o &lt;em&gt;rozwazenie mozliwosci wystosowania takiego listu&lt;/em&gt; na min. 1 miesiac przed data, na kiedy list ma byc gotowy. Warto w takim pierwszym mejlu zaznaczyc wyraznie, na kiedy list bedziemy potrzebowac.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Listy rekomendacyjne pisane przez profesorow w USA sa zawsze pelne &amp;ldquo;ochow&amp;rdquo; i &amp;ldquo;achow&amp;rdquo;. Choc ciezko mi wyobrazic sobie poproszenie explicite o &amp;ldquo;pelen pochwal list&amp;rdquo;, warto sprobowac zaznaczyc, ze np. ze wzgledu na wysoka konkurencyjnosc uczelni, potrzebujemy &amp;ldquo;silnego&amp;rdquo; listu rekomendacyjnego. (Z tego co rozumiem, wylistowanie aktywnosci aplikanta i jednozdaniowe wyrazenie przekonania, ze to dobry kandydat, to - generalnie rzecz biarac - tresc na slaby list.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;5-networking&#34;&gt;5. Networking&lt;/h1&gt;
&lt;p&gt;Ciezko mi podkreslic wystarczajaco mocno, jak &lt;strong&gt;istotnym elementem aplikacji jest networking&lt;/strong&gt;, tzn. nawiazanie kontaktu z profesorami na wybranych przez nas uczelniach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Faktycznie, &lt;em&gt;dostalam&lt;/em&gt; sie na niektore uczelnie (ze swoich kategorii &amp;ldquo;safe&amp;rdquo; i &amp;ldquo;po srodku&amp;rdquo;), z ktorymi nie nawiazalam wczesniej zadnego bezposredniego kontaktu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Twierdze, ze bardzo trudne byloby dostanie sie do &amp;ldquo;dream school&amp;rdquo; bez nawiazania wczesniej bezposredniego kontaktu. Tu, aplikacja bardzo potrzebuje &amp;ldquo;wsparcia od srodka&amp;rdquo; departamentu, do ktorego chcemy sie dostac.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Przyklady tego, &lt;strong&gt;jak mozna budowac potrzebny networking&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wyjechanie do USA na kilka miesiecy do tymczasowej pracy / na staz na wybrana uczelnie.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pierwszym krokiem do zaproszenia na taki wyjazd moze byc krotki mejl do wybranego profesora, mowiacy: &amp;ldquo;Czesc, jestem bardzo zainteresowany twoja praca o X, sam od dawna czytam i pracuje nad rzeczami zwiazanymi z Y, czy znalazlbys 10 minut na rozmowe na Skajpie? Dostosuje sie do terminu, ktory zaproponujesz.&amp;rdquo;  &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wyjechanie do USA na konferencje / szkole wakacyjna / warsztaty, gdzie beda profesorowie z interesujacej nas uczelni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nawiazanie kontaktu telefonicznego / mejlowego z profesorami z interesujacej nas uczelni. (Por. wskazowka w podpunkcie wyzej).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;6-aplikowanie&#34;&gt;6. Aplikowanie&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wypelnianie aplikacji jest czasochlonne&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nalezy wziac margines na specjalne przypadki nawet w ramach wykonywania aplikacji w formularzu online. Przyklady: a) z ostatniej strony formularza aplikacyjnego: nie przechodzi platnosc polska karta platnicza; b) z ktorejkolwiek / wielu stron formularza aplikacyjnego: nie jest jasne, co oznacza to pole - musze wyslac mejla z pytaniem do dzialu rekrutacji tej uczelni 😎.  &lt;br/&gt;  &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aplikacje sa drogie&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Niektore koszty sa jednorazowe i prawie niezalezne od liczby aplikacji (wyjazd na egzamin TOEFL / GRE). Aplikacja do kazdej kolejnej szkoly generuje  koszt (bezzwrotna oplata aplikacyjna: 30-130 USD, przeslanie wyniku GRE: 20 USD, przeslanie wyniku TOEFL: 20 USD).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mysle, ze calkowity koszt moich aplikacji (w tym: tlumacz przysiegly, dojazdy i noclegi na egzaminy w innych miastach Polski, wyslanie paczek UPS z dokumentami do kilku szkol w USA) to lacznie 7.000-10.000 PLN ☂️.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ADaptive Empirical Pattern Transformation (ADEPT) with application to walking stride segmentation</title>
      <link>/talk/2018-08-01-jsm/</link>
      <pubDate>Wed, 01 Aug 2018 15:05:50 -0400</pubDate>
      <guid>/talk/2018-08-01-jsm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wearable accelerometers, accelerometry data and automatic steps segmentation in R: strideter and convo R packages</title>
      <link>/talk/2018-07-03-whyr/</link>
      <pubDate>Tue, 03 Jul 2018 10:30:00 -0400</pubDate>
      <guid>/talk/2018-07-03-whyr/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;../../img/2018-07-whyr/pic12.jpg&#34; alt=&#34;pic1&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brain connectivity-informed regularization methods for regression</title>
      <link>/project/project_mdpeer/</link>
      <pubDate>Wed, 06 Dec 2017 11:54:53 -0400</pubDate>
      <guid>/project/project_mdpeer/</guid>
      <description>&lt;p&gt;We propose to estimate association between the brain structure features and a scalar outcome in a regression model while utilizing additional information about structural connectivity between the brain regions.&lt;/p&gt;
&lt;p&gt;Specifically, we propose a novel regularization method &amp;ndash; riPEER (ridgified Partially Empirical Eigenvectors for Regression) &amp;ndash; that defines a regularization penalty term based on the structural connectivity-derived Laplacian matrix.&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to quantify the association between alcohol abuse phenotypes (outcome) and cortical thickness of the brain (covariates) in a study sample of young social-to-heavy drinking males. The data included measurements of average cortical thickness estimated for 68 brain regions.&lt;/p&gt;
&lt;p&gt;The image (see images credit &lt;a href=&#34;#custom&#34;&gt;below&lt;/a&gt;) visualizes process of obtaining cortical thickness measurements from structural MRI images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;MRI_sequence.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;Commonly shared issues in such settings are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;high dimensionality of the data - we typically parcel the brain into tens, or hundreds of units from which we take measurements, and each unit may then correspond to a covariate in the data set,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;correlation of the covariates - measurements from spatially neighbouring or otherwise connected brain regions are likely to be correlated,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;small sample size - brain imaging studies often recruit a few tens of participants only.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose penalized regression method riPEER to estimate a linear model: $$y =  Zb + X\beta + \varepsilon$$ where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y$ - response (&lt;em&gt;here: alcohol abuse phenotypes&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$Z$ - input data matrix (&lt;em&gt;here: cortical thickness measurements&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$X$ - input data matrix (&lt;em&gt;here: demographics data&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\beta$ - regression coefficients, not penalized in estimation process&lt;/li&gt;
&lt;li&gt;$b$ - regression coefficients, penalized in estimation process and for whom there is a prior graph of similarity / graph of connections. available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The riPEER estimation method uses a penalty being a linear combination of a graph-based and ridge penalty terms:
$$
\hat{\beta}, \hat{b}
= \underset{\beta,b}{\text{arg min}} \left[ (y - X\beta - Zb)^T(y - X\beta - Zb)  + \lambda_Qb^TQb +  \lambda_Rb^Tb  \right ]
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Q$ - a graph-originated penalty matrix; typically: a graph Laplacian matrix (&lt;em&gt;here: a graph Laplacian derived from structural connectivity of brain regions&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\lambda_Q$ - regularization parameter for a graph-based penalty term,&lt;/li&gt;
&lt;li&gt;$\lambda_R$ - regularization parameter for ridge penalty term.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;ripeer-penalty-term&#34;&gt;riPEER penalty term&lt;/h5&gt;
&lt;p&gt;In the riPEER penalty term  $(\lambda_Qb^TQb +  \lambda_Rb^Tb)$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A graph-originated penalty matrix $Q$ allows imposing similarity between coefficients of variables which are &lt;em&gt;connected&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A ridge penalty term, $\lambda_Rb^Tb$, allows for L2 regularization component; in addition, even with very small $\lambda_R$, eliminates computational issues arising from singularity of $Q$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regularization parameters $\lambda_R$, $\lambda_Q$ are estimated automatically as ML estimators of equivalent Linear Mixed Models optimization problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We published the proposed riPEER method in work &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6583926/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brain connectivity-informed regularization methods for regression&lt;/a&gt; (Karas, M., Brzyski, D., Dzemidzic, M., Goni, J., Kareken, D.A., Randolph, T., Harezlak J. (2017)).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We published the riPEER extension to generalized linear regression, addressing both theoretical and computational issues, in work &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connectivity‐informed adaptive regularization for generalized outcomes&lt;/a&gt; (Brzyski, D., Karas, M., Ances, B.M., Dzemidzic, M., Goni, J., Randolph, T., Harezlak J. (2021)).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed riPEER estimation method in R package mdpeer (&lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The package provides functions for graph-constrained regression methods in which regularization parameters are selected automatically via estimation of equivalent Linear Mixed Model formulation.&lt;/p&gt;
&lt;p&gt;The R package is accompanied by &lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/vignettes/Intro_and_usage_examples.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intro and usage examples&lt;/a&gt; vignette.&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top left component. Cortical thickness. Resources of Neurorecovery Laboratory at MGH/MIT/HMS Athinoula A. Martinos Center for Biomedical Imaging. Accessed at: &lt;a href=&#34;https://www.nmr.mgh.harvard.edu/neurorecovery/technology.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top middle component. Diffusion MRI Tractography in the brain white matter. Xavier Gigandet et. al. - Gigandet X, Hagmann P, Kurant M, Cammoun L, Meuli R, et al. (2008) Estimating the Confidence Level of White Matter Connections Obtained with MRI Tractography. PLoS ONE 3(12): e4006. doi:10.1371/journal.pone.0004006. Accessed at: &lt;a href=&#34;https://en.wikipedia.org/wiki/Connectome#/media/File:White_Matter_Connections_Obtained_with_MRI_Tractography.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top right component. Databases of Statistical Information. Resources of Berkeley Advanced Media Institute
Graduate School of Journalism. Accessed at: &lt;a href=&#34;https://multimedia.journalism.berkeley.edu/tutorials/databases-of-statistical-information/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Brain Connectivity Informed Regularization Methods for Regression</title>
      <link>/publication/brain-connectivity-informed-regularization/</link>
      <pubDate>Thu, 23 Nov 2017 17:24:49 -0400</pubDate>
      <guid>/publication/brain-connectivity-informed-regularization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent developments in R tidyverse</title>
      <link>/resources/computing_club_materials/2020-12-01-computing_club/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/resources/computing_club_materials/2020-12-01-computing_club/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;tidyverse&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tidyverse&lt;/h2&gt;
&lt;p&gt;The tidyverse is an ecosystem of packages designed with a shared underlying design philosophy, grammar, and data structures.&lt;/p&gt;
&lt;p&gt;The tidyverse v1.3.0 loads 8 packages via &lt;code&gt;library(tidyverse)&lt;/code&gt;: ggplot2, dplyr, tidyr, purrr, tibble, stringr, forcats, readr.&lt;/p&gt;
&lt;p&gt;It also includes (installs) but does not automatically load some other (i.e. lubridate).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/tidyverse-logo.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;presentation-motivation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Presentation motivation&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 45%;&#34;&gt;
&lt;h4 id=&#34;me-using-tidyverse-packages-in-2015&#34;&gt;Me using tidyverse packages in &lt;strong&gt;2015&lt;/strong&gt;:&lt;/h4&gt;
&lt;p&gt;&lt;/br&gt;
Typically do stuff like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  filter(age &amp;gt;= 50) %&amp;gt;%
  group_by(var1, var2) %&amp;gt;%
  summarize(y_mean = mean(y),
            y_median = median(y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and google “r ggplot2 rotate x axis labels”&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 45%;&#34;&gt;
&lt;h4 id=&#34;me-using-tidyverse-packages-in-2020&#34;&gt;Me using tidyverse packages in &lt;strong&gt;2020&lt;/strong&gt;:&lt;/h4&gt;
&lt;p&gt;&lt;/br&gt;
Typically do stuff like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  filter(age &amp;gt;= 50) %&amp;gt;%
  group_by(var1, var2) %&amp;gt;%
  summarize(y_mean = mean(y),
            y_median = median(y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and google “r ggplot2 rotate x axis labels”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;presentation-content-credits&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Presentation content credits&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 50%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/twitter_q_long.png&#34; style=&#34;width:90.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 50%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/twitter_a2.png&#34; style=&#34;width:90.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://towardsdatascience.com/ten-up-to-date-ways-to-do-common-data-tasks-in-r-4f15e56c92d&#34;&gt;Post link here.&lt;/a&gt;) These slides from now on are like 80-90% of this post content, with small alterations from my side.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;outline&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Outline&lt;/h2&gt;
&lt;p&gt;Palmer Penguins dataset&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Selecting columns in data&lt;/li&gt;
&lt;li&gt;Reordering columns in data&lt;/li&gt;
&lt;li&gt;Controlling mutated column location&lt;/li&gt;
&lt;li&gt;Transforming from wide to long&lt;/li&gt;
&lt;li&gt;Transforming from long to wide&lt;/li&gt;
&lt;li&gt;Running group statistics across multiple columns&lt;/li&gt;
&lt;li&gt;Control how output columns are named when summarising across multiple columns&lt;/li&gt;
&lt;li&gt;Running models across subsets of data&lt;/li&gt;
&lt;li&gt;Nesting data&lt;/li&gt;
&lt;li&gt;Graphing across subsets&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;palmer-penguins-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Palmer Penguins dataset&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 75%;&#34;&gt;
&lt;p&gt;“The goal of &lt;code&gt;palmerpenguins&lt;/code&gt; is to provide a great dataset for data exploration &amp;amp; visualization, as an alternative to &lt;code&gt;iris&lt;/code&gt;.”&lt;/p&gt;
&lt;p&gt;Data set contains size measurements for three penguin species (Adelie, Chinstrap, Gentoo) observed on three islands in the Palmer Archipelago, Antarctica (Biscoe, Dream, Torgersen).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(palmerpenguins)
str(penguins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [344 × 8] (S3: tbl_df/tbl/data.frame)
##  $ species          : Factor w/ 3 levels &amp;quot;Adelie&amp;quot;,&amp;quot;Chinstrap&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ island           : Factor w/ 3 levels &amp;quot;Biscoe&amp;quot;,&amp;quot;Dream&amp;quot;,..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...
##  $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...
##  $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...
##  $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...
##  $ sex              : Factor w/ 2 levels &amp;quot;female&amp;quot;,&amp;quot;male&amp;quot;: 2 1 1 NA 1 2 1 2 NA NA ...
##  $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 25%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/penguin.jpeg&#34; style=&#34;width:99.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;selecting-columns-in-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Selecting columns in data&lt;/h2&gt;
&lt;p&gt;To select columns using &lt;code&gt;dplyr::select()&lt;/code&gt; or &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; based on common conditions, use helper functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To select variables contained in a character vector: &lt;code&gt;all_of()&lt;/code&gt;, &lt;code&gt;any_of()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To select all (i.e. remaining) or last column: &lt;code&gt;everything()&lt;/code&gt;, &lt;code&gt;last_col()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To select variables by matching patterns in their names: &lt;code&gt;starts_with()&lt;/code&gt;, &lt;code&gt;ends_with()&lt;/code&gt;, &lt;code&gt;contains()&lt;/code&gt;, &lt;code&gt;matches()&lt;/code&gt;, &lt;code&gt;num_range()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To apply a custom function and select those for which the function returns TRUE: &lt;code&gt;where()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::select(!contains(&amp;quot;_&amp;quot;), starts_with(&amp;quot;bill&amp;quot;)) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 6
##   species island    sex     year bill_length_mm bill_depth_mm
##   &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
## 1 Adelie  Torgersen male    2007           39.1          18.7
## 2 Adelie  Torgersen female  2007           39.5          17.4
## 3 Adelie  Torgersen female  2007           40.3          18&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_select_func &amp;lt;- function(var_name){
  return(is.factor(var_name))
}

penguins %&amp;gt;% 
  dplyr::select(where(my_select_func)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 3
##    species island    sex   
##    &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt; 
##  1 Adelie  Torgersen male  
##  2 Adelie  Torgersen female
##  3 Adelie  Torgersen female
##  4 Adelie  Torgersen &amp;lt;NA&amp;gt;  
##  5 Adelie  Torgersen female
##  6 Adelie  Torgersen male  
##  7 Adelie  Torgersen female
##  8 Adelie  Torgersen male  
##  9 Adelie  Torgersen &amp;lt;NA&amp;gt;  
## 10 Adelie  Torgersen &amp;lt;NA&amp;gt;  
## # … with 334 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reordering-columns-in-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Reordering columns in data&lt;/h2&gt;
&lt;p&gt;To reorder specific columns or sets of columns, use &lt;code&gt;dplyr::relocate()&lt;/code&gt; with &lt;code&gt;.before&lt;/code&gt; or &lt;code&gt;.after&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::relocate(contains(&amp;quot;_&amp;quot;), .after = year) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 8
##   species island sex    year bill_length_mm bill_depth_mm flipper_length_…
##   &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;
## 1 Adelie  Torge… male   2007           39.1          18.7              181
## 2 Adelie  Torge… fema…  2007           39.5          17.4              186
## 3 Adelie  Torge… fema…  2007           40.3          18                195
## # … with 1 more variable: body_mass_g &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::relocate(species, .after = last_col()) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 8
##   island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex    year
##   &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Torge…           39.1          18.7              181        3750 male   2007
## 2 Torge…           39.5          17.4              186        3800 fema…  2007
## 3 Torge…           40.3          18                195        3250 fema…  2007
## # … with 1 more variable: species &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;controlling-mutated-column-location&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Controlling mutated column location&lt;/h2&gt;
&lt;p&gt;To control the location of the newly added column, use &lt;code&gt;dplyr::mutate()&lt;/code&gt;’s option (similar to above’s &lt;code&gt;dplyr::relocate()&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins &amp;lt;- penguins %&amp;gt;% 
  dplyr::mutate(penguinid = row_number(), .before = everything()) 

penguins &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 9
##    penguinid species island bill_length_mm bill_depth_mm flipper_length_…
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;
##  1         1 Adelie  Torge…           39.1          18.7              181
##  2         2 Adelie  Torge…           39.5          17.4              186
##  3         3 Adelie  Torge…           40.3          18                195
##  4         4 Adelie  Torge…           NA            NA                 NA
##  5         5 Adelie  Torge…           36.7          19.3              193
##  6         6 Adelie  Torge…           39.3          20.6              190
##  7         7 Adelie  Torge…           38.9          17.8              181
##  8         8 Adelie  Torge…           39.2          19.6              195
##  9         9 Adelie  Torge…           34.1          18.1              193
## 10        10 Adelie  Torge…           42            20.2              190
## # … with 334 more rows, and 3 more variables: body_mass_g &amp;lt;int&amp;gt;, sex &amp;lt;fct&amp;gt;,
## #   year &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transforming-from-wide-to-long&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. Transforming from wide to long&lt;/h2&gt;
&lt;p&gt;To transform data set from wide(r) to long(er) form, use &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; which is an updated approach to an older &lt;code&gt;tidyr::gather()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  tidyr::pivot_longer(cols = contains(&amp;quot;_&amp;quot;),  # pivot these columns
                      names_to = &amp;quot;variable_name&amp;quot;, # name of column containing &amp;quot;old columns&amp;quot; names
                      values_to = &amp;quot;variable_value&amp;quot;)  # name of column containing &amp;quot;old columns&amp;quot; values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,376 x 7
##    penguinid species island    sex     year variable_name     variable_value
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torgersen male    2007 bill_length_mm              39.1
##  2         1 Adelie  Torgersen male    2007 bill_depth_mm               18.7
##  3         1 Adelie  Torgersen male    2007 flipper_length_mm          181  
##  4         1 Adelie  Torgersen male    2007 body_mass_g               3750  
##  5         2 Adelie  Torgersen female  2007 bill_length_mm              39.5
##  6         2 Adelie  Torgersen female  2007 bill_depth_mm               17.4
##  7         2 Adelie  Torgersen female  2007 flipper_length_mm          186  
##  8         2 Adelie  Torgersen female  2007 body_mass_g               3800  
##  9         3 Adelie  Torgersen female  2007 bill_length_mm              40.3
## 10         3 Adelie  Torgersen female  2007 bill_depth_mm               18  
## # … with 1,366 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# as previous example, but simultaneously split the names of columns 
# which we pivot into longer format by &amp;quot;_&amp;quot; separator 
penguins_longer &amp;lt;- penguins %&amp;gt;% 
  tidyr::pivot_longer(cols = contains(&amp;quot;_&amp;quot;), # pivot these columns
                      names_sep = &amp;quot;_&amp;quot;, 
                      names_to = c(&amp;quot;part&amp;quot;, &amp;quot;measure&amp;quot;, &amp;quot;unit&amp;quot;), # name of column(s) containing &amp;quot;old columns&amp;quot; names
                      values_to = &amp;quot;measure_value&amp;quot; ) # name of column containing &amp;quot;old columns&amp;quot; values

penguins_longer &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,376 x 9
##    penguinid species island    sex     year part    measure unit  measure_value
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torgersen male    2007 bill    length  mm             39.1
##  2         1 Adelie  Torgersen male    2007 bill    depth   mm             18.7
##  3         1 Adelie  Torgersen male    2007 flipper length  mm            181  
##  4         1 Adelie  Torgersen male    2007 body    mass    g            3750  
##  5         2 Adelie  Torgersen female  2007 bill    length  mm             39.5
##  6         2 Adelie  Torgersen female  2007 bill    depth   mm             17.4
##  7         2 Adelie  Torgersen female  2007 flipper length  mm            186  
##  8         2 Adelie  Torgersen female  2007 body    mass    g            3800  
##  9         3 Adelie  Torgersen female  2007 bill    length  mm             40.3
## 10         3 Adelie  Torgersen female  2007 bill    depth   mm             18  
## # … with 1,366 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transforming-from-long-to-wide&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5. Transforming from long to wide&lt;/h2&gt;
&lt;p&gt;To transform data set from long(er) to wide(r) form, use &lt;code&gt;tidyr::pivot_wider()&lt;/code&gt; which is an updated approach to an older &lt;code&gt;tidyr::spread()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# revert from long form from previous example 
penguins_wider &amp;lt;- penguins_longer %&amp;gt;% 
  tidyr::pivot_wider(names_from = c(&amp;quot;part&amp;quot;, &amp;quot;measure&amp;quot;, &amp;quot;unit&amp;quot;), # pivot these columns
                     values_from = &amp;quot;measure_value&amp;quot;, # take the values from here
                     names_sep = &amp;quot;_&amp;quot;) # combine col names using an underscore

penguins_wider&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 9
##    penguinid species island sex    year bill_length_mm bill_depth_mm
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torge… male   2007           39.1          18.7
##  2         2 Adelie  Torge… fema…  2007           39.5          17.4
##  3         3 Adelie  Torge… fema…  2007           40.3          18  
##  4         4 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           NA            NA  
##  5         5 Adelie  Torge… fema…  2007           36.7          19.3
##  6         6 Adelie  Torge… male   2007           39.3          20.6
##  7         7 Adelie  Torge… fema…  2007           38.9          17.8
##  8         8 Adelie  Torge… male   2007           39.2          19.6
##  9         9 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           34.1          18.1
## 10        10 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           42            20.2
## # … with 334 more rows, and 2 more variables: flipper_length_mm &amp;lt;dbl&amp;gt;,
## #   body_mass_g &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-group-statistics-across-multiple-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;6. Running group statistics across multiple columns&lt;/h2&gt;
&lt;p&gt;To apply multiple summary statistics simultaneously in an efficient way, use &lt;code&gt;across()&lt;/code&gt; verb.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate mean and sd for each variable  ending in mm, across three species 
penguin_stats &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(across(.cols = ends_with(&amp;quot;mm&amp;quot;), 
                          .fns = list(~mean(.x, na.rm = TRUE), 
                                      ~sd(.x, na.rm = TRUE))))

penguin_stats&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 7
##   species bill_length_mm_1 bill_length_mm_2 bill_depth_mm_1 bill_depth_mm_2
##   &amp;lt;fct&amp;gt;              &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Adelie              38.8             2.66            18.3           1.22 
## 2 Chinst…             48.8             3.34            18.4           1.14 
## 3 Gentoo              47.5             3.08            15.0           0.981
## # … with 2 more variables: flipper_length_mm_1 &amp;lt;dbl&amp;gt;, flipper_length_mm_2 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;control-how-output-columns-are-named-when-summarising-across-multiple-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;7. Control how output columns are named when summarising across multiple columns&lt;/h2&gt;
&lt;p&gt;To apply multiple summary statistics simultaneously in an efficient way with &lt;code&gt;across()&lt;/code&gt; verb and to use other than default column names of summary variables, use the &lt;code&gt;.names&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins_stats &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(across(.cols = ends_with(&amp;quot;mm&amp;quot;), 
                          .fns = list(mean = ~mean(.x, na.rm = TRUE), 
                                      sd = ~sd(.x, na.rm = TRUE)),
                          .names = &amp;quot;{gsub(&amp;#39;_|_mm&amp;#39;, &amp;#39;&amp;#39;, col)}_{.fn}&amp;quot;))
penguins_stats&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 7
##   species billlength_mean billlength_sd billdepth_mean billdepth_sd
##   &amp;lt;fct&amp;gt;             &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 Adelie             38.8          2.66           18.3        1.22 
## 2 Chinst…            48.8          3.34           18.4        1.14 
## 3 Gentoo             47.5          3.08           15.0        0.981
## # … with 2 more variables: flipperlength_mean &amp;lt;dbl&amp;gt;, flipperlength_sd &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-models-across-subsets-of-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;8. Running models across subsets of data&lt;/h2&gt;
&lt;p&gt;Use &lt;code&gt;dplyr::summarise()&lt;/code&gt; to compute different &lt;em&gt;types&lt;/em&gt; of outcomes stored in a list, for example, summary vectors, data frames or other objects like models or graphs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_models &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(model = list(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm)))  
penguin_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   species   model 
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;gt;
## 1 Adelie    &amp;lt;lm&amp;gt;  
## 2 Chinstrap &amp;lt;lm&amp;gt;  
## 3 Gentoo    &amp;lt;lm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_tmp &amp;lt;- penguin_models[1, 2][[1]][[1]]
# summary(model_tmp)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

penguin_models &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(broom::glance(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm))) 

penguin_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 13
##   species r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC
##   &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Adelie      0.508         0.498  325.      50.6 1.55e-22     3 -1086. 2181.
## 2 Chinst…     0.504         0.481  277.      21.7 8.48e-10     3  -477.  964.
## 3 Gentoo      0.625         0.615  313.      66.0 3.39e-25     3  -879. 1768.
## # … with 4 more variables: BIC &amp;lt;dbl&amp;gt;, deviance &amp;lt;dbl&amp;gt;, df.residual &amp;lt;int&amp;gt;,
## #   nobs &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nesting-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;9. Nesting data&lt;/h2&gt;
&lt;p&gt;To partition data into subsets so that we can apply a common function or operation across all subsets of the data, use &lt;code&gt;dplyr::nest_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  nest_by(species)  %&amp;gt;%
  mutate(data_model = list(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm, data = data)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
## # Rowwise:  species
##   species                 data data_model
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;lt;tbl_df[,8]&amp;gt;&amp;gt; &amp;lt;list&amp;gt;    
## 1 Adelie             [152 × 8] &amp;lt;lm&amp;gt;      
## 2 Chinstrap           [68 × 8] &amp;lt;lm&amp;gt;      
## 3 Gentoo             [124 × 8] &amp;lt;lm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-across-subsets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;10. Graphing across subsets&lt;/h2&gt;
&lt;p&gt;To generate plots across data subsets and store them for further usage, use &lt;code&gt;dplyr::nest_by()&lt;/code&gt; combined with plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generic function for generating a simple scatter plot in ggplot2
scatter_fn &amp;lt;- function(df, col1, col2, title) {
  df %&amp;gt;% 
    ggplot2::ggplot(aes(x = {{col1}}, y = {{col2}})) +
    ggplot2::geom_point() +
    ggplot2::geom_smooth() +
    ggplot2::labs(title = title)
}

# run function across species and store plots in a list column
penguin_scatters &amp;lt;- penguins %&amp;gt;% 
  dplyr::nest_by(species) %&amp;gt;% 
  dplyr::mutate(plot = list(scatter_fn(data, bill_length_mm, bill_depth_mm, species))) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_scatters&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
## # Rowwise:  species
##   species                 data plot  
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;lt;tbl_df[,8]&amp;gt;&amp;gt; &amp;lt;list&amp;gt;
## 1 Adelie             [152 × 8] &amp;lt;gg&amp;gt;  
## 2 Chinstrap           [68 × 8] &amp;lt;gg&amp;gt;  
## 3 Gentoo             [124 × 8] &amp;lt;gg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_all &amp;lt;- scatter_fn(penguins, bill_length_mm, bill_depth_mm, &amp;quot;All Species&amp;quot;) 
# get species scatters from penguin_scatters dataframe
for (i in 1:3) {
 assign(paste(&amp;quot;p&amp;quot;, i, sep = &amp;quot;_&amp;quot;),
        penguin_scatters$plot[i][[1]]) 
}

# display nicely using patchwork in R Markdown
library(patchwork)
p_all /
(p_1 | p_2 | p_3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/talk/2020-12-01-computing_club/slides_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;thank-you&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thank you!&lt;/h2&gt;
&lt;p&gt;Credit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides in this presentation are &lt;strong&gt;&lt;em&gt;very heavily&lt;/em&gt;&lt;/strong&gt; based on &lt;a href=&#34;https://towardsdatascience.com/ten-up-to-date-ways-to-do-common-data-tasks-in-r-4f15e56c92d&#34;&gt;“Ten Up-To-Date Ways to do Common Data Tasks in R” post&lt;/a&gt; by Keith McNulty.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://vita.had.co.nz/papers/tidy-data.pdf&#34;&gt;Tidy data&lt;/a&gt; paper by Wickham, Hadley (2013). Journal of Statistical Software.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01686&#34;&gt;Welcome to the Tidyverse&lt;/a&gt; paper by Wickham, Hadley et al. (2019). Journal of Open Source Software.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.tidyverse.org/blog/&#34;&gt;Tidyverse blog&lt;/a&gt; with updates (in a form of a blog post)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Recent developments in R tidyverse</title>
      <link>/slides/2020-12-01-computing_club/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/slides/2020-12-01-computing_club/</guid>
      <description>
&lt;link href=&#34;index_files/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;index_files/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;tidyverse&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tidyverse&lt;/h2&gt;
&lt;p&gt;The tidyverse is an ecosystem of packages designed with a shared underlying design philosophy, grammar, and data structures.&lt;/p&gt;
&lt;p&gt;The tidyverse v1.3.0 loads 8 packages via &lt;code&gt;library(tidyverse)&lt;/code&gt;: ggplot2, dplyr, tidyr, purrr, tibble, stringr, forcats, readr.&lt;/p&gt;
&lt;p&gt;It also includes (installs) but does not automatically load some other (i.e. lubridate).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/tidyverse-logo.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;presentation-motivation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Presentation motivation&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 45%;&#34;&gt;
&lt;h4 id=&#34;me-using-tidyverse-packages-in-2015&#34;&gt;Me using tidyverse packages in &lt;strong&gt;2015&lt;/strong&gt;:&lt;/h4&gt;
&lt;p&gt;&lt;/br&gt;
Typically do stuff like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  filter(age &amp;gt;= 50) %&amp;gt;%
  group_by(var1, var2) %&amp;gt;%
  summarize(y_mean = mean(y),
            y_median = median(y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and google “r ggplot2 rotate x axis labels”&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 45%;&#34;&gt;
&lt;h4 id=&#34;me-using-tidyverse-packages-in-2020&#34;&gt;Me using tidyverse packages in &lt;strong&gt;2020&lt;/strong&gt;:&lt;/h4&gt;
&lt;p&gt;&lt;/br&gt;
Typically do stuff like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  filter(age &amp;gt;= 50) %&amp;gt;%
  group_by(var1, var2) %&amp;gt;%
  summarize(y_mean = mean(y),
            y_median = median(y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and google “r ggplot2 rotate x axis labels”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;presentation-content-credits&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Presentation content credits&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 50%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/twitter_q_long.png&#34; style=&#34;width:90.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 50%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/twitter_a2.png&#34; style=&#34;width:90.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://towardsdatascience.com/ten-up-to-date-ways-to-do-common-data-tasks-in-r-4f15e56c92d&#34;&gt;Post link here.&lt;/a&gt;) These slides from now on are like 80-90% of this post content, with small alterations from my side.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;outline&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Outline&lt;/h2&gt;
&lt;p&gt;Palmer Penguins dataset&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Selecting columns in data&lt;/li&gt;
&lt;li&gt;Reordering columns in data&lt;/li&gt;
&lt;li&gt;Controlling mutated column location&lt;/li&gt;
&lt;li&gt;Transforming from wide to long&lt;/li&gt;
&lt;li&gt;Transforming from long to wide&lt;/li&gt;
&lt;li&gt;Running group statistics across multiple columns&lt;/li&gt;
&lt;li&gt;Control how output columns are named when summarising across multiple columns&lt;/li&gt;
&lt;li&gt;Running models across subsets of data&lt;/li&gt;
&lt;li&gt;Nesting data&lt;/li&gt;
&lt;li&gt;Graphing across subsets&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;palmer-penguins-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Palmer Penguins dataset&lt;/h2&gt;
&lt;div style=&#34;float: left; width: 75%;&#34;&gt;
&lt;p&gt;“The goal of &lt;code&gt;palmerpenguins&lt;/code&gt; is to provide a great dataset for data exploration &amp;amp; visualization, as an alternative to &lt;code&gt;iris&lt;/code&gt;.”&lt;/p&gt;
&lt;p&gt;Data set contains size measurements for three penguin species (Adelie, Chinstrap, Gentoo) observed on three islands in the Palmer Archipelago, Antarctica (Biscoe, Dream, Torgersen).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(palmerpenguins)
str(penguins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [344 × 8] (S3: tbl_df/tbl/data.frame)
##  $ species          : Factor w/ 3 levels &amp;quot;Adelie&amp;quot;,&amp;quot;Chinstrap&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ island           : Factor w/ 3 levels &amp;quot;Biscoe&amp;quot;,&amp;quot;Dream&amp;quot;,..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...
##  $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...
##  $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...
##  $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...
##  $ sex              : Factor w/ 2 levels &amp;quot;female&amp;quot;,&amp;quot;male&amp;quot;: 2 1 1 NA 1 2 1 2 NA NA ...
##  $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div style=&#34;float: right; width: 25%;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;img/penguin.jpeg&#34; style=&#34;width:99.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;selecting-columns-in-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Selecting columns in data&lt;/h2&gt;
&lt;p&gt;To select columns using &lt;code&gt;dplyr::select()&lt;/code&gt; or &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; based on common conditions, use helper functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To select variables contained in a character vector: &lt;code&gt;all_of()&lt;/code&gt;, &lt;code&gt;any_of()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To select all (i.e. remaining) or last column: &lt;code&gt;everything()&lt;/code&gt;, &lt;code&gt;last_col()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To select variables by matching patterns in their names: &lt;code&gt;starts_with()&lt;/code&gt;, &lt;code&gt;ends_with()&lt;/code&gt;, &lt;code&gt;contains()&lt;/code&gt;, &lt;code&gt;matches()&lt;/code&gt;, &lt;code&gt;num_range()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To apply a custom function and select those for which the function returns TRUE: &lt;code&gt;where()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::select(!contains(&amp;quot;_&amp;quot;), starts_with(&amp;quot;bill&amp;quot;)) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 6
##   species island    sex     year bill_length_mm bill_depth_mm
##   &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
## 1 Adelie  Torgersen male    2007           39.1          18.7
## 2 Adelie  Torgersen female  2007           39.5          17.4
## 3 Adelie  Torgersen female  2007           40.3          18&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_select_func &amp;lt;- function(var_name){
  return(is.factor(var_name))
}

penguins %&amp;gt;% 
  dplyr::select(where(my_select_func)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 3
##    species island    sex   
##    &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt; 
##  1 Adelie  Torgersen male  
##  2 Adelie  Torgersen female
##  3 Adelie  Torgersen female
##  4 Adelie  Torgersen &amp;lt;NA&amp;gt;  
##  5 Adelie  Torgersen female
##  6 Adelie  Torgersen male  
##  7 Adelie  Torgersen female
##  8 Adelie  Torgersen male  
##  9 Adelie  Torgersen &amp;lt;NA&amp;gt;  
## 10 Adelie  Torgersen &amp;lt;NA&amp;gt;  
## # … with 334 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reordering-columns-in-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Reordering columns in data&lt;/h2&gt;
&lt;p&gt;To reorder specific columns or sets of columns, use &lt;code&gt;dplyr::relocate()&lt;/code&gt; with &lt;code&gt;.before&lt;/code&gt; or &lt;code&gt;.after&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::relocate(contains(&amp;quot;_&amp;quot;), .after = year) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 8
##   species island sex    year bill_length_mm bill_depth_mm flipper_length_…
##   &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;
## 1 Adelie  Torge… male   2007           39.1          18.7              181
## 2 Adelie  Torge… fema…  2007           39.5          17.4              186
## 3 Adelie  Torge… fema…  2007           40.3          18                195
## # … with 1 more variable: body_mass_g &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  dplyr::relocate(species, .after = last_col()) %&amp;gt;% head(n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 8
##   island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex    year
##   &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Torge…           39.1          18.7              181        3750 male   2007
## 2 Torge…           39.5          17.4              186        3800 fema…  2007
## 3 Torge…           40.3          18                195        3250 fema…  2007
## # … with 1 more variable: species &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;controlling-mutated-column-location&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Controlling mutated column location&lt;/h2&gt;
&lt;p&gt;To control the location of the newly added column, use &lt;code&gt;dplyr::mutate()&lt;/code&gt;’s option (similar to above’s &lt;code&gt;dplyr::relocate()&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins &amp;lt;- penguins %&amp;gt;% 
  dplyr::mutate(penguinid = row_number(), .before = everything()) 

penguins &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 9
##    penguinid species island bill_length_mm bill_depth_mm flipper_length_…
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;int&amp;gt;
##  1         1 Adelie  Torge…           39.1          18.7              181
##  2         2 Adelie  Torge…           39.5          17.4              186
##  3         3 Adelie  Torge…           40.3          18                195
##  4         4 Adelie  Torge…           NA            NA                 NA
##  5         5 Adelie  Torge…           36.7          19.3              193
##  6         6 Adelie  Torge…           39.3          20.6              190
##  7         7 Adelie  Torge…           38.9          17.8              181
##  8         8 Adelie  Torge…           39.2          19.6              195
##  9         9 Adelie  Torge…           34.1          18.1              193
## 10        10 Adelie  Torge…           42            20.2              190
## # … with 334 more rows, and 3 more variables: body_mass_g &amp;lt;int&amp;gt;, sex &amp;lt;fct&amp;gt;,
## #   year &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transforming-from-wide-to-long&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. Transforming from wide to long&lt;/h2&gt;
&lt;p&gt;To transform data set from wide(r) to long(er) form, use &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; which is an updated approach to an older &lt;code&gt;tidyr::gather()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  tidyr::pivot_longer(cols = contains(&amp;quot;_&amp;quot;),  # pivot these columns
                      names_to = &amp;quot;variable_name&amp;quot;, # name of column containing &amp;quot;old columns&amp;quot; names
                      values_to = &amp;quot;variable_value&amp;quot;)  # name of column containing &amp;quot;old columns&amp;quot; values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,376 x 7
##    penguinid species island    sex     year variable_name     variable_value
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torgersen male    2007 bill_length_mm              39.1
##  2         1 Adelie  Torgersen male    2007 bill_depth_mm               18.7
##  3         1 Adelie  Torgersen male    2007 flipper_length_mm          181  
##  4         1 Adelie  Torgersen male    2007 body_mass_g               3750  
##  5         2 Adelie  Torgersen female  2007 bill_length_mm              39.5
##  6         2 Adelie  Torgersen female  2007 bill_depth_mm               17.4
##  7         2 Adelie  Torgersen female  2007 flipper_length_mm          186  
##  8         2 Adelie  Torgersen female  2007 body_mass_g               3800  
##  9         3 Adelie  Torgersen female  2007 bill_length_mm              40.3
## 10         3 Adelie  Torgersen female  2007 bill_depth_mm               18  
## # … with 1,366 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# as previous example, but simultaneously split the names of columns 
# which we pivot into longer format by &amp;quot;_&amp;quot; separator 
penguins_longer &amp;lt;- penguins %&amp;gt;% 
  tidyr::pivot_longer(cols = contains(&amp;quot;_&amp;quot;), # pivot these columns
                      names_sep = &amp;quot;_&amp;quot;, 
                      names_to = c(&amp;quot;part&amp;quot;, &amp;quot;measure&amp;quot;, &amp;quot;unit&amp;quot;), # name of column(s) containing &amp;quot;old columns&amp;quot; names
                      values_to = &amp;quot;measure_value&amp;quot; ) # name of column containing &amp;quot;old columns&amp;quot; values

penguins_longer &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,376 x 9
##    penguinid species island    sex     year part    measure unit  measure_value
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torgersen male    2007 bill    length  mm             39.1
##  2         1 Adelie  Torgersen male    2007 bill    depth   mm             18.7
##  3         1 Adelie  Torgersen male    2007 flipper length  mm            181  
##  4         1 Adelie  Torgersen male    2007 body    mass    g            3750  
##  5         2 Adelie  Torgersen female  2007 bill    length  mm             39.5
##  6         2 Adelie  Torgersen female  2007 bill    depth   mm             17.4
##  7         2 Adelie  Torgersen female  2007 flipper length  mm            186  
##  8         2 Adelie  Torgersen female  2007 body    mass    g            3800  
##  9         3 Adelie  Torgersen female  2007 bill    length  mm             40.3
## 10         3 Adelie  Torgersen female  2007 bill    depth   mm             18  
## # … with 1,366 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transforming-from-long-to-wide&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5. Transforming from long to wide&lt;/h2&gt;
&lt;p&gt;To transform data set from long(er) to wide(r) form, use &lt;code&gt;tidyr::pivot_wider()&lt;/code&gt; which is an updated approach to an older &lt;code&gt;tidyr::spread()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# revert from long form from previous example 
penguins_wider &amp;lt;- penguins_longer %&amp;gt;% 
  tidyr::pivot_wider(names_from = c(&amp;quot;part&amp;quot;, &amp;quot;measure&amp;quot;, &amp;quot;unit&amp;quot;), # pivot these columns
                     values_from = &amp;quot;measure_value&amp;quot;, # take the values from here
                     names_sep = &amp;quot;_&amp;quot;) # combine col names using an underscore

penguins_wider&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 x 9
##    penguinid species island sex    year bill_length_mm bill_depth_mm
##        &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
##  1         1 Adelie  Torge… male   2007           39.1          18.7
##  2         2 Adelie  Torge… fema…  2007           39.5          17.4
##  3         3 Adelie  Torge… fema…  2007           40.3          18  
##  4         4 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           NA            NA  
##  5         5 Adelie  Torge… fema…  2007           36.7          19.3
##  6         6 Adelie  Torge… male   2007           39.3          20.6
##  7         7 Adelie  Torge… fema…  2007           38.9          17.8
##  8         8 Adelie  Torge… male   2007           39.2          19.6
##  9         9 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           34.1          18.1
## 10        10 Adelie  Torge… &amp;lt;NA&amp;gt;   2007           42            20.2
## # … with 334 more rows, and 2 more variables: flipper_length_mm &amp;lt;dbl&amp;gt;,
## #   body_mass_g &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-group-statistics-across-multiple-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;6. Running group statistics across multiple columns&lt;/h2&gt;
&lt;p&gt;To apply multiple summary statistics simultaneously in an efficient way, use &lt;code&gt;across()&lt;/code&gt; verb.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate mean and sd for each variable  ending in mm, across three species 
penguin_stats &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(across(.cols = ends_with(&amp;quot;mm&amp;quot;), 
                          .fns = list(~mean(.x, na.rm = TRUE), 
                                      ~sd(.x, na.rm = TRUE))))

penguin_stats&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 7
##   species bill_length_mm_1 bill_length_mm_2 bill_depth_mm_1 bill_depth_mm_2
##   &amp;lt;fct&amp;gt;              &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Adelie              38.8             2.66            18.3           1.22 
## 2 Chinst…             48.8             3.34            18.4           1.14 
## 3 Gentoo              47.5             3.08            15.0           0.981
## # … with 2 more variables: flipper_length_mm_1 &amp;lt;dbl&amp;gt;, flipper_length_mm_2 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;control-how-output-columns-are-named-when-summarising-across-multiple-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;7. Control how output columns are named when summarising across multiple columns&lt;/h2&gt;
&lt;p&gt;To apply multiple summary statistics simultaneously in an efficient way with &lt;code&gt;across()&lt;/code&gt; verb and to use other than default column names of summary variables, use the &lt;code&gt;.names&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins_stats &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(across(.cols = ends_with(&amp;quot;mm&amp;quot;), 
                          .fns = list(mean = ~mean(.x, na.rm = TRUE), 
                                      sd = ~sd(.x, na.rm = TRUE)),
                          .names = &amp;quot;{gsub(&amp;#39;_|_mm&amp;#39;, &amp;#39;&amp;#39;, col)}_{.fn}&amp;quot;))
penguins_stats&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 7
##   species billlength_mean billlength_sd billdepth_mean billdepth_sd
##   &amp;lt;fct&amp;gt;             &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 Adelie             38.8          2.66           18.3        1.22 
## 2 Chinst…            48.8          3.34           18.4        1.14 
## 3 Gentoo             47.5          3.08           15.0        0.981
## # … with 2 more variables: flipperlength_mean &amp;lt;dbl&amp;gt;, flipperlength_sd &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-models-across-subsets-of-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;8. Running models across subsets of data&lt;/h2&gt;
&lt;p&gt;Use &lt;code&gt;dplyr::summarise()&lt;/code&gt; to compute different &lt;em&gt;types&lt;/em&gt; of outcomes stored in a list, for example, summary vectors, data frames or other objects like models or graphs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_models &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(model = list(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm)))  
penguin_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   species   model 
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;gt;
## 1 Adelie    &amp;lt;lm&amp;gt;  
## 2 Chinstrap &amp;lt;lm&amp;gt;  
## 3 Gentoo    &amp;lt;lm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_tmp &amp;lt;- penguin_models[1, 2][[1]][[1]]
# summary(model_tmp)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

penguin_models &amp;lt;- penguins %&amp;gt;% 
  dplyr::group_by(species) %&amp;gt;% 
  dplyr::summarise(broom::glance(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm))) 

penguin_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 13
##   species r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC
##   &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Adelie      0.508         0.498  325.      50.6 1.55e-22     3 -1086. 2181.
## 2 Chinst…     0.504         0.481  277.      21.7 8.48e-10     3  -477.  964.
## 3 Gentoo      0.625         0.615  313.      66.0 3.39e-25     3  -879. 1768.
## # … with 4 more variables: BIC &amp;lt;dbl&amp;gt;, deviance &amp;lt;dbl&amp;gt;, df.residual &amp;lt;int&amp;gt;,
## #   nobs &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nesting-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;9. Nesting data&lt;/h2&gt;
&lt;p&gt;To partition data into subsets so that we can apply a common function or operation across all subsets of the data, use &lt;code&gt;dplyr::nest_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  nest_by(species)  %&amp;gt;%
  mutate(data_model = list(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm, data = data)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
## # Rowwise:  species
##   species                 data data_model
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;lt;tbl_df[,8]&amp;gt;&amp;gt; &amp;lt;list&amp;gt;    
## 1 Adelie             [152 × 8] &amp;lt;lm&amp;gt;      
## 2 Chinstrap           [68 × 8] &amp;lt;lm&amp;gt;      
## 3 Gentoo             [124 × 8] &amp;lt;lm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-across-subsets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;10. Graphing across subsets&lt;/h2&gt;
&lt;p&gt;To generate plots across data subsets and store them for further usage, use &lt;code&gt;dplyr::nest_by()&lt;/code&gt; combined with plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generic function for generating a simple scatter plot in ggplot2
scatter_fn &amp;lt;- function(df, col1, col2, title) {
  df %&amp;gt;% 
    ggplot2::ggplot(aes(x = {{col1}}, y = {{col2}})) +
    ggplot2::geom_point() +
    ggplot2::geom_smooth() +
    ggplot2::labs(title = title)
}

# run function across species and store plots in a list column
penguin_scatters &amp;lt;- penguins %&amp;gt;% 
  dplyr::nest_by(species) %&amp;gt;% 
  dplyr::mutate(plot = list(scatter_fn(data, bill_length_mm, bill_depth_mm, species))) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_scatters&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
## # Rowwise:  species
##   species                 data plot  
##   &amp;lt;fct&amp;gt;     &amp;lt;list&amp;lt;tbl_df[,8]&amp;gt;&amp;gt; &amp;lt;list&amp;gt;
## 1 Adelie             [152 × 8] &amp;lt;gg&amp;gt;  
## 2 Chinstrap           [68 × 8] &amp;lt;gg&amp;gt;  
## 3 Gentoo             [124 × 8] &amp;lt;gg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_all &amp;lt;- scatter_fn(penguins, bill_length_mm, bill_depth_mm, &amp;quot;All Species&amp;quot;) 
# get species scatters from penguin_scatters dataframe
for (i in 1:3) {
 assign(paste(&amp;quot;p&amp;quot;, i, sep = &amp;quot;_&amp;quot;),
        penguin_scatters$plot[i][[1]]) 
}

# display nicely using patchwork in R Markdown
library(patchwork)
p_all /
(p_1 | p_2 | p_3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;thank-you&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thank you!&lt;/h2&gt;
&lt;p&gt;Credit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides in this presentation are &lt;strong&gt;&lt;em&gt;very heavily&lt;/em&gt;&lt;/strong&gt; based on &lt;a href=&#34;https://towardsdatascience.com/ten-up-to-date-ways-to-do-common-data-tasks-in-r-4f15e56c92d&#34;&gt;“Ten Up-To-Date Ways to do Common Data Tasks in R” post&lt;/a&gt; by Keith McNulty.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://vita.had.co.nz/papers/tidy-data.pdf&#34;&gt;Tidy data&lt;/a&gt; paper by Wickham, Hadley (2013). Journal of Statistical Software.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01686&#34;&gt;Welcome to the Tidyverse&lt;/a&gt; paper by Wickham, Hadley et al. (2019). Journal of Open Source Software.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.tidyverse.org/blog/&#34;&gt;Tidyverse blog&lt;/a&gt; with updates (in a form of a blog post)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
