<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home</title>
    <link>https://example.com/</link>
      <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Home</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Home</title>
      <link>https://example.com/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://example.com/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://example.com/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Hugo Blox Builder&amp;rsquo;s &lt;a href=&#34;https://docs.hugoblox.com/reference/content-types/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nature and the city</title>
      <link>https://example.com/resources/gallery-all/</link>
      <pubDate>Sun, 03 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/resources/gallery-all/</guid>
      <description>&lt;p&gt;Welcome to my photo gallery! These are some of my favorite pictures taken in recent years. Click on any picture to enter the gallery view and see it in full size (this allows to see description of a picture&amp;rsquo;s location in the left-bottom). Thank you for visiting my website.&lt;/p&gt;

















&lt;div class=&#34;gallery-grid&#34;&gt;

  
  
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28056_8.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28056_8_hue6a03529431eb1de755d58bb7e083a42_3149583_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28056_8.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28056_9.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28056_9_hua8b40f83ff60ed8f95d23890164d1426_4790075_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28056_9.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_4.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_4_hu7f8ad0671760588c355dce549821f4d8_5692286_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_4.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_5.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_5_hu813db9b2a6a8d7db0f1ff252679ac6c3_2931649_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_5.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_6.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_6_hua925fd8e0ab18451c54a9ec36d3e8f9f_2590360_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_6.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_7.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_7_hu85e2e90c5475e9a3f084c791f9b4bd16_3932898_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_7.jpg&#34; width=&#34;750&#34; height=&#34;569&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_8.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_8_hub785831a0d73d89d6d069da1956080e4_3031691_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_8.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28124_9.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28124_9_hu170f95e267d240dd9c7fa0deca9dac7f_4199980_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28124_9.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28258_3.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28258_3_hu544b9fe811d869333f833fbd63e71668_4521932_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28258_3.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28258_6.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28258_6_hu092c5acc553aac1a12b08954c209e7b2_6907683_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28258_6.jpg&#34; width=&#34;563&#34; height=&#34;750&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28260_3.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28260_3_huad4c8de92b9a30716296eab911225236_5216525_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28260_3.jpg&#34; width=&#34;750&#34; height=&#34;563&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-gallery_all&#34; href=&#34;https://example.com/media/albums/gallery_all/28260_6.jpg&#34; &gt;
      &lt;img src=&#34;https://example.com/media/albums/gallery_all/28260_6_hu60762719c9149ad57a7baab1ce3e6f94_4101022_750x750_fit_q75_h2_lanczos.webp&#34; loading=&#34;lazy&#34; alt=&#34;28260_6.jpg&#34; width=&#34;750&#34; height=&#34;597&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  

&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Blog with Jupyter Notebooks!</title>
      <link>https://example.com/post/_template_blog-with-jupyter/</link>
      <pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/_template_blog-with-jupyter/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;IPython.core.display&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;png&#34; srcset=&#34;
               /post/_template_blog-with-jupyter/output_1_0_hu1e42f419f47ffd4b1ca9ef8f6670390a_11155_5a714abab5f53c70f7c38e19755638d3.webp 400w,
               /post/_template_blog-with-jupyter/output_1_0_hu1e42f419f47ffd4b1ca9ef8f6670390a_11155_6b76da17c04a40aee4c1c633206f8065.webp 760w,
               /post/_template_blog-with-jupyter/output_1_0_hu1e42f419f47ffd4b1ca9ef8f6670390a_11155_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/_template_blog-with-jupyter/output_1_0_hu1e42f419f47ffd4b1ca9ef8f6670390a_11155_5a714abab5f53c70f7c38e19755638d3.webp&#34;
               width=&#34;601&#34;
               height=&#34;203&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Welcome to Academic!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Welcome to Academic!
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;organize-your-notebooks&#34;&gt;Organize your notebooks&lt;/h2&gt;
&lt;p&gt;Place the notebooks that you would like to publish in a &lt;code&gt;notebooks&lt;/code&gt; folder at the root of your website.&lt;/p&gt;
&lt;h2 id=&#34;import-the-notebooks-into-your-site&#34;&gt;Import the notebooks into your site&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pipx install academic
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;academic import &lt;span class=&#34;s1&#34;&gt;&amp;#39;notebooks/**.ipynb&amp;#39;&lt;/span&gt; content/post/ --verbose
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The notebooks will be published to the folder you specify above. In this case, they will be published to your &lt;code&gt;content/post/&lt;/code&gt; folder.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Repeated Measures Correlation (rmcorr): when may be not an ideal choice to quantify the association</title>
      <link>https://example.com/post/2022-04-27-rmcorr_vs_lmm/</link>
      <pubDate>Tue, 26 Apr 2022 17:19:28 -0400</pubDate>
      <guid>https://example.com/post/2022-04-27-rmcorr_vs_lmm/</guid>
      <description>&lt;p&gt;In this post, we use the Repeated Measures Correlation (&lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt;) approach to quantify association between two continuous measures recorded multiple times per study subject.&lt;/p&gt;
&lt;p&gt;I recently learned about the &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; approach and explored it with a view of applying in one of the current projects. I think &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; is a very interesting method with neat interpretation. Here, I highlight  key notes from how the &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; works, and I point to a few cases where I expect that &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; may be not an ideal choice to quantify the association.&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#repeated-measures-correlation&#34;&gt;Repeated Measures Correlation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#method&#34;&gt;Method&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#key-notes&#34;&gt;Key notes&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#scenarios&#34;&gt;Scenarios&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-1a&#34;&gt;Scenario 1a&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-1b&#34;&gt;Scenario 1b&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-2a&#34;&gt;Scenario 2a&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-2b&#34;&gt;Scenario 2b&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-3a&#34;&gt;Scenario 3a&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-3b&#34;&gt;Scenario 3b&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-4a&#34;&gt;Scenario 4a&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#scenario-4b&#34;&gt;Scenario 4b&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#observations&#34;&gt;Observations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h2 id=&#34;repeated-measures-correlation&#34;&gt;Repeated Measures Correlation&lt;/h2&gt;
&lt;p&gt;The Bakdash et al. (2017) paper &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00456/full&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Repeated Measures
Correlation&lt;/a&gt;
discusses within-participants correlation to analyze the common
intra-individual association for paired repeated measures. The paper
provides background information, methods description, R package
reference, and discussion on tradeoffs with &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; as compared to
multilevel modeling.&lt;/p&gt;
&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;
&lt;p&gt;In short, &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is based on ANCOVA analysis: it considers a subject as a factor-level variable to remove between-person variation. ANCOVA model is set to estimate subjects&amp;rsquo; common regression slope $\beta$.&lt;/li&gt;
&lt;li&gt;The rmcorr correlation coefficient is calculated using sums of squares for the Measure and for the error from the above ANCOVA model and its sign is determined by the sign (positive vs. negative) of estimated $\beta$.&lt;/li&gt;
&lt;li&gt;It has a nice, intuitive interpretation.&lt;/li&gt;
&lt;li&gt;Authors argue is &amp;ldquo;comparable to linear multilevel model (&lt;em&gt;&lt;strong&gt;LMM&lt;/strong&gt;&lt;/em&gt;) with random intercept only and a fixed effect&amp;rdquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;key-notes&#34;&gt;Key notes&lt;/h3&gt;
&lt;p&gt;Key notes on &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; does not allow for slope variation by subject,&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; does not utilize any of &lt;em&gt;&lt;strong&gt;LMM&lt;/strong&gt;&lt;/em&gt;&amp;rsquo;s partial-pooling idea (i.e., where for subjects with a relatively smaller number of observations, their estimates are &amp;ldquo;shrunk&amp;rdquo; closer to the overall population average);&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and hence, as the authors noted, &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; may be not an ideal choice to quantify the association:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;when the effect slope varies between subjects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also thought having random slopes is even more problematic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;when the number of observations varies between subjects (e.g., varies between 2-10),&lt;/li&gt;
&lt;li&gt;when there are influential observation(s) (e.g., subject(s) with wide $x$ values range).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;scenarios&#34;&gt;Scenarios&lt;/h2&gt;
&lt;p&gt;To illustrate the above notes, 4x2 simple data scenarios are considered.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In each scenario, data on N = 20 subjects with 2 continuous variables ($x$, $y$), recorded at multiple occasions for each subject, are simulated.&lt;/li&gt;
&lt;li&gt;The scenarios differ in true data-generating model that is assumed:
&lt;ul&gt;
&lt;li&gt;Scenario 1: random intercept only;&lt;/li&gt;
&lt;li&gt;Scenario 2: random intercept and random slope (uncorrelated);&lt;/li&gt;
&lt;li&gt;Scenario 3: random intercept and random slope (uncorrelated), added one subject with influential observations;&lt;/li&gt;
&lt;li&gt;Scenario 4: random intercept and random slope (uncorrelated), unbalanced number of observations per subject.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For each scenario, two versions are considered, assuming: (a): small variance of residual error; (b) large variance of residual error.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To show the results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each scenario, 1 data set is used and results from applying 2 approaches are shown:
&lt;ul&gt;
&lt;li&gt;left plot: &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; with an estimate of &amp;ldquo;repeated measures correlation&amp;rdquo;,&lt;/li&gt;
&lt;li&gt;right plot: &lt;em&gt;&lt;strong&gt;LMM&lt;/strong&gt;&lt;/em&gt; fit with an estimate of fixed effect slope.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For all scenarios, left plot points same as right plot points (the same data used for 2 approaches).&lt;/li&gt;
&lt;li&gt;For all scenarios, population-level effect $x$ on $y$ was assumed to be equal $2.0$.&lt;/li&gt;
&lt;li&gt;For all scenarios, &lt;em&gt;&lt;strong&gt;LMM&lt;/strong&gt;&lt;/em&gt; assumes random intercept and random slope for $x$, and a fixed effect for $x$.&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code shared for all simulations.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(lme4)
library(lmerTest)
library(rmcorr)
library(MASS)

# define simulation parameters
# number of subjects 
M &amp;lt;- 20 
# number of repeated measures per subjects (for all except last two scenarios)
k &amp;lt;- 5  

#&#39; Function to apply two approaches to `dat` data set: 
#&#39; (1) rmcorr with an estimate of &amp;quot;repeated measures correlation&amp;quot;,
#&#39; (2) LMM fit with an estimate of fixed effect slope 
est_and_plot &amp;lt;- function(dat){
  # approach 1 
  rmcorr_out &amp;lt;- rmcorr(subj_id, x, y, dat)
  plt_label &amp;lt;- paste0(&amp;quot;r = &amp;quot;, round(rmcorr_out$r, 3), &amp;quot; (95% CI: [&amp;quot;, paste0(round(rmcorr_out$CI, 3), collapse = &amp;quot;, &amp;quot;), &amp;quot;])&amp;quot;)
  par(mar = rep(2, 4))
  plot(rmcorr_out, main = plt_label)
  
  # approach 2 
  lmm_out &amp;lt;- lmer(y ~ x + (1 + x | subj_id), data = dat)
  conf_est &amp;lt;- summary(lmm_out)$coef[2, 1]
  conf_out &amp;lt;- as.vector(confint(lmm_out, parm = &amp;quot;x&amp;quot;))
  plt_label &amp;lt;- paste0(&amp;quot;beta = &amp;quot;, round(conf_est, 3), &amp;quot; (95% CI: [&amp;quot;, paste0(round(conf_out, 3), collapse = &amp;quot;, &amp;quot;), &amp;quot;])&amp;quot;)
  dat$mu &amp;lt;- getME(lmm_out, &amp;quot;mu&amp;quot;)[1 : nrow(dat)]
  plt &amp;lt;- 
    ggplot(dat, aes(x = x, y = y, color = subj_id, group = subj_id)) + 
    # geom_line(color = &amp;quot;black&amp;quot;) + 
    geom_line(aes(x = x, y = mu), size = 0.3) + 
    geom_point() + 
    theme_classic(base_size = 12) + 
    theme(
      legend.position = &amp;quot;none&amp;quot;,
    )  + 
    labs(x = &amp;quot;x&amp;quot;, y = &amp;quot;y&amp;quot;, title = plt_label)
  plot(plt) 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;h3 id=&#34;scenario-1a&#34;&gt;Scenario 1a&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept only&lt;/li&gt;
&lt;li&gt;small residual error&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 0.25
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 0)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-1_hu5cff1378496e5dffdff468e25d68a9dc_48807_eed08decf85092b0dc74cb4c3d3d9fdf.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-1_hu5cff1378496e5dffdff468e25d68a9dc_48807_c87c624f1b391052b57b77b8027d7283.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-1_hu5cff1378496e5dffdff468e25d68a9dc_48807_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-1_hu5cff1378496e5dffdff468e25d68a9dc_48807_eed08decf85092b0dc74cb4c3d3d9fdf.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-2_hu795ded65459e975bb88d3491916fd929_48342_ccd55c78a88798ecf3e1c459846ab579.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-2_hu795ded65459e975bb88d3491916fd929_48342_513cdb5d8509c4514b3b2a1c062e477d.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-2_hu795ded65459e975bb88d3491916fd929_48342_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_1a_plot-2_hu795ded65459e975bb88d3491916fd929_48342_ccd55c78a88798ecf3e1c459846ab579.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-1b&#34;&gt;Scenario 1b&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept only&lt;/li&gt;
&lt;li&gt;large residual error&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 2
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 0)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-1_hu8f7feba532312f4634f3d20ae6383a98_53938_ddfa2f1c102a4c9f699f0f45cd8fa42e.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-1_hu8f7feba532312f4634f3d20ae6383a98_53938_fcbe4eda7ff3ee3aa12f629d88533a35.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-1_hu8f7feba532312f4634f3d20ae6383a98_53938_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-1_hu8f7feba532312f4634f3d20ae6383a98_53938_ddfa2f1c102a4c9f699f0f45cd8fa42e.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-2_hu7de55121e9f16eed2cf7e41b85063a1a_49108_2fb3360b4b0797ef69d5f61fb012c077.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-2_hu7de55121e9f16eed2cf7e41b85063a1a_49108_bafbcb441a55678567accca3466dcdb3.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-2_hu7de55121e9f16eed2cf7e41b85063a1a_49108_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_1b_plot-2_hu7de55121e9f16eed2cf7e41b85063a1a_49108_2fb3360b4b0797ef69d5f61fb012c077.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-2a&#34;&gt;Scenario 2a&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;small residual error&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 0.25
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-1_hu68938e91c702dc0881670ceced7fdc42_44762_ae8242f7eef9ee2d34002e257260dea5.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-1_hu68938e91c702dc0881670ceced7fdc42_44762_5b3301e300791b31461f5787d4b8f67f.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-1_hu68938e91c702dc0881670ceced7fdc42_44762_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-1_hu68938e91c702dc0881670ceced7fdc42_44762_ae8242f7eef9ee2d34002e257260dea5.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-2_hub8abc0b38e012f34c47f858a0fb081a3_42385_fd49ab8c420aebfe333b5b21106e6329.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-2_hub8abc0b38e012f34c47f858a0fb081a3_42385_09284b19ca7492648a06d89f5074b60a.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-2_hub8abc0b38e012f34c47f858a0fb081a3_42385_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_2a_plot-2_hub8abc0b38e012f34c47f858a0fb081a3_42385_fd49ab8c420aebfe333b5b21106e6329.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-2b&#34;&gt;Scenario 2b&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;large residual error&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 2
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-1_hu31e001fd868b211982d4184d9e799253_45713_68665537104d3cf54b57602bb60a1017.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-1_hu31e001fd868b211982d4184d9e799253_45713_f12084b82b0dacee8b1357b5fb814620.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-1_hu31e001fd868b211982d4184d9e799253_45713_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-1_hu31e001fd868b211982d4184d9e799253_45713_68665537104d3cf54b57602bb60a1017.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-2_hu12e4ffc4ef898873d74316864a29738b_44528_ab877daa30d92dec3f75a945bb82f8b9.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-2_hu12e4ffc4ef898873d74316864a29738b_44528_ae7ab60ecd02bb61286d013f3f3c72b8.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-2_hu12e4ffc4ef898873d74316864a29738b_44528_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_2b_plot-2_hu12e4ffc4ef898873d74316864a29738b_44528_ab877daa30d92dec3f75a945bb82f8b9.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-3a&#34;&gt;Scenario 3a&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;small residual error&lt;/li&gt;
&lt;li&gt;add one influential observation (wide x-axis range, simulate 0 $x$
effect on $y$ for that subject)&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 0.25
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : (M-1)){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
i &amp;lt;- M
x_a &amp;lt;- runif(1, 0, 5)
x_b &amp;lt;- x_a + 15
x &amp;lt;- seq(x_a, x_b, length.out = k)
eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
# y &amp;lt;- (alpha + ai[i]) + rep(0, k) + eps
y &amp;lt;- alpha + rep(0, k) + eps
subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
x_vec &amp;lt;- c(x_vec, x)
y_vec &amp;lt;- c(y_vec, y)
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-1_hu667d09b82dd5c3253da58f0076bc1b5b_36353_72a9735ae8c25fcb7e8c958b842b5dfa.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-1_hu667d09b82dd5c3253da58f0076bc1b5b_36353_67157c7b8bd5649a35124d87f96975e0.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-1_hu667d09b82dd5c3253da58f0076bc1b5b_36353_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-1_hu667d09b82dd5c3253da58f0076bc1b5b_36353_72a9735ae8c25fcb7e8c958b842b5dfa.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-2_hu398abee66154428632829e83d69e9927_34539_7c13a1601c187c7f73d9535c191f9b67.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-2_hu398abee66154428632829e83d69e9927_34539_bdabc959452ad2857ea30700667d42b2.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-2_hu398abee66154428632829e83d69e9927_34539_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_3a_plot-2_hu398abee66154428632829e83d69e9927_34539_7c13a1601c187c7f73d9535c191f9b67.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-3b&#34;&gt;Scenario 3b&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;large residual error&lt;/li&gt;
&lt;li&gt;add one influential observation (wide x-axis range, simulate 0 $x$
effect on $y$ for that subject)&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 2
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : (M-1)){ # i &amp;lt;- 2
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k)
  eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
i &amp;lt;- M
x_a &amp;lt;- runif(1, 0, 5)
x_b &amp;lt;- x_a + 15
x &amp;lt;- seq(x_a, x_b, length.out = k)
eps &amp;lt;- rnorm(k, mean = 0, sd = eps_sd)
# y &amp;lt;- (alpha + ai[i]) + rep(0, k) + eps
y &amp;lt;- (alpha + 0) + rep(0, k) + eps
subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k))
x_vec &amp;lt;- c(x_vec, x)
y_vec &amp;lt;- c(y_vec, y)
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-1_huce58b3a330520c15f76090f2f4da10ce_36257_1bcd0f4e319e41757a31a533cb933e3d.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-1_huce58b3a330520c15f76090f2f4da10ce_36257_fa6d31e422ba97553947133e0368f592.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-1_huce58b3a330520c15f76090f2f4da10ce_36257_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-1_huce58b3a330520c15f76090f2f4da10ce_36257_1bcd0f4e319e41757a31a533cb933e3d.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-2_huf45c399df32b2908cd854c0031d7d8c3_36962_7a0d2fa3d6e54a222745e26c1bf8a52b.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-2_huf45c399df32b2908cd854c0031d7d8c3_36962_03c39651cf2ab42553d545f0ae47f17c.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-2_huf45c399df32b2908cd854c0031d7d8c3_36962_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_3b_plot-2_huf45c399df32b2908cd854c0031d7d8c3_36962_7a0d2fa3d6e54a222745e26c1bf8a52b.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-4a&#34;&gt;Scenario 4a&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;small residual error&lt;/li&gt;
&lt;li&gt;various number (between 2 and 8) of observations per subject&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 0.25
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  k_i &amp;lt;- sample(2 : 8, 1)
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k_i)
  eps &amp;lt;- rnorm(k_i, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k_i))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-1_hua057d26f7e1af0f7e0248c191bfd1810_47376_149527dca5383a818170a0061b4c97ef.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-1_hua057d26f7e1af0f7e0248c191bfd1810_47376_00b0c05e50e3a83425aed9a6ec9ed7ca.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-1_hua057d26f7e1af0f7e0248c191bfd1810_47376_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-1_hua057d26f7e1af0f7e0248c191bfd1810_47376_149527dca5383a818170a0061b4c97ef.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-2_huca6a1f176dbb79660eaf083787cf77fd_43845_d4ed0a3ee96ace44742d476114bdeb5b.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-2_huca6a1f176dbb79660eaf083787cf77fd_43845_26f116811591eeea12f0c42114667b81.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-2_huca6a1f176dbb79660eaf083787cf77fd_43845_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_4a_plot-2_huca6a1f176dbb79660eaf083787cf77fd_43845_d4ed0a3ee96ace44742d476114bdeb5b.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;scenario-4b&#34;&gt;Scenario 4b&lt;/h3&gt;
&lt;p&gt;Data-generating model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random intercept and random slope (uncorrelated)&lt;/li&gt;
&lt;li&gt;large residual error&lt;/li&gt;
&lt;li&gt;various number (between 2 and 8) of observations per subject&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see R code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;set.seed(1)
eps_sd &amp;lt;- 2
alpha = 1
beta = 2
ai = rnorm(M, mean = 0, sd = 3)
bi = rnorm(M, mean = 0, sd = 1.5)

subj_id_vec &amp;lt;- numeric()
x_vec &amp;lt;- numeric()
y_vec &amp;lt;- numeric()
for (i in 1 : M){ # i &amp;lt;- 2
  k_i &amp;lt;- sample(2 : 8, 1)
  x_a &amp;lt;- runif(1, 0, 5)
  x_b &amp;lt;- x_a + 2 + rnorm(1)
  x &amp;lt;- seq(x_a, x_b, length.out = k_i)
  eps &amp;lt;- rnorm(k_i, mean = 0, sd = eps_sd)
  y &amp;lt;- (alpha + ai[i]) + (beta + bi[i]) * x + eps
  subj_id_vec &amp;lt;- c(subj_id_vec, rep(paste0(&amp;quot;subj_id_&amp;quot;, i), k_i))
  x_vec &amp;lt;- c(x_vec, x)
  y_vec &amp;lt;- c(y_vec, y)
}
dat &amp;lt;- data.frame(subj_id = factor(subj_id_vec), x = x_vec, y = y_vec)
est_and_plot(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;rmcorr&lt;/th&gt;
&lt;th&gt;LMM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-1_hu876d06a346f893fe66053b12b3f4a158_44241_559b364751e7ea7b0672040f07ac677d.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-1_hu876d06a346f893fe66053b12b3f4a158_44241_fd709b906851768c114d0872e94c068d.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-1_hu876d06a346f893fe66053b12b3f4a158_44241_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-1_hu876d06a346f893fe66053b12b3f4a158_44241_559b364751e7ea7b0672040f07ac677d.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-2_hu6d9fc98a7aef2a0744582057d9f437a1_45555_42bcea9fc93b38973174a1cd1588832d.webp 400w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-2_hu6d9fc98a7aef2a0744582057d9f437a1_45555_fa4e3fd2b05d7c8187085cb6f19a6927.webp 760w,
               /post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-2_hu6d9fc98a7aef2a0744582057d9f437a1_45555_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-04-27-rmcorr_vs_lmm/scenario_4b_plot-2_hu6d9fc98a7aef2a0744582057d9f437a1_45555_42bcea9fc93b38973174a1cd1588832d.webp&#34;
               width=&#34;432&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;observations&#34;&gt;Observations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;When the &amp;ldquo;true&amp;rdquo; effect slope varies between subjects&lt;/strong&gt;, the estimated
&lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; correlation, $r_{rm}$, might be tanking. See Scenario 2a
($r_{rm}$ = 0.652) and 2b ($r_{rm}$ = 0.458) where data-generating model
assumed varying slope, and compare with Scenario 1a ($r_{rm}$ = 0.992)
and 1b ($r_{rm}$ = 0.623) where data-generating model assumed the same
population-effect as 2a and 2b but no varying slope. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;In presence of influential observation&lt;/strong&gt;, the estimated &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt;
correlation, $r_{rm}$, appear to be prone to be further affected. See
Scenario 3a and 3b where influential observation was added (data for
one subject, assumed wide x-axis range, simulate 0 $x$ effect on $y$
for that subject). Compare scenario 2a and 3a ($r_{rm}$ = 0.652 =&amp;gt;
$r_{rm}$ = 0.349) and Scenario 2b and 3b ($r_{rm}$ = 0.458 =&amp;gt; $r_{rm}$ = 0.189)
where data-generating models within these pairs differ only by how
data for that one subject were simulated.  &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;When number of observations&lt;/strong&gt; varies between subjects (and especially
when it is small for some), due to lack of partial-pooling
mechanism, I expect &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; correlation results might be
unstable too. See Scenario 4a and 4b where various number (between 2
and 8) of observations per subject was assumed. Compare scenario 2a
and 4a ($r_{rm}$ = 0.652 =&amp;gt; $r_{rm}$ = 0.885) and Scenario 2b and 4b
($r_{rm}$ = 0.458 =&amp;gt; $r_{rm}$ = 0.594) which data-generating models only
differ by assuming fixed or variate number of observations per
subject (while the average number of observations per subject is set
the same).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion: &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; is IMO a very interesting method with neat &amp;ldquo;repeated measures correlation interpretation&amp;rdquo;. However, in some data scenarios demonstrated above, the correlation estmated by &lt;em&gt;&lt;strong&gt;rmcorr&lt;/strong&gt;&lt;/em&gt; might be not an ideal choice to quantify the association between two measures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GPS data in R: parse and plot GPX data exported from Strava</title>
      <link>https://example.com/post/2022-01-05-gps_strava_read_and_viz/</link>
      <pubDate>Wed, 05 Jan 2022 17:19:28 -0400</pubDate>
      <guid>https://example.com/post/2022-01-05-gps_strava_read_and_viz/</guid>
      <description>&lt;p&gt;In this post, we:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use a GPX file with with geographic information, exported from
Strava from one running activity,&lt;/li&gt;
&lt;li&gt;parse and plot the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#gpx-data-from-strava&#34;&gt;GPX data from Strava&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#parsing-gpx&#34;&gt;Parsing GPX&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#computing-distance-time-elapsed-and-speed&#34;&gt;Computing distance, time elapsed and speed&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plot-elevation-speed&#34;&gt;Plot elevation, speed&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plot-run-path&#34;&gt;Plot run path&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h2 id=&#34;gpx-data-from-strava&#34;&gt;GPX data from Strava&lt;/h2&gt;
&lt;p&gt;GPX stands for “GPS Exchange Format”. It is an XML schema commonly used
for storing GPS data.&lt;/p&gt;
&lt;p&gt;Strava (Strava, Inc; San Francisco, CA) is a popular activity tracker
app I have been using for a few weeks. Strava allows to export GPS data
collected during a recorded activity in a GPX format. To export the
data, go to Strava activity page &amp;gt; “three dots” button &amp;gt; Export
GPX.&lt;/p&gt;
&lt;p&gt;I downloaded GPX data from a run I did on Jan 1, 2022. The run distance
is 10.88 km and spans 1:03:49 time. The data is available on my GitHub
and can be downloaded using the code below.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code to download the data.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;url &amp;lt;- paste0(
  &amp;quot;https://raw.githubusercontent.com/martakarass/gps-stats/main/data/&amp;quot;,
  &amp;quot;/Morning_Run_2022-01-01.gpx&amp;quot;)
fpath &amp;lt;- paste0(
  &amp;quot;/Users/martakaras/Downloads&amp;quot;,
  &amp;quot;/Morning_Run_2022-01-01.gpx&amp;quot;)
# download 
result &amp;lt;- curl::curl_download(url, destfile = fpath, quiet = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;h2 id=&#34;parsing-gpx&#34;&gt;Parsing GPX&lt;/h2&gt;
&lt;p&gt;First, we parse the GPX file and put the extracted data trajectories
into a data frame:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;timestamp,&lt;/li&gt;
&lt;li&gt;latitude,&lt;/li&gt;
&lt;li&gt;longitude,&lt;/li&gt;
&lt;li&gt;elevation.&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;# rm(list = ls())
library(tidyverse)
library(here)
library(XML)
library(lubridate)
library(ggmap)
library(geosphere)
options(digits.secs = 3)
options(scipen = 999)

# parse GPX file
path_tmp &amp;lt;- paste0(&amp;quot;/Users/martakaras/Downloads/Morning_Run_2022-01-01.gpx&amp;quot;)
parsed &amp;lt;- htmlTreeParse(file = path_tmp, useInternalNodes = TRUE)

# get values via via the respective xpath
coords &amp;lt;- xpathSApply(parsed, path = &amp;quot;//trkpt&amp;quot;, xmlAttrs)
elev   &amp;lt;- xpathSApply(parsed, path = &amp;quot;//trkpt/ele&amp;quot;, xmlValue)
ts_chr &amp;lt;- xpathSApply(parsed, path = &amp;quot;//trkpt/time&amp;quot;, xmlValue)

# combine into df 
dat_df &amp;lt;- data.frame(
  ts_POSIXct = ymd_hms(ts_chr, tz = &amp;quot;EST&amp;quot;),
  lat = as.numeric(coords[&amp;quot;lat&amp;quot;,]), 
  lon = as.numeric(coords[&amp;quot;lon&amp;quot;,]), 
  elev = as.numeric(elev)
)
head(dat_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;           ts_POSIXct      lat       lon elev
1 2022-01-01 09:42:01 42.32791 -71.10868 23.0
2 2022-01-01 09:42:06 42.32791 -71.10868 23.0
3 2022-01-01 09:42:08 42.32795 -71.10866 23.2
4 2022-01-01 09:42:10 42.32817 -71.10872 24.7
5 2022-01-01 09:42:11 42.32816 -71.10875 24.7
6 2022-01-01 09:42:12 42.32814 -71.10875 23.8
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;computing-distance-time-elapsed-and-speed&#34;&gt;Computing distance, time elapsed and speed&lt;/h2&gt;
&lt;p&gt;Next, we compute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distance (in meters) between subsequent GPS recordings&lt;/li&gt;
&lt;li&gt;time elapsed (in seconds) between subsequent GPS recordings,&lt;/li&gt;
&lt;li&gt;speed (metres per seconds, kilometres per hour) – temporal, based on
subsequent GPS recordings.&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;# compute distance (in meters) between subsequent GPS points
dat_df &amp;lt;- 
  dat_df %&amp;gt;%
  mutate(lat_lead = lead(lat)) %&amp;gt;%
  mutate(lon_lead = lead(lon)) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(dist_to_lead_m = distm(c(lon, lat), c(lon_lead, lat_lead), fun = distHaversine)[1,1]) %&amp;gt;%
  ungroup()

# compute time elapsed (in seconds) between subsequent GPS points
dat_df &amp;lt;- 
  dat_df %&amp;gt;%
  mutate(ts_POSIXct_lead = lead(ts_POSIXct)) %&amp;gt;%
  mutate(ts_diff_s = as.numeric(difftime(ts_POSIXct_lead, ts_POSIXct, units = &amp;quot;secs&amp;quot;))) 

# compute metres per seconds, kilometres per hour 
dat_df &amp;lt;- 
  dat_df %&amp;gt;%
  mutate(speed_m_per_sec = dist_to_lead_m / ts_diff_s) %&amp;gt;%
  mutate(speed_km_per_h = speed_m_per_sec * 3.6)

# remove some columns we won&#39;t use anymore 
dat_df &amp;lt;- 
  dat_df %&amp;gt;% 
  select(-c(lat_lead, lon_lead, ts_POSIXct_lead, ts_diff_s))
head(dat_df) %&amp;gt;% as.data.frame()
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;           ts_POSIXct      lat       lon elev dist_to_lead_m ts_diff_s speed_m_per_sec speed_km_per_h
1 2022-01-01 09:42:01 42.32791 -71.10868 23.0       0.000000         5        0.000000       0.000000
2 2022-01-01 09:42:06 42.32791 -71.10868 23.0       4.406590         2        2.203295       7.931862
3 2022-01-01 09:42:08 42.32795 -71.10866 23.2      25.403927         2       12.701963      45.727068
4 2022-01-01 09:42:10 42.32817 -71.10872 24.7       2.510645         1        2.510645       9.038324
5 2022-01-01 09:42:11 42.32816 -71.10875 24.7       2.264098         1        2.264098       8.150751
6 2022-01-01 09:42:12 42.32814 -71.10875 23.8       1.899407         1        1.899407       6.837864
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;plot-elevation-speed&#34;&gt;Plot elevation, speed&lt;/h2&gt;
&lt;p&gt;Plot elevation&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;plt_elev &amp;lt;- 
  ggplot(dat_df, aes(x = ts_POSIXct, y = elev)) + 
  geom_line() + 
  labs(x = &amp;quot;Time&amp;quot;, y = &amp;quot;Elevation [m]&amp;quot;) + 
  theme_grey(base_size = 14)
plt_elev
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-01-05-gps_strava_read_and_viz/plt_elev_hu45ee88c23e5687fac15706c0e98e3f67_175739_adc03b01ac0bc01441c5450eaeef292d.webp 400w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_elev_hu45ee88c23e5687fac15706c0e98e3f67_175739_d2d552e270b8be2cc482c68416e85600.webp 760w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_elev_hu45ee88c23e5687fac15706c0e98e3f67_175739_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-01-05-gps_strava_read_and_viz/plt_elev_hu45ee88c23e5687fac15706c0e98e3f67_175739_adc03b01ac0bc01441c5450eaeef292d.webp&#34;
               width=&#34;760&#34;
               height=&#34;304&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Plot speed&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;plt_speed_km_per_h &amp;lt;- 
  ggplot(dat_df, aes(x = ts_POSIXct, y = speed_km_per_h)) + 
  geom_line() + 
  labs(x = &amp;quot;Time&amp;quot;, y = &amp;quot;Speed [km/h]&amp;quot;) + 
  theme_grey(base_size = 14)
plt_speed_km_per_h
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-01-05-gps_strava_read_and_viz/plt_speed_km_per_h_hu348b6635eb2ec8c8901607089911f58a_330023_5fe1fb9b4900508d61807b9ad2274c34.webp 400w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_speed_km_per_h_hu348b6635eb2ec8c8901607089911f58a_330023_d0269895813e62fd1fdb5fdf6ee81198.webp 760w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_speed_km_per_h_hu348b6635eb2ec8c8901607089911f58a_330023_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-01-05-gps_strava_read_and_viz/plt_speed_km_per_h_hu348b6635eb2ec8c8901607089911f58a_330023_5fe1fb9b4900508d61807b9ad2274c34.webp&#34;
               width=&#34;760&#34;
               height=&#34;304&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The above plot is very wiggly due to small time increment over which the
speed statistic was computed. It could be made smoother by first aggregating distance covered and time elapsed over a fixed time interval longer than GPS recordings interval (e.g. 10 seconds), or by using data smoothing (e.g. LOWESS).&lt;/p&gt;
&lt;p&gt;The dips in the plot are, to my judgement, correct representations of the times I briefly stopped during the run for various reasons.&lt;/p&gt;
&lt;h2 id=&#34;plot-run-path&#34;&gt;Plot run path&lt;/h2&gt;
&lt;p&gt;A simple, &lt;code&gt;graphics&lt;/code&gt;-based version of the trajectory plot:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;plot(x = dat_df$lon, y = dat_df$lat, 
     type = &amp;quot;l&amp;quot;, col = &amp;quot;blue&amp;quot;, lwd = 3, 
     xlab = &amp;quot;Longitude&amp;quot;, ylab = &amp;quot;Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_simple_hud6a767dbdddc432ae6a3425963d41629_27840_f57dc1c527b963ff6defda6136e64518.webp 400w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_simple_hud6a767dbdddc432ae6a3425963d41629_27840_4a500f399b7ba36817f1744e5c31055e.webp 760w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_simple_hud6a767dbdddc432ae6a3425963d41629_27840_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-01-05-gps_strava_read_and_viz/plt_path_simple_hud6a767dbdddc432ae6a3425963d41629_27840_f57dc1c527b963ff6defda6136e64518.webp&#34;
               width=&#34;480&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A more fancy plot can be generated with &lt;code&gt;ggmap&lt;/code&gt; package. I used labels to
mark each kilometer passed. My Google API key is registered hence I
could also &lt;a href=&#34;https://cran.r-project.org/web/packages/ggmap/readme/README.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;access the Google map for use with
&lt;code&gt;ggmap&lt;/code&gt;&lt;/a&gt;
(code for API key registration not showed.)&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;# get the map background 
bbox &amp;lt;- make_bbox(range(dat_df$lon), range(dat_df$lat))
dat_df_map &amp;lt;- get_googlemap(center = c(mean(range(dat_df$lon)), mean(range(dat_df$lat))), zoom = 15)
# no Google token alternative: 
# dat_df_map &amp;lt;- get_map(bbox, maptype = &amp;quot;toner-lite&amp;quot;, source = &amp;quot;stamen&amp;quot;)

# data frame to add distance marks
dat_df_dist_marks &amp;lt;- 
  dat_df %&amp;gt;% 
  mutate(dist_m_cumsum = cumsum(dist_to_lead_m)) %&amp;gt;%
  mutate(dist_m_cumsum_km_floor = floor(dist_m_cumsum / 1000)) %&amp;gt;%
  group_by(dist_m_cumsum_km_floor) %&amp;gt;%
  filter(row_number() == 1, dist_m_cumsum_km_floor &amp;gt; 0) 

# generate plot
plt_path_fancy &amp;lt;- 
  ggmap(dat_df_map) + 
  geom_point(data = dat_df, aes(lon, lat, col = elev),
             size = 1, alpha = 0.5) +
  geom_path(data = dat_df, aes(lon, lat),
             size = 0.3) +
  geom_label(data = dat_df_dist_marks, aes(lon, lat, label = dist_m_cumsum_km_floor),
             size = 3) +
  labs(x = &amp;quot;Longitude&amp;quot;, 
       y = &amp;quot;Latitude&amp;quot;, 
       color = &amp;quot;Elev. [m]&amp;quot;,
       title = &amp;quot;Track of one Marta&#39;s run on 2022-01-01&amp;quot;)
plt_path_fancy
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_fancy_hu3dd7f10a129334abad2de60fbf79c131_3475230_e7e90cf8b6abd679754d35e991f6645f.webp 400w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_fancy_hu3dd7f10a129334abad2de60fbf79c131_3475230_100053db85ad0c8cf31eae5333cabe61.webp 760w,
               /post/2022-01-05-gps_strava_read_and_viz/plt_path_fancy_hu3dd7f10a129334abad2de60fbf79c131_3475230_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2022-01-05-gps_strava_read_and_viz/plt_path_fancy_hu3dd7f10a129334abad2de60fbf79c131_3475230_e7e90cf8b6abd679754d35e991f6645f.webp&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;The above content is inspired by AND borrows some code from &lt;a href=&#34;https://rpubs.com/ials2un/gpx1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotting GPS tracks with
R&lt;/a&gt; by Ivan Lizarazo, who in turn based
their content on &lt;a href=&#34;https://rpubs.com/ials2un/gpx1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stay on track: Plotting GPS tracks with
R&lt;/a&gt; by Sascha Wolfer. My main
contributions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identifying (TTBOMK) an error in their shared code for computing
of subsequent locations distance, and using an alternative way,&lt;/li&gt;
&lt;li&gt;parsing GPX timestamp with &lt;code&gt;lubridate&lt;/code&gt; function,&lt;/li&gt;
&lt;li&gt;providing my run data as open source GPS data set.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Upstrap for estimating power and sample size in complex models</title>
      <link>https://example.com/post/project_upstrap/</link>
      <pubDate>Wed, 01 Sep 2021 11:54:53 -0400</pubDate>
      <guid>https://example.com/post/project_upstrap/</guid>
      <description>&lt;p&gt;Power and sample size calculation are major components of statistical analyses. The upstrap resampling method was proposed as a general solution to this problem.&lt;/p&gt;
&lt;p&gt;We evaluate power estimation properties of the upstrap and provide a series of &amp;ldquo;read, adapt and use&amp;rdquo; R code examples for power estimation in simple and complex settings (&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bioRxiv preprint&lt;/a&gt;).&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#code-example-testing-for-significance-of-lm-coefficient&#34;&gt;Code example: testing for significance of LM coefficient&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#contributions&#34;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;We consider the following problem: given an observed data sample $\mathbf{x}$ of sample size $N$, given specific null and alternative hypothesis, and a test statistic, assuming significance level $\alpha$, estimate sample size $M$ required to achieve power $1 -\beta$ (i.e., to achieve probability $1 -\beta$ of rejecting the null hypothesis when the null is true).&lt;/p&gt;
&lt;p&gt;Here, we consider the tasks to estimate the power to detect:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;an effect size observed in the data;&lt;/li&gt;
&lt;li&gt;an effect size chosen by a researcher.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We aim to ddress complex settings, including testing significance of model coefficients in: LM, GLM, LMM, GLMM, GEE, and others.&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;For multilevel data settings, the existing approaches tend to fall into two categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First are theoretical results for estimating power in specific multilevel data setups; these often use assumptions about the intra-class correlation coefficient, and/or assume a particular study design (e.g., that
the data are balanced). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Another class is based on simulations. Such may require specifying a population model for the data, simulating data from the assumed model, and estimating the power via Monte Carlo simulations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The former arguably lacks flexibility; in addition, finding and then determining applicability of a theoretical result may be difficult. The latter is flexible but involves potentially complex programming task.&lt;/p&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;h4 id=&#34;upstrap&#34;&gt;Upstrap&lt;/h4&gt;
&lt;p&gt;The upstrap resampling method (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7868048/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crainiceanu, C.M., Crainiceanu, A. (2020)&lt;/a&gt;) was proposed as a general
solution to this problem.&lt;/p&gt;
&lt;p&gt;Upstrap starts with a sample (observed data) and resamples with replacement either fewer or more samples than in the original data set. The below example shows difference between bootstrap and upstrap resample.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# simulate data &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# bootstrap resample&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# upstrap resample (case: more samples than in original x) &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_u&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;upstrap-for-estimating-power&#34;&gt;Upstrap for estimating power&lt;/h4&gt;
&lt;p&gt;Given observed data sample $\mathbf{x}$, to estimate power for a target sample size, we propose:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Generate $B$ resamples of target sample size by sampling with replacement from $\mathbf{x}$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perform  hypothesis test on each resample.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Estimate power as the proportion of $B$ resamples where the null hypothesis was rejected.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above procedure estimates power corresponding to the effect size &lt;em&gt;observed&lt;/em&gt; in the sample $\mathbf{x}$. For example, for one-sample t-test, the above procedure estimates:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;power.t.test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;power&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;upstrap-for-estimating-power-specific-effect-size&#34;&gt;Upstrap for estimating power: specific effect size&lt;/h4&gt;
&lt;p&gt;In practice, one is often is interested in estimating power for a &lt;em&gt;specific&lt;/em&gt; effect size. For example, for one-sample t-test, a specific effect size could be set to 0.3:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;power.t.test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;power&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To address such cases, we propose to update  response variable values in the observed sample $\mathbf{x}$ to ensure the effect size in this updated data is our target effect size. Details are provided in the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;code-example-testing-for-significance-of-lm-coefficient&#34;&gt;Code example: testing for significance of LM coefficient&lt;/h3&gt;
&lt;p&gt;Below, we demonstrate the upstrap power estimation method for testing for significance of LM coefficient. In the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint&lt;/a&gt;, we provide more R code examples, including testing for significance of coefficient in LM, GLM, LMM, GLMM.&lt;/p&gt;
&lt;p&gt;We define simulation parameters and simulate a sample of size $N = 50$.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see setup definition and R code.)
&lt;/summary&gt;
&lt;h4 id=&#34;setup&#34;&gt;Setup&lt;/h4&gt;
&lt;p&gt;Consider a random sample with $N = 50$ independent observations (e.g., 50 subjects, 1 observation per subject). Assume a continuous response variable $Y$ and two covariates: dichotomous $X_1$, continuous $X_2$. We are interested in estimating power of test for significance of the coefficient $\beta_{1}$ in linear model $Y_{i}=\beta_{0}+\beta_{1} X_{1 i}+\beta_{2} X_{2 i}+\varepsilon_{i}$, where $i=1, \ldots, N$ and $\varepsilon_{i} \sim_{\text {iid }} N\left(0, \sigma^{2}\right)$.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# simulation parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;50&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;coef_x0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;coef_x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;coef_x2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sigma2&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# simulate sample&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;set.seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;subjid_i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# subject ID unique in data set&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x1_i&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbinom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x2_i&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbinom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;eps_i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sigma2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_i&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;coef_x0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coef_x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coef_x2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eps_i&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subjid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subjid_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;data.frame&amp;#39;:	50 obs. of  4 variables:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  $ y     : num  0.398 -0.512 0.541 -0.929 1.433 ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  $ x1    : int  0 0 1 1 0 1 1 1 1 0 ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  $ x2    : int  0 1 0 0 0 0 0 1 1 0 ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  $ subjid: int  1 2 3 4 5 6 7 8 9 10 ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We get the observed effect size.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;coef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x1&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 0.5585879 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We estimate the test power via the upstrap.&lt;/p&gt;
&lt;h4 id=&#34;case-target-sample-size-m--n--50-target-effect-size-as-observed-in-the-sample&#34;&gt;Case: target sample size M = N = 50, target effect size as observed in the sample&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# number of upstrap resamples&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rr&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr_idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;nrow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat[dat_rr_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coef[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out[rr]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# [1] 0.493&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case-target-sample-size-m--100-target-effect-size-as-observed-in-the-sample&#34;&gt;Case: target sample size M = 100, target effect size as observed in the sample&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rr&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr_idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;nrow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat[dat_rr_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coef[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out[rr]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# [1] 0.773&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case-target-sample-size-m--100-target-effect-size-set-to-08&#34;&gt;Case: target sample size M = 100, target effect size set to 0.8&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# update the outcome in the sample to represent the target effect size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dat_upd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dat_upd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_upd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.8&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;coef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x1&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_upd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rr&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B_boot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr_idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;nrow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dat_upd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_upd[dat_rr_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_rr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coef[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out[rr]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pval_rr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# [1] 0.92&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;contributions&#34;&gt;Contributions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Our preprint: Karas, M., Crainiceanu, C.M. (2021) &lt;em&gt;Upstrap for estimating power and sample size in complex models&lt;/em&gt; &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;is available on bioRxiv&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Computing minute-level summary measures of physical activity from raw accelerometry data in R: AC, MIMS, ENMO, MAD, and AI</title>
      <link>https://example.com/post/2021-06-29-pa_measures_and_summarizedactigraphy/</link>
      <pubDate>Sat, 10 Jul 2021 17:19:28 -0400</pubDate>
      <guid>https://example.com/post/2021-06-29-pa_measures_and_summarizedactigraphy/</guid>
      <description>&lt;p&gt;In this post, we:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;use dataset “Labeled raw accelerometry data captured during walking,
stair climbing and driving” that is freely available on PhysioNet;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;derive four minute-level summary measures of physical activity – AC,
MIMS, ENMO, MAD, AI – from raw accelerometry data using
&lt;code&gt;SummarizedActigraphy&lt;/code&gt; R package;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;summarize minute-level summary measures across walking and driving
activities.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#dataset-labeled-raw-accelerometry-data&#34;&gt;Dataset “Labeled raw accelerometry data”&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#computing-minute-level-summary-measures-of-raw-accelerometry-data&#34;&gt;Computing minute-level summary measures of raw accelerometry data&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#summary-measures&#34;&gt;Summary measures&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#summarizedactigraphy-r-package&#34;&gt;SummarizedActigraphy R package&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#preparing-the-data-input&#34;&gt;Preparing the data input&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#computing-the-measures&#34;&gt;Computing the measures&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#minute-level-physical-activity-measures-during-walking-and-driving-activities&#34;&gt;Minute-level physical activity measures during walking and driving activities&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#merging-physical-activity-measures-with-physical-activity-labels&#34;&gt;Merging physical activity measures with physical activity labels&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#visualizing-physical-activity-measures-across-activity-types&#34;&gt;Visualizing physical activity measures across activity types&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolorredcitation-infospan&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;Citation info&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h2 id=&#34;dataset-labeled-raw-accelerometry-data&#34;&gt;Dataset “Labeled raw accelerometry data”&lt;/h2&gt;
&lt;p&gt;The dataset contains raw accelerometry data collected during outdoor
walking, stair climbing, and driving for n=32 healthy adults. It is
freely is available to download on PhysioNet at:
&lt;a href=&#34;https://doi.org/10.13026/51h0-a262&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.13026/51h0-a262&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The study was led by Dr. Jaroslaw Harezlak, assisted by Drs. William
Fadel and Jacek Urbanek.&lt;/li&gt;
&lt;li&gt;Accelerometry data were collected simultaneously at four body
locations: left wrist, left hip, left ankle, and right ankle, at a
sampling frequency of 100 Hz.&lt;/li&gt;
&lt;li&gt;The 3-axial ActiGraph GT3X+ devices were used to collect the data.&lt;/li&gt;
&lt;li&gt;The data include labels of activity type performed for each time
point of data collection (1=walking; 2=descending stairs;
3=ascending stairs; 4=driving; 77=clapping; 99=non-study activity).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We downloaded the data zip from PhysioNet and unpacked. This can be done
manually from the website, or using download the data programmatically.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code to download the data.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;url &amp;lt;- paste0(
  &amp;quot;https://physionet.org/static/published-projects&amp;quot;,
  &amp;quot;/accelerometry-walk-climb-drive&amp;quot;,
  &amp;quot;/labeled-raw-accelerometry-data-captured-during-walking-stair-climbing-and-driving-1.0.0.zip&amp;quot;)
destfile &amp;lt;- paste0(
  &amp;quot;/Users/martakaras/Downloads&amp;quot;,
  &amp;quot;/labeled-raw-accelerometry-data-captured-during-walking-stair-climbing-and-driving-1.0.0.zip&amp;quot;)
# download zip
result &amp;lt;- curl::curl_download(url, destfile = destfile, quiet = FALSE)
# unzip zip 
unzip(zipfile = destfile, exdir = dirname(destfile))
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/br&gt;
&lt;p&gt;First, let’s look at raw accelerometry data of a single subject.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(lme4)
library(knitr)
# remotes::install_github(&amp;quot;muschellij2/SummarizedActigraphy&amp;quot;)
library(SummarizedActigraphy)
library(MIMSunit)
library(activityCounts)
options(digits.secs = 3)
options(scipen=999)

# define path to raw data files directory
raw_files_dir &amp;lt;- paste0(
  &amp;quot;/Users/martakaras/Downloads&amp;quot;,
  &amp;quot;/labeled-raw-accelerometry-data-captured-during-walking-stair-climbing-and-driving-1.0.0&amp;quot;,
  &amp;quot;/raw_accelerometry_data&amp;quot;)

# single participant&#39;s raw accelerometry data
dat_fpaths &amp;lt;- list.files(raw_files_dir, full.names = TRUE)
dat_i &amp;lt;- read_csv(dat_fpaths[1])
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;dat_i

# A tibble: 303,300 x 14
   activity time_s   lw_x   lw_y   lw_z   lh_x   lh_y   lh_z   la_x  la_y   la_z
      &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
 1       99   0.01  0.039  1.02  -0.02  -0.18   1.23   0.023  0.156 0.855 -0.582
 2       99   0.02 -0.629 -0.461  0.973 -0.246  0.137  0.969 -0.707 0.559  0.449
 3       99   0.03 -0.926 -1.26   0.691  0.238 -0.328  1.22  -1.44  1.37   0.367
 4       99   0.04 -0.871 -1.50  -0.246  0.711 -0.484  0.414 -1.66  1.64  -0.543
 5       99   0.05 -0.727 -1.62  -0.559  1.03  -0.297  0.145 -1.76  1.68  -0.918
 6       99   0.06 -0.543 -1.66  -0.629  1.12  -0.246  0.137 -1.80  1.65  -0.988
 7       99   0.07 -0.348 -1.64  -0.609  1.24  -0.426  0.047 -1.76  1.57  -0.992
 8       99   0.08 -0.16  -1.60  -0.566  1.18  -0.539 -0.008 -1.63  1.53  -1.02 
 9       99   0.09 -0.012 -1.53  -0.523  1.03  -0.633 -0.043 -1.13  1.87  -0.738
10       99   0.1   0.117 -1.43  -0.484  0.922 -0.766 -0.047  0.285 1.37  -0.156
# … with 303,290 more rows, and 3 more variables: ra_x &amp;lt;dbl&amp;gt;, ra_y &amp;lt;dbl&amp;gt;,
#   ra_z &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each file contains 14 variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;activity&lt;/code&gt; – type of activity (1=walking; 2=descending stairs;
3=ascending stairs; 4=driving; 77=clapping; 99=non-study activity);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;time_s&lt;/code&gt; – time from device initiation (seconds [s]);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lw_x&lt;/code&gt;, &lt;code&gt;lw_y&lt;/code&gt;, &lt;code&gt;lw_z&lt;/code&gt; – acceleration [&lt;em&gt;g&lt;/em&gt;] measured by a left
wrist-worn sensor at axis x, y, z;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lh_x&lt;/code&gt;, &lt;code&gt;lh_y&lt;/code&gt;, &lt;code&gt;lh_z&lt;/code&gt; – acceleration [&lt;em&gt;g&lt;/em&gt;] measured by a left
hip-worn sensor at axis x, y, z;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;la_x&lt;/code&gt;, &lt;code&gt;la_y&lt;/code&gt;, &lt;code&gt;la_z&lt;/code&gt; – acceleration [&lt;em&gt;g&lt;/em&gt;] measured by a left
ankle-worn sensor at axis x, y, z;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ra_x&lt;/code&gt;, &lt;code&gt;ra_y&lt;/code&gt;, &lt;code&gt;ra_z&lt;/code&gt; – acceleration [&lt;em&gt;g&lt;/em&gt;] measured by a right
ankle-worn sensor at axis x, y, z.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An exemplary few seconds of raw data from of walking and driving
activities, collected by sensors at four different locations:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;loc_id_levels &amp;lt;- c(&amp;quot;lw&amp;quot;, &amp;quot;lh&amp;quot;, &amp;quot;la&amp;quot;, &amp;quot;ra&amp;quot;)
loc_id_labels &amp;lt;- c(&amp;quot;left wrist&amp;quot;, &amp;quot;left hip&amp;quot;, &amp;quot;left ankle&amp;quot;, &amp;quot;right ankle&amp;quot;)
activity_levels &amp;lt;- c(&amp;quot;walking&amp;quot;, &amp;quot;driving&amp;quot;)
plt_df &amp;lt;- 
  dat_i %&amp;gt;%
  filter(activity %in% c(1,4)) %&amp;gt;%
  group_by(activity) %&amp;gt;%
  mutate(time_s = time_s - min(time_s)) %&amp;gt;%
  ungroup() %&amp;gt;%
  filter(time_s &amp;gt;= (5 + 5), time_s &amp;lt; (5 + 10)) %&amp;gt;%
  mutate(activity = recode(activity, &#39;1&#39; = &#39;walking&#39;, &#39;4&#39; = &#39;driving&#39;)) %&amp;gt;%
  pivot_longer(cols = -c(activity, time_s)) %&amp;gt;%
  separate(name, c(&amp;quot;loc_id&amp;quot;, &amp;quot;axis_id&amp;quot;), sep = &amp;quot;_&amp;quot;) %&amp;gt;%
  mutate(activity = factor(activity, levels = activity_levels)) %&amp;gt;%
  mutate(loc_id = factor(loc_id, levels = loc_id_levels, labels = loc_id_labels)) 
plt_raw_data &amp;lt;- 
  ggplot(plt_df, aes(x = time_s, y = value, color = axis_id)) + 
  geom_line() + 
  facet_grid(loc_id ~ activity) + 
  scale_y_continuous(limits = c(-1, 1) * max(abs(plt_df$value))) + 
  labs(y = &amp;quot;Acceleration [g]&amp;quot;,
       x = &amp;quot;Time since activity started [s]&amp;quot;,
       color = &amp;quot;Sensor axis: &amp;quot;) + 
  theme_gray(base_size = 14) + 
  theme(legend.position=&amp;quot;bottom&amp;quot;) + 
  scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;darkgreen&amp;quot;, &amp;quot;blue&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;plt_raw_data
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_raw_data_hue9f9551e4c64133b238545b5cbe9f02d_751533_05d100ef56d110ea312ec855e4541d6c.webp 400w,
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_raw_data_hue9f9551e4c64133b238545b5cbe9f02d_751533_03a15c1218f7793a37623dcfeadf5abc.webp 760w,
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_raw_data_hue9f9551e4c64133b238545b5cbe9f02d_751533_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_raw_data_hue9f9551e4c64133b238545b5cbe9f02d_751533_05d100ef56d110ea312ec855e4541d6c.webp&#34;
               width=&#34;760&#34;
               height=&#34;456&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;computing-minute-level-summary-measures-of-raw-accelerometry-data&#34;&gt;Computing minute-level summary measures of raw accelerometry data&lt;/h2&gt;
&lt;h3 id=&#34;summary-measures&#34;&gt;Summary measures&lt;/h3&gt;
&lt;p&gt;A number of open-source measures have been proposed to aggregate
subsecond-level accelerometry data. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Monitor Independent Movement Summary (MIMS) (&lt;a href=&#34;https://journals.humankinetics.com/view/journals/jmpb/2/4/article-p268.xml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John et al.,
2019&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Euclidean Norm Minus One (ENMO) (&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/25103964/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;van Hees et al.,
2013&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Mean Amplitude Deviation (MAD) (&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/24393233/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vähä-Ypyä et al.,
2015&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Activity Index (AI) (&lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0160644&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bai et al.,
2016&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, attempts have been made to reverse-engineer proprietary
activity counts (AC) generated by ActiLife software from data collected
by ActiGraph accelerometers. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;activityCounts&lt;/code&gt; R package – allows generating “ActiLife counts from
raw acceleration data for different accelerometer brands and it is
developed based on the study done by &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/28604558/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brond et al.,
2017&lt;/a&gt;”.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;summarizedactigraphy-r-package&#34;&gt;SummarizedActigraphy R package&lt;/h3&gt;
&lt;p&gt;We derive the measures using &lt;code&gt;SummarizedActigraphy&lt;/code&gt; R package. The
package was authored by &lt;a href=&#34;https://github.com/muschellij2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Muschelli&lt;/a&gt;
and is available on GitHub
(&lt;a href=&#34;https://github.com/muschellij2/SummarizedActigraphy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;It uses some of the existing R software under the hood to compute some
part of the measures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MIMSunit&lt;/code&gt; R package to compute MIMS,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;activityCounts&lt;/code&gt; R package to compute AC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It computes some other measures straightfoward from their definition,
e.g.: MAD, AI.&lt;/p&gt;
&lt;p&gt;Note: the recommendations in the ENMO paper state data calibration
preprocessing step. I observed an
&lt;a href=&#34;https://github.com/muschellij2/SummarizedActigraphy/issues/2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;issue&lt;/a&gt;
while attempting to run the calibration for files of less than 2h of
duration which is the case for the exemplary data we use here. Therefore, here, we do not use data calibration. However, we
successfully used &lt;code&gt;SummarizedActigraphy&lt;/code&gt; R package to calibrate data and compute ENMO for hundreds
of longer duration data files in the past &amp;ndash; &lt;a href=&#34;https://github.com/muschellij2/blsa_mims/blob/master/code/data_preprocessing/mat_calibrated_to_open_source_measures.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;see this R
script&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-the-data-input&#34;&gt;Preparing the data input&lt;/h3&gt;
&lt;p&gt;We use raw accelerometry data from a wrist-worn sensor.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see notes and code.)
&lt;/summary&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SummarizedActigraphy&lt;/code&gt; R package needs data with observation
timestamp in the form of &lt;code&gt;POSIXct&lt;/code&gt; class. This timestamp column must
be named &lt;code&gt;HEADER_TIME_STAMP&lt;/code&gt;; the specific column naming is needed
due to &lt;a href=&#34;https://github.com/mHealthGroup/MIMSunit/issues/29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;some
issue&lt;/a&gt; reported
for &lt;code&gt;MIMSunit&lt;/code&gt; R package.&lt;/li&gt;
&lt;li&gt;We hence create a “fake” &lt;code&gt;POSIXct&lt;/code&gt; column named
&lt;code&gt;HEADER_TIME_STAMP&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The option &lt;code&gt;options(digits.secs = 3)&lt;/code&gt; was used on the top of this R
script to allow displaying decimal time part.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first demonstrate the code for one participant.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dat_input_i &amp;lt;- 
  dat_i %&amp;gt;% 
  mutate(HEADER_TIME_STAMP = seq(from = ymd_hms(&amp;quot;2021-01-01 00:00:00&amp;quot;), by = 0.01, length.out = nrow(dat_i))) %&amp;gt;%
  select(HEADER_TIME_STAMP, X = lw_x, Y = lw_y, Z = lw_z)
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;dat_input_i

# A tibble: 303,300 x 4
   HEADER_TIME_STAMP            X      Y      Z
   &amp;lt;dttm&amp;gt;                   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
 1 2021-01-01 00:00:00.000  0.039  1.02  -0.02 
 2 2021-01-01 00:00:00.009 -0.629 -0.461  0.973
 3 2021-01-01 00:00:00.019 -0.926 -1.26   0.691
 4 2021-01-01 00:00:00.029 -0.871 -1.50  -0.246
 5 2021-01-01 00:00:00.039 -0.727 -1.62  -0.559
 6 2021-01-01 00:00:00.049 -0.543 -1.66  -0.629
 7 2021-01-01 00:00:00.059 -0.348 -1.64  -0.609
 8 2021-01-01 00:00:00.069 -0.16  -1.60  -0.566
 9 2021-01-01 00:00:00.079 -0.012 -1.53  -0.523
10 2021-01-01 00:00:00.089  0.117 -1.43  -0.484
# … with 303,290 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use package’s helper function to check if sample rate is being
determined correctly (should be 100 Hz).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;get_sample_rate(dat_input_i)

[1] 100
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;h3 id=&#34;computing-the-measures&#34;&gt;Computing the measures&lt;/h3&gt;
&lt;p&gt;We calculate minute-level summary measures: AC, MIMS, ENMO, MAD, AI. The
output shows values of the measures per each minute.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;out_i = SummarizedActigraphy::calculate_measures(
  df = dat_input_i, 
  dynamic_range = c(-8, 8),  # dynamic range
  fix_zeros = FALSE,         # fixes zeros from idle sleep mode -- not needed in our case 
  calculate_mims = TRUE,     # uses algorithm from MIMSunit package
  calculate_ac = TRUE,       # uses algorithm from activityCounts package 
  flag_data = FALSE,         # runs raw data quality control flags algorithm -- not used in our case  
  verbose = FALSE)

======================================================================================

out_i &amp;lt;- out_i %&amp;gt;% select(HEADER_TIME_STAMP = time, AC, MIMS = MIMS_UNIT, ENMO = ENMO_t, MAD, AI)
out_i

# A tibble: 51 × 6
   HEADER_TIME_STAMP            AC  MIMS     ENMO     MAD    AI
   &amp;lt;dttm&amp;gt;                    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1 2021-01-01 00:00:00.000  3623.  19.3  0.0882   0.140    7.62
 2 2021-01-01 00:01:00.000  2460.  14.8  0.0544   0.0971   5.84
 3 2021-01-01 00:02:00.000   648.   6.52 0.00607  0.0192   2.44
 4 2021-01-01 00:03:00.000    36.2  1.86 0.000769 0.00862  1.03
 5 2021-01-01 00:04:00.000  8084.  34.8  0.323    0.316   15.1 
 6 2021-01-01 00:05:00.000 13845.  60.1  0.442    0.358   25.3 
 7 2021-01-01 00:06:00.000 10549.  44.1  0.475    0.248   18.7 
 8 2021-01-01 00:07:00.000 11219.  45.8  0.508    0.244   19.6 
 9 2021-01-01 00:08:00.000 11624.  51.6  0.393    0.338   22.1 
10 2021-01-01 00:09:00.000 11049.  45.8  0.404    0.288   20.0 
# … with 41 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we calculate the measures for all n=32 subjects.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;out_all &amp;lt;- data.frame()
for (dat_fpath_i in dat_fpaths){ #  dat_fpath_i &amp;lt;- dat_fpaths[1]
  message(basename(dat_fpath_i))
  # read data 
  basename_i &amp;lt;- gsub(&amp;quot;.csv&amp;quot;, &amp;quot;&amp;quot;, basename(dat_fpath_i))
  dat_i &amp;lt;- read.csv(dat_fpath_i) 
  # prepare data input
  ts_i &amp;lt;- seq(from = ymd_hms(&amp;quot;2021-01-01 00:00:00&amp;quot;), by = 0.01, length.out = nrow(dat_i))
  dat_input_i &amp;lt;- 
    dat_i %&amp;gt;% 
    mutate(HEADER_TIME_STAMP = ts_i) %&amp;gt;%
    select(HEADER_TIME_STAMP, X = lw_x, Y = lw_y, Z = lw_z)
  # compute the measures 
  out_i = SummarizedActigraphy::calculate_measures(
    df = dat_input_i, 
    dynamic_range = c(-8, 8),  # dynamic range
    fix_zeros = FALSE,         # fixes zeros from idle sleep mode -- not needed in our case 
    calculate_mims = TRUE,     # uses algorithm from MIMSunit package
    calculate_ac = TRUE,       # uses algorithm from activityCounts package 
    flag_data = FALSE,         # runs raw data quality control flags algorithm -- not used in our case  
    verbose = FALSE)
  out_i &amp;lt;- out_i %&amp;gt;% select(HEADER_TIME_STAMP = time, AC, MIMS = MIMS_UNIT, MAD, AI)
  out_i &amp;lt;- mutate(out_i, subj_id = basename_i, .before = everything())
  # append subject-specific measures to all subjects file 
  out_all &amp;lt;- rbind(out_all, out_i)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;h2 id=&#34;minute-level-physical-activity-measures-during-walking-and-driving-activities&#34;&gt;Minute-level physical activity measures during walking and driving activities&lt;/h2&gt;
&lt;h3 id=&#34;merging-physical-activity-measures-with-physical-activity-labels&#34;&gt;Merging physical activity measures with physical activity labels&lt;/h3&gt;
&lt;p&gt;Next, we merge the minute-level physical-activity measures with the
activity labels. We only keep the minutes for which all the measurements
were labelled with no more than one type of activity.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;labels_df_all &amp;lt;- data.frame()
for (dat_fpath_i in dat_fpaths){ #  dat_fpath_i &amp;lt;- dat_fpaths[1]
  message(basename(dat_fpath_i))
  # read data 
  basename_i &amp;lt;- gsub(&amp;quot;.csv&amp;quot;, &amp;quot;&amp;quot;, basename(dat_fpath_i))
  dat_i &amp;lt;- read.csv(dat_fpath_i) 
  # aggregate activity labels
  ts_i &amp;lt;- seq(from = ymd_hms(&amp;quot;2021-01-01 00:00:00&amp;quot;), by = 0.01, length.out = nrow(dat_i))
  labels_df_i &amp;lt;- 
    dat_i %&amp;gt;% 
    mutate(HEADER_TIME_STAMP = ts_i) %&amp;gt;%
    mutate(HEADER_TIME_STAMP = lubridate::floor_date(HEADER_TIME_STAMP, &amp;quot;1 min&amp;quot;)) %&amp;gt;%
    group_by(HEADER_TIME_STAMP) %&amp;gt;%
    filter(n_distinct(activity) == 1) %&amp;gt;%
    filter(row_number() == 1) %&amp;gt;%
    # 1=walking; 2=descending stairs; 3=ascending stairs; 4=driving
    filter(activity %in% c(1,2,3,4)) %&amp;gt;%
    ungroup() %&amp;gt;%
    select(HEADER_TIME_STAMP, activity) 
  labels_df_i &amp;lt;- mutate(labels_df_i, subj_id = basename_i, .before = everything())
  # append subject-specific measures to all subjects file 
  labels_df_all &amp;lt;- rbind(labels_df_all, labels_df_i)
}
# recode activity label
labels_df_all &amp;lt;- labels_df_all %&amp;gt;%
  mutate(activity = recode(activity, &#39;1&#39; = &#39;walking&#39;, &#39;2&#39; = &#39;descending_stairs&#39;, 
                           &#39;3&#39; = &#39;ascending_stairs&#39;, &#39;4&#39; = &#39;driving&#39;))

# merge: 
# (1) physical activity minute-level measures, 
# (2) physical activity minute-level activity labels
out_all_merged &amp;lt;- 
  out_all %&amp;gt;% 
  inner_join(labels_df_all, by = c(&amp;quot;subj_id&amp;quot;, &amp;quot;HEADER_TIME_STAMP&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;out_all_merged

# A tibble: 686 × 8
   subj_id    HEADER_TIME_STAMP           AC  MIMS   ENMO    MAD    AI activity
   &amp;lt;chr&amp;gt;      &amp;lt;dttm&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   
 1 id00b70b13 2021-01-01 00:06:00.000 10549. 44.1  0.475  0.248  18.7  walking 
 2 id00b70b13 2021-01-01 00:07:00.000 11219. 45.8  0.508  0.244  19.6  walking 
 3 id00b70b13 2021-01-01 00:11:00.000 11026. 42.3  0.498  0.215  18.9  walking 
 4 id00b70b13 2021-01-01 00:12:00.000 10561. 42.1  0.486  0.231  19.1  walking 
 5 id00b70b13 2021-01-01 00:13:00.000 13297. 53.9  0.591  0.325  23.1  walking 
 6 id00b70b13 2021-01-01 00:21:00.000  2603. 14.5  0.0501 0.0413  4.80 driving 
 7 id00b70b13 2021-01-01 00:23:00.000   499.  6.65 0.0534 0.0537  3.59 driving 
 8 id00b70b13 2021-01-01 00:24:00.000   398.  6.06 0.0537 0.0496  3.49 driving 
 9 id00b70b13 2021-01-01 00:25:00.000   130.  5.92 0.0542 0.0560  3.67 driving 
10 id00b70b13 2021-01-01 00:26:00.000   414.  7.00 0.0469 0.0561  3.55 driving 
# … with 676 more rows

table(out_all_merged$activity)


driving walking 
    569     117 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;visualizing-physical-activity-measures-across-activity-types&#34;&gt;Visualizing physical activity measures across activity types&lt;/h3&gt;
&lt;p&gt;We visualize values of minute-level physical activity measures. Note
these only used data collected with a sensor located at left wrist.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;name_levels &amp;lt;- c(&amp;quot;AC&amp;quot;, &amp;quot;MIMS&amp;quot;, &amp;quot;ENMO&amp;quot;,  &amp;quot;MAD&amp;quot;, &amp;quot;AI&amp;quot;)
activity_levels &amp;lt;- c(&amp;quot;walking&amp;quot;, &amp;quot;driving&amp;quot;)
# define data subsets with one activity type only 
df_walk &amp;lt;- out_all_merged %&amp;gt;% filter(activity == &amp;quot;walking&amp;quot;) 
df_driv &amp;lt;- out_all_merged %&amp;gt;% filter(activity == &amp;quot;driving&amp;quot;)
# estimate sample population mean for each measure via LMM
measure_mean_vals &amp;lt;- c(
  # walking 
  fixef(lmer(AC ~ (1 | subj_id), data = df_walk))[1],
  fixef(lmer(MIMS ~ (1 | subj_id), data = df_walk))[1],
  fixef(lmer(ENMO ~ (1 | subj_id), data = df_walk))[1],
  fixef(lmer(MAD ~ (1 | subj_id), data = df_walk))[1],
  fixef(lmer(AI ~ (1 | subj_id), data = df_walk))[1],
   # driving 
  fixef(lmer(AC ~ (1 | subj_id), data = df_driv))[1],
  fixef(lmer(MIMS ~ (1 | subj_id), data = df_driv))[1],
  fixef(lmer(ENMO ~ (1 | subj_id), data = df_driv))[1],
  fixef(lmer(MAD ~ (1 | subj_id), data = df_driv))[1],
  fixef(lmer(AI ~ (1 | subj_id), data = df_driv))[1]
)
measure_mean_df &amp;lt;- data.frame(
  value = measure_mean_vals,
  name = rep(name_levels, times = 2),
  activity = rep(activity_levels, each = 5)
)
measure_mean_df_w &amp;lt;- 
  measure_mean_df %&amp;gt;%
  mutate(value = round(value, 2)) %&amp;gt;% 
  pivot_wider(names_from = activity)
# define subject-specific means 
out_all_l &amp;lt;- 
  out_all_merged %&amp;gt;%
  pivot_longer(cols = all_of(name_levels)) 
out_all_l_agg &amp;lt;- 
  out_all_l %&amp;gt;%
  group_by(subj_id, name, activity) %&amp;gt;%
  summarise(value = mean(value))
subj_id_levels &amp;lt;- 
  out_all_l_agg %&amp;gt;%
  filter(name == &amp;quot;AC&amp;quot;, activity == &amp;quot;walking&amp;quot;) %&amp;gt;%
  arrange(desc(value)) %&amp;gt;%
  pull(subj_id)
# mutate data frames used on the plot to have factors at certain levels order
measure_mean_df &amp;lt;- 
  measure_mean_df %&amp;gt;%
  mutate(activity = factor(activity, levels = activity_levels)) %&amp;gt;%
  mutate(name = factor(name, levels = name_levels))
out_all_l &amp;lt;- 
  out_all_l %&amp;gt;%
  mutate(subj_id = factor(subj_id, levels = subj_id_levels),
         activity = factor(activity, levels = activity_levels)) %&amp;gt;%
  mutate(name = factor(name, levels = name_levels))
out_all_l_agg &amp;lt;-
  out_all_l_agg %&amp;gt;%
   mutate(subj_id = factor(subj_id, levels = subj_id_levels),
         activity = factor(activity, levels = activity_levels)) %&amp;gt;%
  mutate(name = factor(name, levels = name_levels))
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;First, we estimated sample population mean for each minute-level measure
via linear mixed model (LMM).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kable(measure_mean_df_w)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;name&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;walking&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;driving&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;AC&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;7616.48&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;801.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;MIMS&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;34.86&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;7.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;ENMO&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.24&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;MAD&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.26&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;AI&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;15.01&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;3.31&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Next, we plot minute-level physical activity measures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;individual measure values (red) for each subject,&lt;/li&gt;
&lt;li&gt;mean measure value (black) for each subject,&lt;/li&gt;
&lt;li&gt;sample population mean for each measure (dashed horizontal line)
estimated via LMM.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On each plot panel, subject IDs (x-axis) are sorted by average AC during
walking (left-top plot panel).&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
(Click to see the code.)
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;plt_measures &amp;lt;- 
  ggplot(out_all_l, 
         aes(x = subj_id, y = value)) + 
  geom_hline(data = measure_mean_df,
             aes(yintercept = value), 
             linetype = 2, size = 0.2) + 
  geom_point(size = 0.5, alpha = 0.3, color = &amp;quot;red&amp;quot;) + 
  geom_point(data = out_all_l_agg, 
             aes(x = subj_id, y = value),
             size = 0.5, color = &amp;quot;black&amp;quot;) + 
  facet_grid(name ~ activity, scales = &amp;quot;free&amp;quot;) + 
  labs(x = &amp;quot;Subject ID&amp;quot;, y = &amp;quot;&amp;quot;) + 
  theme_gray(base_size = 14) +    
  theme(panel.grid.major = element_line(size = 0.3),  
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(size = 6, angle = 90, vjust = 0.5, hjust = 1)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;plt_measures
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_measures_hu5e18c1b0c00dbc82a56a8f0159b07488_728122_ed0f80e02c18d26147fa3724c672fa4a.webp 400w,
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_measures_hu5e18c1b0c00dbc82a56a8f0159b07488_728122_aeb9f7436a863a026572f2f56aff6d82.webp 760w,
               /post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_measures_hu5e18c1b0c00dbc82a56a8f0159b07488_728122_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2021-06-29-pa_measures_and_summarizedactigraphy/plt_measures_hu5e18c1b0c00dbc82a56a8f0159b07488_728122_ed0f80e02c18d26147fa3724c672fa4a.webp&#34;
               width=&#34;760&#34;
               height=&#34;532&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The above plot highlights what are minute-level summary measures of
physical activity from raw accelerometry data: AC, MIMS, ENMO, MAD, and AI,
across two different activities (walking, driving) in the study sample
of n=32 healthy individuals.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I’d like to thank &lt;a href=&#34;https://github.com/muschellij2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Muschelli&lt;/a&gt; for
feedback on this tutorial.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolorredcitation-infospan&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;Citation info&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Please cite &lt;code&gt;SummarizedActigraphy&lt;/code&gt; R package, if applicable.&lt;/p&gt;
&lt;p&gt;Please cite raw accelerometry dataset DOI, if applicable (go to see
&lt;a href=&#34;https://physionet.org/content/accelerometry-walk-climb-drive/1.0.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this dataset citation
options&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>All past updates</title>
      <link>https://example.com/resources/recently-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/resources/recently-all/</guid>
      <description>&lt;h4 id=&#34;2023&#34;&gt;2023&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;[2023-03-06] Our paper &lt;a href=&#34;https://www.nature.com/articles/s41746-023-00778-y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Wearable device and smartphone data can track ALS disease progression and may serve as novel clinical trial outcome measures&amp;rdquo;&lt;/a&gt; is published. This work
investigates whether mobile applications and wearable devices can be used to quantify ALS disease progression through active (surveys) and passive (sensors) data collection. &lt;/br&gt;&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2022&#34;&gt;2022&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;[2022-11-21] Our preprint &lt;a href=&#34;https://doi.org/10.21203/rs.3.rs-2248487/v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Wearable device and smartphone data can track ALS disease progression and may serve as novel clinical trial outcome measures&amp;rdquo;&lt;/a&gt; is out. This work
investigates whether mobile applications and wearable devices can be used to quantify ALS disease progression through active (surveys) and passive (sensors) data collection. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-10-25] Our preprint &lt;a href=&#34;https://doi.org/10.21203/rs.3.rs-2183645/v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Performance analyses of step-counting algorithms using wrist accelerometry&amp;rdquo;&lt;/a&gt; is available online. This work evaluates  performance of several modern wrist-accelerometry-based algorithms for step count estimation using a common dataset with various continuous walking trials. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-07-27] Our paper &lt;a href=&#34;https://martakarass.github.io/docs/papers/Matabuena_2022_estimating_knee_movement_patterns.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Estimating knee movement patterns of recreational runners across training sessions using multilevel functional regression models&amp;rdquo;&lt;/a&gt; is published. This work can serve as a reference for practitioners modeling repeated functional measures at different resolution levels in the context of biomechanics and sports science applications. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-07-22] Our paper &lt;a href=&#34;https://mhealth.jmir.org/2022/7/e38077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Comparison of Accelerometry-Based Measures of Physical Activity: Retrospective Observational Data Analysis Study&amp;rdquo;&lt;/a&gt; is published. This work provides comparison and harmonization mapping between minute-level accelerometry-derived measures (ActiGraph AC, MIMS, ENMO, MAD, AI). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-07-13] Our paper &lt;a href=&#34;https://www.nature.com/articles/s41598-022-16003-x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Quantification of acceleration as activity counts in ActiGraph wearables&amp;rdquo;&lt;/a&gt; is out. This work publishes activity counts algorithm from ActiGraph&amp;rsquo;s ActiLife and CentrePoint. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-04-27] I was elected as a member of the &lt;a href=&#34;https://publichealth.jhu.edu/alumni/the-delta-omega-public-health-honorary-society-alpha-chapter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alpha chapter&lt;/a&gt; of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Delta_Omega&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Delta Omega Society&lt;/a&gt;. A nice certificate I received is available &lt;a href=&#34;https://martakarass.github.io/docs/delta_omega_cert.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-01-13] Our paper &lt;a href=&#34;https://doi.org/10.1093/gerona/glac013&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Free-living gait cadence measured by wearable accelerometer: a promising alternative to traditional measures of mobility for assessing fall risk&amp;rdquo;&lt;/a&gt; is published. We showed that in community-dwelling older adults, free-living walking cadence was significantly related to fall rates (while clinic-based mobility measures were not).&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2022-01-01] For my first post-grad role, I accepted a postdoctoral researcher position at the &lt;a href=&#34;https://www.hsph.harvard.edu/onnela-lab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Onnela Lab&lt;/a&gt; at Harvard University. I will be working at methods for digital phenotyping and its applications.&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2021&#34;&gt;2021&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I defended my PhD thesis &amp;ldquo;Statistical Methods for Wearable Device Data and Sample Size Calculation in Complex Models&amp;rdquo;! My &lt;a href=&#34;https://martakarass.github.io/docs/PhD_defense_slides.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;defense slides&lt;/a&gt;, with video recording linked, are available. I published the &lt;a href=&#34;https://martakarass.github.io/docs/PhD_thesis_acknowledgements.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Acknowledgements and Dedication&lt;/a&gt; parts of the thesis.&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I received Travel Reimbursement Award to &lt;a href=&#34;https://projects.iq.harvard.edu/cnoc-symposium/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3rd Annual Health Data Science Symposium&lt;/a&gt; at Harvard to present our work on harmonization of open-source and proprietary accelerometry-based physical activity measures in Nov 2021. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our preprint &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.08.21.457220v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Upstrap for estimating power and sample size in complex models&amp;rdquo;&lt;/a&gt; is available on bioRxiv. We evaluate power estimation properties of the upstrap and provide a series of &amp;ldquo;read, adapt and use&amp;rdquo; R code examples for simple and complex settings, including GLMM. See the relevant &lt;a href=&#34;https://martakarass.github.io/project/project_upstrap/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project page&lt;/a&gt;.&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I &lt;a href=&#34;https://twitter.com/actigraph/status/1433438451635048451&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;received Student Poster Sponsorship&lt;/a&gt; and will present our work on harmonization of open-source and proprietary accelerometry-based physical activity measures during the &lt;a href=&#34;https://adds.actigraphcorp.com/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ActiGraph Digital Data Summit&lt;/a&gt; in Nov 2021. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am a co-instructor for &lt;a href=&#34;http://jhudatascience.org//intro_to_r/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to R for Public Health Researchers&lt;/a&gt; Summer Institute week-long course. All class materials are available online. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/34049292/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Estimation of free-living walking cadence from wrist-worn sensor accelerometry data and its association with SF-36 quality of life scores&amp;rdquo;&lt;/a&gt; is published. Check out the &lt;a href=&#34;https://github.com/martakarass/walking-segmentation-free-living-wrist&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repo&lt;/a&gt; showing examples of using our method for automatic walking strides segmentation from wrist-worn sensor accelerometry data collected in the free-living environment. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I received the &lt;a href=&#34;http://www.jhsph.edu/departments/biostatistics/about-us/honors-and-awards/#dublin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Louis I. and Thomas D. Dublin Award&lt;/a&gt; for the Advancement of Epidemiology and Biostatistics for work on open-source physical activity measurements. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I received the &lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/about-us/honors-and-awards/#helen-abbey&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Helen Abbey Award&lt;/a&gt; for excellence in teaching. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Connectivity‐informed adaptive regularization for generalized outcomes&amp;rdquo;&lt;/a&gt; is published. We proposed riPEER (ridgified Partially Empirical Eigenvectors for Regression) extension to generalized linear regression, addressing both theoretical and computational issues. See the relevant &lt;a href=&#34;https://martakarass.github.io/project/project_mdpeer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project page&lt;/a&gt;. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2020&#34;&gt;2020&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://www.karger.com/Article/FullText/511531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Predicting Subjective Recovery from Lower Limb Surgery Using Consumer Wearables&amp;rdquo;&lt;/a&gt; is published. We showed that passively collected wearable PGHD can capture post-surgery physical activity changes relative to individual&amp;rsquo;s baseline, and baseline data can improve prediction of self-reported recovery time at 4 weeks post surgery. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;During the upcoming workshop &amp;ldquo;The Future of Digital Health&amp;rdquo;, I will give a talk highlighting &amp;ldquo;Predicting subjective recovery from lower limb surgery using consumer wearables&amp;rdquo; paper I co-authored. This workshop will highlight key papers from the newly released &lt;a href=&#34;https://pages.evidation.com/karger-special-issue&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Special Issue of Digital Biomarkers&lt;/a&gt;, sponsored by &lt;a href=&#34;https://evidation.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evidation Health&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/company/dime-society/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DiMe&lt;/a&gt;. Register for the workshop &lt;a href=&#34;https://us02web.zoom.us/webinar/register/WN_ugdWjno7S5ummYWYPX_s3w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;During summer of 2020, I am working as a Data Science Intern in Digital Measures team @ &lt;a href=&#34;https://evidation.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evidation Health&lt;/a&gt;. My main project aims at estimating medical procedure recovery trajectories and predicting recovery time from wearable patient-generated health data. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why R? Foundation awards a &lt;a href=&#34;http://whyr.pl/foundation/supporting-grant/#scientific-committee&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;supporting grant for Women in Data Science&lt;/a&gt; to aid exceptional female data scientists in Poland. I serve as a member of Scientific committee for this initiative. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2019&#34;&gt;2019&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I passed my preliminary schoolwide oral exam. My Committee consisted of three faculty from the Dept. of Biostatistics, one faculty from Dept. of Epidemiology, and one faculty from the Dept. of Medicine. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I received Leadership, Empowerment and Learning Culture &lt;a href=&#34;https://example.com/docs/certificates/2019-10-09-Novartis_LELC_US_Bios_Award_Certificate_Marta_Karas.pdf&#34;&gt;Award&lt;/a&gt; during Novartis US Analytics Conference 2019. My conference talk presented the work done as a Sensor Data Analytics Intern with Novartis in Basel, Switzerland during summer 2019. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our paper &amp;ldquo;&lt;em&gt;Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation&lt;/em&gt;&amp;rdquo; just got published in
&lt;em&gt;Biostatistics&lt;/em&gt; with the journal&amp;rsquo;s highest reproducibility status! See &lt;a href=&#34;https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz033/5572661?guestAccessKey=f3abdf65-a94d-4509-b7e9-cca2ff384528&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ADEPT article&lt;/a&gt; online. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our R package &lt;code&gt;adept&lt;/code&gt; that implements ADEPT pattern-segmentation method is out on CRAN (&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;. The vignette shows example of strides segmentation from raw accelerometry data of 25min outdoor run w/ walking and resting bouts. Listed May 2019 top 40 new CRAN packages. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am working as Sensor Data Analytics Intern with Novartis pharmaceutical company in Basel, Switzerland this summer. I am also &lt;a href=&#34;https://martakarass.github.io/talk/2019-06-26-icampam/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;presenting&lt;/a&gt; at ICAMPAM 2019 conference on Jun 26 in Maastricht, the Netherlands. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our R package &lt;code&gt;runstats&lt;/code&gt; that provides methods for fast computation of running sample statistics for time series is out on CRAN (&lt;a href=&#34;https://cran.r-project.org/web/packages/runstats/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). Use &lt;code&gt;runstats&lt;/code&gt; to compute  (1) mean, (2) standard deviation, and (3) variance over a fixed-length window of time-series, (4) correlation, (5) covariance, and (6) Euclidean distance (L2 norm) between short-time pattern and time-series. Implemented methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our recent article &amp;ldquo;Accelerometry Data in Health Research: Challenges and Opportunities&amp;rdquo; is now published and &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6874221/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available online&lt;/a&gt;. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2018&#34;&gt;2018&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Interested in statistical methodology for singal processing in physical activity research? Come to JSM &lt;a href=&#34;https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/ActivityDetails.cfm?SessionID=215216&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;session&lt;/a&gt; on Wednesday (8/1/2018), 2:00 PM - 3:50 PM. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://whyr2018.pl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WhyR? 2018&lt;/a&gt; conference starts on July 2nd in Wroclaw, Poland. Both academia and industry professionals meet and discuss experiences in R software development and analysis applications. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am working as a Research Assistant with Drs. &lt;a href=&#34;https://jacekurbanek.wordpress.com/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jacek Urbanek&lt;/a&gt; and &lt;a href=&#34;http://www.ciprianstats.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ciprian Crainiceanu&lt;/a&gt; this summer at a novel approach for identifying individual working strides from subsecond accelerometry data of walking.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>All posts</title>
      <link>https://example.com/resources/posts-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/resources/posts-all/</guid>
      <description>&lt;h3 id=&#34;2022&#34;&gt;2022&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/2022-04-27-rmcorr_vs_lmm&#34;&gt;Repeated Measures Correlation (rmcorr): when may be not an ideal choice to quantify the association&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/2022-01-05-gps_strava_read_and_viz&#34;&gt;GPS data in R: parse and plot GPX data exported from Strava&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2021&#34;&gt;2021&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/2021-06-29-pa_measures_and_summarizedactigraphy&#34;&gt;Computing minute-level summary measures of physical activity from raw accelerometry data in R: AC, MIMS, ENMO, MAD, and AI&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/project_upstrap&#34;&gt;Upstrap for estimating power and sample size in complex models&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2019&#34;&gt;2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/2019-10-28-ttest-versus-ztest&#34;&gt;When to use t distribution versus normal distribution quantiles in constructing confidence interval for the mean&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/2019-01-26-favs-of-rstudio2019-conference&#34;&gt;Favourite topics seen at RStudio conference 2019&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/project_runstats&#34;&gt;runstats R package: fast computation of running statistics for time series&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/project_adeptdata&#34;&gt;adeptdata R package: raw accelerometry data sets and their derivatives&lt;/a&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;../../post/project_adept&#34;&gt;Adaptive empirical pattern transformation (ADEPT): a fast, scalable, and accurate method for pattern segmentation in time series&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2018&#34;&gt;2018&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../../post/2018-09-02-applying-for-phd-in-usa&#34;&gt;(In Polish) Aplikacja na studia doktoranckie (Biostatystyka) w USA: notatki nt. procesu rekrutacji&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2017&#34;&gt;2017&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../../post/project_mdpeer&#34;&gt;Brain connectivity-informed regularization methods for regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>All publications</title>
      <link>https://example.com/resources/publications-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/resources/publications-all/</guid>
      <description>&lt;p&gt;* Joint first co-authorship.&lt;/p&gt;
&lt;h3 id=&#34;2023&#34;&gt;2023&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tracking ALS disease progression using passively collected smartphone sensor data&lt;/strong&gt; by Karas, M.*, Olsen, J.*, Straczkiewicz, M., Johnson, S. A., Burke, K. M., Iwasaki, S., Lahav, A., Scheier, Z. A., Clark, A. P., Iyer, A. S., Huang, E., Berry, J. D., &amp;amp; Onnela, J.-P. (2023). [Preprint].
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.2139/ssrn.4526533&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preprint&lt;/a&gt; |
&lt;a href=&#34;https://github.com/onnela-lab/als-beiwe-passive-data&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wearable device and smartphone data quantify ALS progression and may provide novel outcome measures&lt;/strong&gt; by
Johnson, S. A.*, Karas, M.*, Burke, K. M., Straczkiewicz, M., Scheier, Z. A., Clark, A. P., Iwasaki, S., Lahav, A., Iyer, A. S., Onnela, J.-P., &amp;amp; Berry, J. D. (2023). Npj Digital Medicine, 6(1), 34.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1038/s41746-023-00778-y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/onnela-lab/als-wearables&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estimating knee movement patterns of recreational runners across training sessions using multilevel functional regression models&lt;/strong&gt; by Matabuena, M.*, Karas, M.*, Riazati, S., Caplan, N., &amp;amp; Hayes, P. R. (2023).  The American Statistician, 77(2), 169–181.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/papers/Matabuena_2022_estimating_knee_movement_patterns.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preprint&lt;/a&gt; |
&lt;a href=&#34;https://doi.org/10.1080/00031305.2022.2105950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/martakarass/biomechanics-manuscript&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Free-living gait cadence measured by wearable accelerometer: a promising alternative to traditional measures of mobility for assessing fall risk&lt;/strong&gt; by Urbanek, J. K., Roth, D. L., Karas, M., Wanigatunga, A. A., Mitchell, C. M., Juraschek, S. P., Cai, Y., Appel, L. J., &amp;amp; Schrack, J. A. (2023). The Journals of Gerontology: Series A, 78(5), 802–810.
&lt;/br&gt;
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10172982/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PubMed&lt;/a&gt; |
&lt;a href=&#34;https://doi.org/10.1093/gerona/glac013&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2022&#34;&gt;2022&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Quantification of acceleration as activity counts in ActiGraph wearable.&lt;/strong&gt; by Neishabouri, A., Nguyen, J., Samuelsson, J., Guthrie, T., Biggs, M., Wyatt, J., Cross, D., Karas, M., Migueles, J. H., Khan, S., &amp;amp; Guo, C. C. (2022). Scientific Reports, 12(1), 11958.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1038/s41598-022-16003-x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/actigraph/agcounts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Comparison of accelerometry-based measures of physical activity: retrospective observational data analysis study&lt;/strong&gt; by Karas, M.*, Muschelli, J.*, Leroux, A., Urbanek, J. K., Wanigatunga, A. A., Bai, J., Crainiceanu, C. M., &amp;amp; Schrack, J. A. (2022). JMIR mHealth and uHealth, 10(7), e38077.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.2196/38077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/muschellij2/blsa_mims&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Performance analyses of step-counting algorithms using wrist accelerometry&lt;/strong&gt; by Pilkar, R., Gerstel, D., Toole, E., Biggs, M., Guthrie, T., Karas, M., Achkar, C. M. E., Renevey, P., Soltani, A., Sloan, S., Nguyen, J., Patterson, M. R., Ferrario, D., Lemay, M., Neishabouri, A., &amp;amp; Guo, C. (2022). [Preprint].
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.21203/rs.3.rs-2183645/v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preprint&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Smartphone-based gait cadence to identify older adults with decreased functional capacity&lt;/strong&gt; by Rubin, D. S., Ranjeva, S. L., Urbanek, J. K., Karas, M., Madariaga, M. L. L., &amp;amp; Huisingh-Scheetz, M. (2022). Digital Biomarkers, 6(2), 61–70.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1159/000525344&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2021&#34;&gt;2021&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upstrap for estimating power and sample size in complex models&lt;/strong&gt; by Karas, M., &amp;amp; Crainiceanu, C. M. (2021).  [Preprint].
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1101/2021.08.21.457220&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preprint&lt;/a&gt; |
&lt;a href=&#34;https://github.com/martakarass/upstrap_manuscript&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation&lt;/strong&gt; by Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C. M., &amp;amp; Urbanek, J. K. (2021). Biostatistics, 22(2), 331–347.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1093/biostatistics/kxz033&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/martakarass/adept-manuscript&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; |
&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software (R)&lt;/a&gt; |
&lt;a href=&#34;https://pypi.org/project/pyadept/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software (Python)&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estimation of free-living walking cadence from wrist-worn sensor accelerometry data and its association with SF-36 quality of life scores&lt;/strong&gt; by Karas, M., Urbanek, J. K., Illiano, V. P., Bogaarts, G., Crainiceanu, C. M., &amp;amp; Dorn, J. F. (2021). Physiological Measurement, 42(6), 065006.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/papers/Karas_2021_estimation_of_free_living_walking_cadence_from_wrist.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preprint&lt;/a&gt; |
&lt;a href=&#34;https://doi.org/10.1088/1361-6579/ac067b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://github.com/martakarass/walking-segmentation-free-living-wrist&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; |
&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Connectivity‐informed adaptive regularization for generalized outcomes&lt;/strong&gt; by Brzyski, D., Karas, M., M Ances, B., Dzemidzic, M., Goñi, J., W Randolph, T., &amp;amp; Harezlak, J. (2021). Canadian Journal of Statistics, 49(1), 203–227. &lt;/br&gt;
&lt;a href=&#34;https://onlinelibrary.wiley.com/share/author/UZEZIW4R9KMHH4URWJH4?target=10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2020&#34;&gt;2020&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Predicting subjective recovery from lower limb surgery using consumer wearables&lt;/strong&gt; by Karas, M., Marinsek, N., Goldhahn, J., Foschini, L., Ramirez, E., &amp;amp; Clay, I. (2020). Digital Biomarkers, 4(Suppl. 1), 73–86.
&lt;/br&gt;
&lt;a href=&#34;https://doi.org/10.1159/000511531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2019&#34;&gt;2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accelerometry data in health research: challenges and opportunities. Review and examples&lt;/strong&gt; by Karas, M., Bai, J., Strączkiewicz, M., Harezlak, J., Glynn, N. W., Harris, T., Zipunnikov, V., Crainiceanu, C., &amp;amp; Urbanek, J. K. (2019). Statistics in Biosciences, 11(2), 210–237.
&lt;/br&gt;
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6874221/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PubMed&lt;/a&gt; |
&lt;a href=&#34;https://doi.org/10.1007/s12561-018-9227-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Brain connectivity-informed regularization methods for regression&lt;/strong&gt; by Karas, M., Brzyski, D., Dzemidzic, M., Goñi, J., Kareken, D. A., Randolph, T. W., &amp;amp; Harezlak, J. (2019). Statistics in Biosciences, 11(1), 47–90.
&lt;/br&gt;
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6583926/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PubMed&lt;/a&gt; |
&lt;a href=&#34;https://doi.org/10.1007/s12561-017-9208-x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal&lt;/a&gt; |
&lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>All talks</title>
      <link>https://example.com/resources/talks-all/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/resources/talks-all/</guid>
      <description>&lt;h3 id=&#34;2023&#34;&gt;2023&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wearable device and smartphone data for tracking ALS disease progression&lt;/strong&gt;, talk, Digital Health Innovation Summit, July 7, 2023, San Francisco, CA, 2023.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/slides/2023-06-05-martakaras_ALS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2022&#34;&gt;2022&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wearable devices can track ALS disease progression and may serve as novel clinical trial outcome measures&lt;/strong&gt;, poster, ActiGraph Digital Data Summit 2022, Nov 13, 2022, Pensacola Beach, FL, USA.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Comparison of accelerometry-based measures of physical activity&lt;/strong&gt;, talk, JSM, Aug 8, 2023, Washington, DC, USA.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/slides/2022-08-05-JSM_2022.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Smartphone devices data in health research: opportunities and challenges&lt;/strong&gt;, talk, Wearable and Implantable Technology group meeting (Department of Biostatistics, Johns Hopkins University), Mar 4, 2022, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/slides/2022-03-04-wit.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2021&#34;&gt;2021&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Harmonization of open-source and proprietary accelerometry-based physical activity measures&lt;/strong&gt;, talk, 3rd Annual Health Data Science Symposium: Smartphones, Wearables, and Health, Nov 5, 2021, Boston, MA, USA.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Statistical methods and modeling of person-generated health data from wearable and mobile devices&lt;/strong&gt;, talk, Onnela Lab meeting (Department of Biostatistics, Harvard University), Jul 28, 2021, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accelerometry-based physical activity measures across NHANES waves. Comparison of five minute-level measures: AC, MIMS, ENMO, MAD, AI&lt;/strong&gt;, talk, Wearable and Implantable Technology group meeting (Department of Biostatistics, Johns Hopkins University), May 13, 2021, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;National Health and Nutrition Examination Survey (NHANES) and comparability of accelerometry-derived physical activity measures across NHANES waves&lt;/strong&gt;, talk, ENGAGE lab meeting (Department of Epidemiology, Johns Hopkins University), May 6, 2021, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Comparison of accelerometry-derived physical activity summary measures by age, sex, and BMI&lt;/strong&gt;, talk, The Epidemiology and Biostatistics of Aging (EBA) Training Program: 6th Annual Joint Presentation of the SMART/ WIT, ENGAGE, and BHS Lab groups, Apr 27, 2021, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=CyCN6X3kwng&amp;amp;t=117s&amp;amp;ab_channel=JohnsHopkinsEBATrainingProgram&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2020&#34;&gt;2020&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estimation of free-living walking cadence from wrist-worn sensor accelerometry data and its association with SF-36 quality of life scores&lt;/strong&gt;, talk, CMStatistics 2020, Dec 20, 2020, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;arctools R package: Processing and physical activity summaries of minute level activity data&lt;/strong&gt;, talk, Wearable and Implantable Technology group meeting (Department of Biostatistics, Johns Hopkins University), Dec 17, 2020, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://cran.r-project.org/web/packages/arctools/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; |
&lt;a href=&#34;https://docs.google.com/presentation/d/1Ly-193VBn97WhuF8d9YFyeNVQzngLEPezLhtASSDgCw/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Predicting subjective recovery from lower limb surgery using consumer wearables&lt;/strong&gt;, talk, Workshop ‘The Future of Digital Health’, Dec 8, 2020, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://docs.google.com/presentation/d/1qSS4wweLBAcqoxKZiUQZF0PGg3Y4e_161quQWdrVUL0/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt; |
&lt;a href=&#34;https://www.youtube.com/watch?v=E74PiCg1vI8&amp;amp;feature=youtu.be&amp;amp;ab_channel=DimeSociety&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Recent developments in R tidyverse&lt;/strong&gt;, talk, Computing Club (Department of Biostatistics, Johns Hopkins University), Dec 1, 2020, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/talk/2020-12-01-computing_club/slides2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt; |
&lt;a href=&#34;https://drive.google.com/file/d/1G2HeuRUqseKHWBcpRV-gJlUjpu9cLwAt/view&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Summer internship project: Predicting subjective recovery from lower limb surgery using consumer wearables&lt;/strong&gt;, talk, Wearable and Implantable Technology group meeting (Department of Biostatistics, Johns Hopkins University), Sep 30, 2020, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Novel approach for precise walking cadence estimation from high-density tri-axial accelerometry data collected at wrist in free-living&lt;/strong&gt;, talk, 41st Annual Conference of the International Society for Clinical Biostatistics, Aug 27, 2020, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;arctools: R software for computing summaries of minute-level physical activity data&lt;/strong&gt;, talk, ENGAGE lab meeting (Department of Epidemiology, Johns Hopkins University), Jun 4, 2020, virtual.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Precise walking strides segmentation from raw accelerometry data: ADEPT method&lt;/strong&gt;, talk, Webinar for OSS developers in physical behavior field, Mar 11, 2020, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/adept/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; |
&lt;a href=&#34;https://docs.google.com/presentation/d/1ThrdQnFIfRH72fkNdpaiBaxdRB2brWvRgE1cT5hlA3A/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Towards precise walking strides segmentation from accelerometry data in free-living: ADEPT method and further developments&lt;/strong&gt;, talk,
BIRS: Use of Wearable and Implantable Devices in Health Research, Feb 25, 2020, Banff, Alberta, Canada.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2019&#34;&gt;2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Functional registration of walking strides in high-density accelerometry data for estimation of gait asymmetry&lt;/strong&gt;, talk, CFE-CMStatistics 2019 conference, Dec 16, 2019, London, UK.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Methods for fast processing of time-series: runstats R package&lt;/strong&gt;, talk, Webinar for OSS developers in physical behavior field, Nov 5, 2019, virtual.
&lt;/br&gt;
&lt;a href=&#34;https://github.com/martakarass/runstats&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; |
&lt;a href=&#34;https://martakarass.github.io/docs/slides/2019-11-05-3rd-webinar-oss-runstats%20developers.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Considerations in statistical modeling of walking features derived from wrist-worn sensor in free-living&lt;/strong&gt;, talk, Wearable and Implantable Technology group meeting (Department of Biostatistics, Johns Hopkins University), Oct 31, 2019, Baltimore, MD, USA.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overview of JHU Biostat Wearable and Implantable Technology (WIT) working group research&lt;/strong&gt;, talk, Journal Club (Department of Biostatistics, Johns Hopkins University), Oct 15, 2019, Baltimore, MD, USA.
&lt;/br&gt;
&lt;a href=&#34;https://docs.google.com/presentation/d/1TAPuMzQmeB9GP06FNKmoXAcPDt9A9_h4NhJSRtoapMY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Walking measurements derived from free-living wrist-worn sensor as novel digital endpoints&lt;/strong&gt;, talk, Novartis 2019 US Analytics Conference - Digital Endpoint Analytics Session, Oct 8, 2019, East Hanover, NJ.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automatic estimation of step asymmetry in a split-belt treadmill experiment using high-resolution accelerometry data&lt;/strong&gt;, talk, ICAMPAM 2019 conference, Jun 26, 2019, Maastricht, the Netherlands.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Physical activity monitoring with wearable accelerometers: strides segmentation, gait pattern estimation and walking detection from free-living data in R. Also: highlights from RStudio 2019 conference.&lt;/strong&gt;, talk, STWUR 11: Physical activity monitoring with wearable accelerometers, May 23, 2019, Wroclaw, Poland.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stride segmentation and stride pattern estimation based on accelerometry data&lt;/strong&gt;, talk, Motion Analysis Laboratory meeting, May 14, 2019, Baltimore, MD, USA.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simulation experiment project for Seminar on Adaptive Clinical Trials&lt;/strong&gt;, talk, PhD Seminar on Adaptive Clinical Trials (Department of Biostatistics, Johns Hopkins University), Apr 17, 2019, Baltimore, MD, USA.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/docs/slides/2019-04-17-Adaptive-Designs-Seminar-final-presentation.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Some of the topics seen at RStudio conference 2019&lt;/strong&gt;, talk, Computing Club (Department of Biostatistics, Johns Hopkins University), Feb 12, 2019, Baltimore, MD, USA.
&lt;/br&gt;
&lt;a href=&#34;https://martakarass.github.io/resources/computing_club_materials/2019-02-12-seen-at-rstudio2019-conf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2018&#34;&gt;2018&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ADaptive Empirical Pattern Transformation (ADEPT) with application to walking stride segmentation&lt;/strong&gt;, talk, JSM 2018, Aug 1, 2018, Vancouver, Canada.
&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wearable accelerometers, accelerometry data and automatic steps segmentation in R: strideter and convo R packages&lt;/strong&gt;, talk, Why R? 2018 Conference, Jul 3, 2018, Wroclaw, Poland.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive empirical pattern transformation (ADEPT)</title>
      <link>https://example.com/post/project_adept/</link>
      <pubDate>Fri, 06 Dec 2019 11:54:53 -0400</pubDate>
      <guid>https://example.com/post/project_adept/</guid>
      <description>&lt;p&gt;We propose adaptive empirical pattern transformation (ADEPT), a fast, scalable, and accurate method for pattern segmentation in time-series.&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to provide fast and accurate open-source method for pattern segmentation from raw accelerometry data.&lt;/p&gt;
&lt;p&gt;The methods were needed for automated walking strides segmentation from accelerometry recordings collected during continuous walking that we had across a number of health studies.&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;The plot below shows an example of raw accelerometry data &amp;ndash; three-dimensional time-series of acceleration [&lt;em&gt;g&lt;/em&gt;] measurements. Data showed were collected 5 s of walking for two different individuals, with 4 wearable sensors worn simultaneously at wrist, hip, left, and right ankle.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_adept/intro_3d_acc_huf4bf13b2a325ec4783166d44a7e48d77_620976_5694baef7845183fe6dfc1b2e790e3dd.webp 400w,
               /post/project_adept/intro_3d_acc_huf4bf13b2a325ec4783166d44a7e48d77_620976_3e606f6be2732850c2a96a77265e0a22.webp 760w,
               /post/project_adept/intro_3d_acc_huf4bf13b2a325ec4783166d44a7e48d77_620976_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/project_adept/intro_3d_acc_huf4bf13b2a325ec4783166d44a7e48d77_620976_5694baef7845183fe6dfc1b2e790e3dd.webp&#34;
               width=&#34;760&#34;
               height=&#34;418&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;While the repetitive patterns of walking are relatively clear to a human observer, there are a few challenges in segmenting them accurately with an algorithm:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There are variations in shape, magnitude and duration of a pattern within individual&amp;rsquo;s data. These might be e.g. due to terrain elevation changes, or temporal changes of step length and cadence (think about slowing down when approaching the turn of the corridor, or basically walking slower during an evening stroll versus morning rush to work). &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is variability of walking data between individuals (e.g. see the plot above).  &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A sensor can move, or be worn on different hands by the same person on different days.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose adaptive empirical pattern transformation (ADEPT) to segment walking stride patterns in vector magnitude of raw accelerometry data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The ADEPT algorithm uses a predefined template and detects its repetitions by maximizing the local distance (i.e. correlation) between (a) collection of scale-transformed templates and (b) the observed data signal. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The scale-transformation adjusts the duration of the dictionary template, allowing for the detection of patterns that are shorter or longer than the original dictionary template. &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple distinct baseline templates can be used simultaneously to account for various shape patterns occurring in the data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The GIF below demonstrates the big picture of the algorithm.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://example.com/post/project_adept/adept_concept3.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The underlying template&amp;rsquo;s scaling and translating along the observed data signal is closely related to the Continuous Wavelet Transform (CWT), $$W_{\Psi}(s, \tau)  =
\int_{-\infty}^{\infty} x(t) \frac{1}{\sqrt{s}}\Psi \left(\frac{t - \tau}{s} \right)dt.$$
Conversely to CWT&amp;rsquo;s mother wavelet $\Psi(\cdot)$, ADEPT  uses a data-based pattern function (not required to satisfy the wavelet admissibility condition) and comes with a number of other algorithm features tailored for its target application.&lt;/p&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We published the proposed ADEPT method in work &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/5572661&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation&lt;/a&gt; Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331–347.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed ADEPT  method in R package adept (&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The R package is accompanied by two vignettes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/vignettes/adept-intro.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to adept package&lt;/a&gt;,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/adept/vignettes/adept-strides-segmentation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Walking strides segmentation with adept&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;#x1f389; The adept R package was selected in Top 40 new CRAN packages in May 2019 (&lt;a href=&#34;https://rviews.rstudio.com/2019/06/25/may-2019-top-40-new-cran-packages/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;list link&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image. Figure 2 in the manuscript: Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331–347. &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/557266&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt; (last accessed on May 26, 2021).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Three-dimensional time-series image. Figure 1 in the manuscript: Karas, M., Straczkiewicz, M., Fadel, W., Harezlak, J., Crainiceanu, C.M., Urbanek, J.K. Adaptive empirical pattern transformation (ADEPT) with application to walking stride segmentation (2018). &lt;em&gt;Biostatistics&lt;/em&gt;, Volume 22, Issue 2, April 2021, Pages 331–347. &lt;a href=&#34;https://academic.oup.com/biostatistics/article/22/2/331/557266&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt; (last accessed on May 26, 2021).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>When to use t distribution versus normal distribution quantiles in constructing confidence interval for the mean</title>
      <link>https://example.com/post/2019-10-28-ttest-versus-ztest/</link>
      <pubDate>Mon, 28 Oct 2019 17:19:28 -0400</pubDate>
      <guid>https://example.com/post/2019-10-28-ttest-versus-ztest/</guid>
      <description>&lt;p&gt;To construct confidence interval for the mean, we often use quantiles of standardized sample mean distribution. Here, I include a list of cases where I&amp;rsquo;d use quantiles of t-distribution versus quantiles of normal distribution for that purpose.&lt;/p&gt;
&lt;p&gt;Note: the below text could be directly translated to answer when to use t-test versus z-test in testing hypothesis about the mean parameter.&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkblueexample-1-constructing-confidence-interval-for-mu-with-z-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 1: constructing confidence interval for $\mu$ with $z$-quantiles&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkblueexample-2-constructing-confidence-interval-for-mu-with-t-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 2: constructing confidence interval for $\mu$ with $t$-quantiles&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-1-observations-from-normal-distribution-sigma-known-any-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 1: observations from normal distribution, $\sigma$ known, any $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-2-observations-from-normal-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 2: observations from normal distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-3-observations-from-normal-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 3: observations from normal distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-4-observations-from-any-distribution-sigma-known-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 4: observations from any distribution, $\sigma$ known, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-5-observations-from-any-distribution-sigma-known-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 5: observations from any distribution, $\sigma$ known, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-6-observations-from-any-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 6: observations from any distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#span-stylecolordarkbluecase-7-observations-from-any-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 7: observations from any distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h1 id=&#34;standardized-sample-mean&#34;&gt;Standardized sample mean&lt;/h1&gt;
&lt;p&gt;Consider $X_1, \ldots, X_n$ &amp;ndash; a sequence of i.i.d. random variables with mean $E(X_i) = \mu$ and  variance $\text{var}(X_i) = \sigma^2$. To construct confidence intervals for $\mu$ parameter, we often use a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}},
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;or its version where $S_n$ &amp;ndash; a consistent estimator of true standard deviation $\sigma$ &amp;ndash; is used, $\frac{\overline{X}_n - \mu}{S_n/\sqrt{n}}$; the latter is common in practice as we typically do not know $\sigma$ and must estimate it from the data. Knowing distribution of a standardized sample mean allows us to construct confidence interval for a mean $\mu$ parameter.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkblueexample-1-constructing-confidence-interval-for-mu-with-z-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 1: constructing confidence interval for $\mu$ with $z$-quantiles&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Assume $X_1, \ldots, X_n$ are i.i.d. $\sim N(\mu,\sigma^2)$ and $\sigma$ is known. Then we have an exact distributional result for a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \sim N(0,1).
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Let us denote $z_{ 1-\frac{\alpha}{2}}$ to be $(1-\frac{\alpha}{2})$-th quantile of standard normal distribution $N(0,1)$. Since  $N(0,1)$ is symmetric around $0$, we have $z_{\frac{\alpha}{2}} = -z_{1-\frac{\alpha}{2}}$ and we can write&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
1-\alpha = P\left(-z_{1-\frac{\alpha}{2}} \leq \frac{\overline{X}_n-\mu}{\sigma/\sqrt{n}} \leq z_{1-\frac{\alpha}{2}} \right)
=  P\left(\bar{X}_n-z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n+z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}} \right),
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;which yields that $\left[ \bar{X}_n-z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, ; \bar{X}_n+z_{1-\frac{\alpha}{2}}  \frac{\sigma}{\sqrt{n}}\right]$ is a $(1-\alpha )$-confidence interval for a mean parameter $\mu$.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkblueexample-2-constructing-confidence-interval-for-mu-with-t-quantilesspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Example 2: constructing confidence interval for $\mu$ with $t$-quantiles&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Assume $X_1, \ldots, X_n$ are i.i.d. $\sim N(\mu,\sigma^2)$ and $\sigma$ is &lt;strong&gt;unknown&lt;/strong&gt;. We use $S_n$ &amp;ndash; a consistent sample estimator of true standard deviation &amp;ndash; to approximate $\sigma$, and have an exact distributional result for a standardized sample mean,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{\overline{X}_n - \mu}{S_n/\sqrt{n}} \sim t_{n-1}.
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Let us denote $t_{n-1,1-\frac{\alpha}{2}}$ to be a $(n-1,1-\frac{\alpha}{2})$-th quantile of $t$-distributuon with $n-1$ degrees of freedom. Since $t$ is symmetric around $0$, we have&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
1-\alpha =P\left(-t_{n-1,1-\frac{\alpha}{2}} \leq \frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \leq t_{n-1,1-\frac{\alpha}{2}}\right)
= P\left(\bar{X}_n-t_{n-1, 1-\frac{\alpha}{2}}\frac{S_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n+t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}} \right),
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;which yields that $\left[ \bar{X}_n-t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}}, ; \bar{X}_n+t_{n-1, 1-\frac{\alpha}{2}} \frac{S_n}{\sqrt{n}}\right]$ is a $(1-\alpha )$-confidence interval for a mean parameter $\mu$.&lt;/p&gt;
&lt;h1 id=&#34;cases&#34;&gt;Cases&lt;/h1&gt;
&lt;p&gt;In many cases, whether to use quantiles of $t$-student distribution versus standard normal distribution is based on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distribution of $X_1, \ldots, X_n$ variables,&lt;/li&gt;
&lt;li&gt;whether  $\sigma$ is known or not (and we need to estimate it i.e. with $S_n$),&lt;/li&gt;
&lt;li&gt;what is sample size $n$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: the below cases could be directly translated to answer when to use $t$-test versus $z$-test in testing hypothesis about the mean $\mu$ parameter, i.e. test for $H_0: \mu = \mu_0$ versus $H_1: \mu &amp;lt; \mu_0$, or $H_1: \mu \neq \mu_0$, or $H_1: \mu &amp;gt; \mu_0$.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-1-observations-from-normal-distribution-sigma-known-any-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 1: observations from normal distribution, $\sigma$ known, any $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Any sample size $n$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We have exact result that  $\frac{\bar{X}_{n}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)$ and hence we use quantiles of normal distribution in constructing the CI.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-2-observations-from-normal-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 2: observations from normal distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We use $S_{n}$ to approximate $\sigma$. We have exact result that  $\frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \sim t_{n-1}$ and hence we use quantiles of $t$ distribution with $n-1$ degrees of freedom in constructing the CI.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-3-observations-from-normal-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 3: observations from normal distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from normal $N(\mu, \sigma^2)$ distribution.&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ We use $S_{n}$ to approximate $\sigma$. Because of $n$ large enough, Slutsky&amp;rsquo;s theorem asymptotic ``kicks in&amp;rsquo;&amp;rsquo; and allows to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation, and to write that $\frac{\bar{X}_{n}-\mu}{S_n / \sqrt{n}} \approx \sim N(0,1)$. Because of $n$ large enough, we assume $N(0,1)$ is approximated ($\approx$) well enough to use quantiles of normal distribution in constructing the CI.&lt;/p&gt;
&lt;p&gt;$\Rightarrow$ Another way to think about this case is that, as in Case 2, we have an exact result that $\frac{\bar{X}_{n}-\mu}{S_{n} / \sqrt{n}} \sim t_{n-1}$, and with large $n$, quantiles of $t$-distribution with $n-1$ degrees of freedom are almost equvalent to quantiles of normal distribution.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-4-observations-from-any-distribution-sigma-known-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 4: observations from any distribution, $\sigma$ known, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$ Use CLT to get that standardized sample mean is approximately normal, $\frac{\bar{X}_{n}-\mu}{\sigma / \sqrt{n}} \approx \sim N(0,1)$. Since there is CLT approximation and we have a small sample size, in practice, we typically use quantiles of $t$ distribution with $n-1$ degrees of freedom to get more conservative (wider) CI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: when $X_1, \ldots, X_n$ distribution of is very skewed (i.e. Poisson) it may be not plausible that CLT already ``kicks in&amp;rsquo;&amp;rsquo; and other techniques may be needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-5-observations-from-any-distribution-sigma-known-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 5: observations from any distribution, $\sigma$ known, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ known.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal. We have $\frac{\bar{X}_{n}-\mu}{\sigma/ \sqrt{n}} \approx \sim N(0,1)$. Since we have a moderate to small sample size, we assume that CLT ``kicks in&amp;rsquo;&amp;rsquo; and the approximation ($\approx$) is good enough to use quantiles of normal distribution.&lt;/p&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-6-observations-from-any-distribution-sigma-unknown-small-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 6: observations from any distribution, $\sigma$ unknown, small $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Small sample size ($n \leq 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal  and we also use Slutsky&amp;rsquo;s theorem to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation. We have $\frac{\bar{X}_{n}-\mu}{S_n/ \sqrt{n}} \approx \sim N(0,1)$. Since there is CLT and Slutsky&amp;rsquo;s theorem approximation and we have a small sample size, in practice, we typically use quantiles of $t$ distribution with $n-1$ degrees of freedom to get more conservative (wider) CI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: two approximations are happening here!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: when $X_1, \ldots, X_n$ distribution of is very skewed (i.e. Poisson) it may be not plausible that CLT already ``kicks in&amp;rsquo;&amp;rsquo; and other techniques may be needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;span-stylecolordarkbluecase-7-observations-from-any-distribution-sigma-unknown-large-nspan&#34;&gt;&lt;span style=&#34;color:darkblue&#34;&gt;Case 7: observations from any distribution, $\sigma$ unknown, large $n$&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observations $X_1, \ldots, X_n$ are from (other than normal) distribution  of mean $E(X_i) = \mu$ and variance $\text{var}(X_i) = \sigma^2$ (&lt;em&gt;for normally distributed $X_i$&amp;rsquo;s, see cases 1-3&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;$\sigma$ unknown.&lt;/li&gt;
&lt;li&gt;Moderate to large sample size ($n &amp;gt; 50$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\Rightarrow$   Use CLT to get that standardized sample mean is approximately normal  and we also use Slutsky&amp;rsquo;s theorem to replace $\sigma$ with $S_n$ &amp;ndash; a consistent estimator of true population standard deviation. We have $\frac{\bar{X}_{n}-\mu}{S_n/ \sqrt{n}} \approx \sim N(0,1)$. Since we have a moderate to small sample size, we assume that both CLT and Slutsky asymptotics ``kicks in&amp;rsquo;&amp;rsquo; and the approximation ($\approx$) is good enough to use quantiles of normal distribution.&lt;/p&gt;
&lt;h1 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h1&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt;The views, thoughts, and opinions expressed in the text belong solely to the author, and not necessarily to the author’s employer, organization, committee or other group or individual.&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1]: Methods in Biostatistics with R. Ciprian Crainiceanu, Brian Caffo, John Muschelli (2019). Available online at &lt;a href=&#34;https://leanpub.com/biostatmethods&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://leanpub.com/biostatmethods&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>&#39;adeptdata&#39; R package: Raw Accelerometry Data Sets and Their Derivatives</title>
      <link>https://example.com/post/project_adeptdata/</link>
      <pubDate>Mon, 22 Apr 2019 11:54:53 -0400</pubDate>
      <guid>https://example.com/post/project_adeptdata/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;adeptdata&lt;/code&gt; was created to host raw accelerometry data sets and their derivatives. Some of them are used in the corresponding &lt;code&gt;adept&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Package CRAN index is located &lt;a href=&#34;https://cran.r-project.org/web/packages/adeptdata/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Package GitHub repo is located &lt;a href=&#34;https://github.com/martakarass/adeptdata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;Install from CRAN.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;install.packages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;adeptdata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;data-objects&#34;&gt;Data objects&lt;/h1&gt;
&lt;h2 id=&#34;outdoor-continuous-walking-raw-accelerometry-data-acc_walking_iu&#34;&gt;Outdoor continuous walking raw accelerometry data &lt;code&gt;acc_walking_IU&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_walking_IU&lt;/code&gt; is a sample of raw accelerometry data collected during outdoor continuous walking from 32 healthy participants between 23 and 52 years of age. Data were collected at frequency 100 Hz simultaneously with four wearable accelerometers located at left wrist, left hip and both ankles. See &lt;code&gt;?acc_walking_IU&lt;/code&gt; for details.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;adeptdata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dplyr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ggplot2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lubridate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;acc_walking_IU&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time_s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subj_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;acc_walking_IU&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subj_id[1]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;levels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;left_wrist&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;left_hip&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;left_ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;right_ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Left wrist&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Left hip&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Left ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Right ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;melt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id.vars&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;subj_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;loc_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;time_s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;time_s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;facet_wrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ncol&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_bw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Exercise time [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Amplitude [g]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Sensor\naxis&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Raw accelerometry data of walking (100 Hz)&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_adeptdata/plot_acc_walking_IU_hud3f906394e33c42b903908d2e33c2bfb_414450_b07639aebe09aa733dbbad598084ec63.webp 400w,
               /post/project_adeptdata/plot_acc_walking_IU_hud3f906394e33c42b903908d2e33c2bfb_414450_2919f5fd1a3b42e98d174c85555b0fae.webp 760w,
               /post/project_adeptdata/plot_acc_walking_IU_hud3f906394e33c42b903908d2e33c2bfb_414450_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://example.com/post/project_adeptdata/plot_acc_walking_IU_hud3f906394e33c42b903908d2e33c2bfb_414450_b07639aebe09aa733dbbad598084ec63.webp&#34;
               width=&#34;760&#34;
               height=&#34;507&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;outdoor-run-raw-accelerometry-data-acc_running&#34;&gt;Outdoor run raw accelerometry data &lt;code&gt;acc_running&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;acc_running&lt;/code&gt; is a sample raw accelerometry data collected during 25 minutes of an outdoor run. Data were collected at frequency 100 Hz with two ActiGraph GT9X Link sensors located at left hip and left ankle. See &lt;code&gt;?acc_running&lt;/code&gt; for details.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;ymd_hms&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;2018-10-25 18:07:00&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;UTC&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;ymd_hms&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;2018-10-25 18:20:30&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;UTC&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;t3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;ymd_hms&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;2018-10-25 18:22:00&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;UTC&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;acc_running&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.period&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;seconds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.period&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;seconds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.period&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;seconds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;levels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;left_hip&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;left_ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Left hip&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Left ankle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;melt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id.vars&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;date_time&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;loc_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_time_floor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s&#34;&gt;&amp;#34;Minute start: &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;floor_date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;minutes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;facet_grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loc_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_time_floor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scales&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;free_x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_bw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Time [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Acceleration [g]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Sensor\naxis&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Raw accelerometry data (100 Hz)&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_adeptdata/acc_running_hud3f906394e33c42b903908d2e33c2bfb_529880_1c04a24300d0be7d4c2f01cce54cbfb8.webp 400w,
               /post/project_adeptdata/acc_running_hud3f906394e33c42b903908d2e33c2bfb_529880_3358f02a5901534636103a03ee999a6d.webp 760w,
               /post/project_adeptdata/acc_running_hud3f906394e33c42b903908d2e33c2bfb_529880_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://example.com/post/project_adeptdata/acc_running_hud3f906394e33c42b903908d2e33c2bfb_529880_1c04a24300d0be7d4c2f01cce54cbfb8.webp&#34;
               width=&#34;760&#34;
               height=&#34;456&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;walking-stride-accelerometry-data-templates-stride_template&#34;&gt;Walking stride accelerometry data templates &lt;code&gt;stride_template&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;stride_template&lt;/code&gt; is a list containing walking stride pattern templates derived from accelerometry data collected at four body locations: left wrist, left hip, left ankle, and right ankle. See &lt;code&gt;?stride_template&lt;/code&gt; for details.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;length.out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stride_template&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_ankle[[2]][1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;stride_template&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_ankle[[2]][2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;facet_grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;.)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_bw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Time [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector magnitude [g]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Walking stride templates (left ankle)&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;stride_template.jpeg&#34; width=&#34;50%&#34;&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://example.com/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#39;runstats&#39; R package: Fast Computation of Running Statistics for Time Series</title>
      <link>https://example.com/post/project_runstats/</link>
      <pubDate>Fri, 15 Mar 2019 11:54:53 -0400</pubDate>
      <guid>https://example.com/post/project_runstats/</guid>
      <description>&lt;p&gt;Package &lt;code&gt;runstats&lt;/code&gt; provides methods for fast computation of running sample statistics for time series. The methods utilize Convolution Theorem to compute convolutions via Fast Fourier Transform (FFT). Implemented running statistics include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mean,&lt;/li&gt;
&lt;li&gt;standard deviation,&lt;/li&gt;
&lt;li&gt;variance,&lt;/li&gt;
&lt;li&gt;covariance,&lt;/li&gt;
&lt;li&gt;correlation,&lt;/li&gt;
&lt;li&gt;euclidean distance.&lt;/li&gt;
&lt;/ol&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session info&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h1 id=&#34;website&#34;&gt;Website&lt;/h1&gt;
&lt;p&gt;Package website is located &lt;a href=&#34;https://martakarass.github.io/runstats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;install.packages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;runstats&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;runstats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Example: running correlation&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;pi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;length.out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x0[1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;RunningCor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;RunningCor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;circular&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Example: running mean&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cumsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;RunningMean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;W&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;RunningMean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;W&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;circular&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;running-statistics&#34;&gt;Running statistics&lt;/h1&gt;
&lt;p&gt;To better explain the details of running statistics, package&amp;rsquo;s function &lt;code&gt;runstats.demo(func.name)&lt;/code&gt; allows to visualize how the output of each running statistics method is generated. To run the demo, use &lt;code&gt;func.name&lt;/code&gt; being one of the methods&amp;rsquo; names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningMean&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningSd&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningVar&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCov&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningCor&amp;quot;&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;RunningL2Norm&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Example: demo for running correlation method  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;runstats.demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;RunningCor&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://example.com/post/project_runstats/gif_1.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Example: demo for running mean method &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;runstats.demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;RunningMean&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://example.com/post/project_runstats/gif_2.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;performance&#34;&gt;Performance&lt;/h1&gt;
&lt;p&gt;We use &lt;code&gt;rbenchmark&lt;/code&gt; to measure elapsed time of &lt;code&gt;RunningCov&lt;/code&gt; execution, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter pattern &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rbenchmark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ggplot2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;set.seed &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20190315&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x.N.seq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x.list&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.N.seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Benchmark execution time of RunningCov &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x.list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s&#34;&gt;&amp;#34;runstats&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;runstats&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;RunningCov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;replications&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;replications&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;elapsed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s&#34;&gt;&amp;#34;relative&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;user.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;sys.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pattern_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;knitr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;kable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;test&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;replications&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;elapsed&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;relative&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;user.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;sys.self&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;x_length&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;pattern_length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.003&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.023&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.019&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.004&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.183&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.148&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.035&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.700&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.592&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;0.107&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;runstats&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;19.852&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;17.185&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2.576&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;10000000&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-a-conventional-method&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with a conventional method&lt;/h2&gt;
&lt;p&gt;To compare &lt;code&gt;runstats&lt;/code&gt; performance with &amp;ldquo;conventional&amp;rdquo; loop-based way of computing running covariance in &lt;code&gt;R&lt;/code&gt;, we use &lt;code&gt;rbenchmark&lt;/code&gt; package to measure elapsed time of &lt;code&gt;runstats::RunningCov&lt;/code&gt; and running covariance implemented with &lt;code&gt;sapply&lt;/code&gt; loop, for different lengths of time-series &lt;code&gt;x&lt;/code&gt; and fixed length of the shorter time-series &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Conventional approach &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RunningCov.sapply&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;l_x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;l_y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;sapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l_x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l_y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;cov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x[i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l_y&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;-1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x.list&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;[c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s&#34;&gt;&amp;#34;conventional&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;RunningCov.sapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s&#34;&gt;&amp;#34;runstats&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;runstats&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;RunningCov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;replications&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;replications&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;elapsed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s&#34;&gt;&amp;#34;relative&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;user.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;sys.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;elapsed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;geom_point&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;scale_x_log10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_minimal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Elapsed [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Method&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Running covariance (x,y) rbenchmark&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;subtitle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of y = 100&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;legend.position&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;bottom&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;plt1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_y_log10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Log of elapsed [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cowplot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;plot_grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plt1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nrow&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;B&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_runstats/benchmark_compare_conventional_plot_results-1_hu8c5045f93dd11c0a8751a52ffd8ded0c_149637_8a062b5ae3fc174100cec843201d84f1.webp 400w,
               /post/project_runstats/benchmark_compare_conventional_plot_results-1_hu8c5045f93dd11c0a8751a52ffd8ded0c_149637_e57aea4b9ddb648493cb8658812031e7.webp 760w,
               /post/project_runstats/benchmark_compare_conventional_plot_results-1_hu8c5045f93dd11c0a8751a52ffd8ded0c_149637_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/project_runstats/benchmark_compare_conventional_plot_results-1_hu8c5045f93dd11c0a8751a52ffd8ded0c_149637_8a062b5ae3fc174100cec843201d84f1.webp&#34;
               width=&#34;760&#34;
               height=&#34;380&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;compare-runningcov-runstats-with-sliding_cov-dvmisc-c-implementation&#34;&gt;Compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; with &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt; c++ implementation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dvmisc&lt;/code&gt; package (&lt;a href=&#34;https://github.com/vandomed/dvmisc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/dvmisc/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;) is a package for &lt;em&gt;Convenience Functions, Moving Window Statistics, and Graphics&lt;/em&gt;, and includes functions for calculating moving-window statistics efficiently via c++, written by &lt;a href=&#34;https://vandomed.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dane Van Domelen&lt;/a&gt;. Here, we compare &lt;code&gt;RunningCov {runstats}&lt;/code&gt; performance with c++ implementation from &lt;code&gt;sliding_cov {dvmisc}&lt;/code&gt;. Dane contributed the code in its large part.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# devtools::install_github(&amp;#34;vandomed/dvmisc&amp;#34;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dvmisc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;set.seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20100315&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x.N.seq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x.list&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.N.seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;get.out.df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x.list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kr&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;replications&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;elapsed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relative&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;user.self&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sys.self&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;runstats&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;runstats&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;RunningCov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;dvmisc&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dvmisc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;sliding_cov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;replications&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;replications&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;elapsed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;s&#34;&gt;&amp;#34;relative&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;user.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;sys.self&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out.df.tmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df_y10&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;^1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df_y100&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;^2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df_y1000&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;^3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;out.df_y10000&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.out.df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;runif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;^4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Benchmark results&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;get.plt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subtitle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;elapsed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;geom_point&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;scale_x_log10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;theme_minimal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;  &lt;span class=&#34;nf&#34;&gt;scale_y_log10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Log of elapsed [s]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Method&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;subtitle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subtitle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;legend.position&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;bottom&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.plt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df_y10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of y = 10&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;labs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Running covariance (x,y) rbenchmark&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.plt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df_y100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;   &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of y = 100&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.plt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df_y1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of y = 1,000&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get.plt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out.df_y10000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Vector length of y = 1,0000&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cowplot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;plot_grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plt1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nrow&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;B&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;D&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_runstats/benchmark_compare_dvmisc_plot_results-1_hu80f7659a715482dadfefccc529e863f6_287003_8313f18a73570e34986e15f0a8406573.webp 400w,
               /post/project_runstats/benchmark_compare_dvmisc_plot_results-1_hu80f7659a715482dadfefccc529e863f6_287003_2f786c7aa2a89c98b5e20099ad5f62ce.webp 760w,
               /post/project_runstats/benchmark_compare_dvmisc_plot_results-1_hu80f7659a715482dadfefccc529e863f6_287003_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/project_runstats/benchmark_compare_dvmisc_plot_results-1_hu80f7659a715482dadfefccc529e863f6_287003_8313f18a73570e34986e15f0a8406573.webp&#34;
               width=&#34;760&#34;
               height=&#34;608&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;session-info&#34;&gt;Session info&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sessioninfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;session_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;## ─ Session info ───────────────────────────────────────────────────────────────&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  setting  value                       &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  version  R version 3.5.2 (2018-12-20)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  os       macOS Mojave 10.14.2        &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  system   x86_64, darwin15.6.0        &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  ui       X11                         &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  language (EN)                        &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  collate  en_US.UTF-8                 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  ctype    en_US.UTF-8                 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  tz       America/New_York            &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  date     2019-11-14                  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;## &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;## ─ Packages ───────────────────────────────────────────────────────────────────&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  package     * version date       lib source        &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  assertthat    0.2.1   2019-03-21 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  cli           1.1.0   2019-03-19 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  colorspace    1.4-1   2019-03-18 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  crayon        1.3.4   2017-09-16 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  digest        0.6.22  2019-10-21 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  dplyr         0.8.3   2019-07-04 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  evaluate      0.14    2019-05-28 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  fftwtools     0.9-8   2017-03-25 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  ggplot2     * 3.2.1   2019-08-10 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  glue          1.3.1   2019-03-12 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  gtable        0.3.0   2019-03-25 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  htmltools     0.3.6   2017-04-28 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  knitr         1.26    2019-11-12 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  lazyeval      0.2.2   2019-03-15 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  magrittr      1.5     2014-11-22 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  munsell       0.5.0   2018-06-12 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  pillar        1.4.2   2019-06-29 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  purrr         0.3.3   2019-10-18 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  R6            2.4.1   2019-11-12 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  rbenchmark  * 1.0.0   2012-08-30 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  Rcpp          1.0.3   2019-11-08 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  rlang         0.4.1   2019-10-24 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  rmarkdown     1.15    2019-08-21 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  rstudioapi    0.10    2019-03-19 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  runstats    * 1.1.0   2019-11-14 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  scales        1.0.0   2018-08-09 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  sessioninfo   1.1.1   2018-11-05 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  stringi       1.4.3   2019-03-12 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  stringr       1.4.0   2019-02-10 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  tibble        2.1.3   2019-06-06 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  tidyselect    0.2.5   2018-10-11 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  withr         2.1.2   2018-03-15 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  xfun          0.11    2019-11-12 [1] CRAN (R 3.5.2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;##  yaml          2.2.0   2018-07-25 [1] CRAN (R 3.5.0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;## &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;## [1] /Library/Frameworks/R.framework/Versions/3.5/Resources/library&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://example.com/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-hugo-blox-builder&#34;&gt;Create slides in Markdown with Hugo Blox Builder&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; | &lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some of the topics seen at RStudio conference 2019</title>
      <link>https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/</link>
      <pubDate>Sat, 26 Jan 2019 19:17:23 -0400</pubDate>
      <guid>https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/</guid>
      <description>&lt;p&gt;I spent the last days of 2018-19 winter break in Austin, TX where I traveled for RStudio 2019 conference. I attended e-poster session and two days of the conference: Jan 17-18. Below I list some of the topics from the talks that I particularly liked and I think I am likely to benefit from in the future.&lt;/p&gt;
&lt;p&gt;Also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The official repo with abstracts for every session, workshop (together with &lt;strong&gt;workshop files free to download&lt;/strong&gt; for most if not all of them), and e-poster can be accessed &lt;a href=&#34;https://github.com/rstudio/rstudio-conf/tree/master/2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;&lt;/nav&gt;
&lt;/details&gt;
&lt;h1 id=&#34;data-visualization&#34;&gt;Data visualization&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tyler Morgan-Wall (&lt;a href=&#34;http://www.tylermw.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/tylermorganwall&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) showing stunning gifs and pics while presenting &amp;ldquo;&lt;em&gt;3D mapping, plotting, and printing with rayshader&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Features showed include shadowing, rotating, water transparency, visualization of a simulation of different water levels. The talk had possibly the most exciting &amp;ldquo;future work&amp;rdquo; announced - because who doesn&amp;rsquo;t get excited about the idea of &amp;ldquo;rotating 3D ggplots&amp;rdquo;? &amp;#x1f498; The &lt;code&gt;rayshader&lt;/code&gt; package is available on GitHub (&lt;a href=&#34;https://github.com/tylermorganwall/rayshader&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;).&lt;/p&gt;
  &lt;table style=&#34;table-layout:fixed&#34;&gt;
  &lt;col style=&#34;width:100%&#34; span=&#34;2&#34; /&gt;
  &lt;tr&gt;
  &lt;td&gt; &lt;img src=&#34;tyler.gif&#34; alt=&#34;Drawing&#34; style=&#34;width: 100%;&#34;/&gt; &lt;/td&gt;
  &lt;td&gt; &lt;img src=&#34;tyler2.png&#34;  alt=&#34;Drawing&#34; style=&#34;weight: 100%;&#34;/&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;/table&gt;
&lt;p&gt;&lt;sub&gt;&lt;sup&gt;(The gif on the left and the image on the right are both sourced from &amp;lsquo;rayshader&amp;rsquo; package GitHub website (&lt;a href=&#34;https://github.com/tylermorganwall/rayshader&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), as accessed on Jan 26, 2019.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Thomas Lin Pedersen (&lt;a href=&#34;https://www.data-imaginist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/thomasp85&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) giving a &amp;ldquo;&lt;em&gt;gganimate live cookbook&lt;/em&gt;&amp;rdquo; speech (and joining Tyler&amp;rsquo;s talk on the podium of most fun presentations, I guess &amp;#x1f602;)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;gganimate&lt;/code&gt; package was introduced per &amp;ldquo;&lt;em&gt;extension to ggplot2&lt;/em&gt;&amp;rdquo; providing &amp;ldquo;&lt;em&gt;implementation of the grammar of animated graphics&lt;/em&gt;&amp;rdquo;. Presentation slides are available online  &lt;a href=&#34;https://www.data-imaginist.com/slides/rstudioconf2019/assets/player/keynotedhtmlplayer#1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;; IMHO worth checking out for inspiring ways of presenting data over time! Besides, &lt;a href=&#34;https://gganimate.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gganimate.com&lt;/a&gt; comes with a bunch of examples, like the one below.&lt;/p&gt;
  &lt;table style=&#34;table-layout:fixed&#34;&gt;
  &lt;col style=&#34;width:100%&#34;  /&gt;
  &lt;tr&gt; 
   &lt;img src=&#34;thomas.gif&#34;  alt=&#34;Drawing&#34; style=&#34;weight: 100%;&#34;/&gt; 
  &lt;/tr&gt;
  &lt;/table&gt;
&lt;p&gt;&lt;sub&gt;&lt;sup&gt;(The gif sourced from &amp;lsquo;gganimate&amp;rsquo; package website (&lt;a href=&#34;https://gganimate.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), as accessed on Jan 26, 2019.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;documents-building&#34;&gt;Documents building&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Yihui Xie (&lt;a href=&#34;https://yihui.name/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/xieyihui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) leaving the audience very enthusiastic (or maybe more like: blown away) with all the recent development in document building.&lt;/p&gt;
&lt;p&gt;The presentation starts with &amp;ldquo;In HTML and the Web I trust&amp;rdquo; (&amp;#x1f60d; I share like 99% of my work summaries with advisors and colleagues in a form HTML). With &lt;code&gt;pagedown&lt;/code&gt; we can now go ahead and get &lt;em&gt;&lt;strong&gt;paged&lt;/strong&gt;&lt;/em&gt; HTML documents, e.g. business card, resume, poster. Fairly &amp;#x1f476; development (&amp;quot;&lt;em&gt;status: experimental&lt;/em&gt;&amp;quot;).
Presentation slides are available &lt;a href=&#34;https://slides.yihui.name/2019-rstudio-conf-pagedown.html#1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2019-01-26-favs-of-rstudio2019-conference/yihui_hu03973834ffb71701b043130dcda620e9_2396951_cc608ef98652305a7c2b945129733d5a.webp 400w,
               /post/2019-01-26-favs-of-rstudio2019-conference/yihui_hu03973834ffb71701b043130dcda620e9_2396951_0df30460e40737a2e9e87b5a009bd93a.webp 760w,
               /post/2019-01-26-favs-of-rstudio2019-conference/yihui_hu03973834ffb71701b043130dcda620e9_2396951_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/yihui_hu03973834ffb71701b043130dcda620e9_2396951_cc608ef98652305a7c2b945129733d5a.webp&#34;
               width=&#34;760&#34;
               height=&#34;552&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;sub&gt;&lt;sup&gt;(Slides 10, 11, 15, 17 from RStudio 2019 conference talk &amp;ldquo;pagedown: Creating Beautiful PDFs with R Markdown + CSS + Your Web Browser&amp;rdquo; by Yihui Xie and Romain Lesur on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich Iannone (&lt;a href=&#34;http://rich-iannone.github.io/DiagrammeR/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/riannone&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) introducing the &lt;code&gt;gt&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;gt&lt;/code&gt; package (&lt;a href=&#34;https://github.com/rstudio/gt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;), one can turn a data table into &amp;ldquo;&lt;em&gt;information-rich, publication-quality&lt;/em&gt;&amp;rdquo; &amp;#x1f3af; table outputs. The table outputs can be in HTML, LaTeX, and RTF. The &amp;ldquo;modular&amp;rdquo; way of building these reminds me of ggplot2 plots construction. Presentation slides are available &lt;a href=&#34;https://github.com/rich-iannone/presentations/tree/master/2019_01-19-rstudio_conf_gt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2019-01-26-favs-of-rstudio2019-conference/rich2_hu33e315257783d8592068b76ca9c54832_237865_7d947189234b85b906b968930c33d18c.webp 400w,
               /post/2019-01-26-favs-of-rstudio2019-conference/rich2_hu33e315257783d8592068b76ca9c54832_237865_1e94212fb1dbd888c9c5eef9687af59c.webp 760w,
               /post/2019-01-26-favs-of-rstudio2019-conference/rich2_hu33e315257783d8592068b76ca9c54832_237865_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/rich2_hu33e315257783d8592068b76ca9c54832_237865_7d947189234b85b906b968930c33d18c.webp&#34;
               width=&#34;760&#34;
               height=&#34;518&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;sub&gt;&lt;sup&gt;(Slide 5. from RStudio 2019 conference talk &amp;ldquo;Introducing the &amp;lsquo;gt&amp;rsquo; package&amp;rdquo; by Rich Iannone on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;community-and-personal-development&#34;&gt;Community and personal development&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;David Robinson (&lt;a href=&#34;http://varianceexplained.org/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/drob&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) delivering a keynote talk &amp;ldquo;The unreasonable effectiveness of public work&amp;rdquo; (&lt;a href=&#34;https://bit.ly/drob-rstudio-2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;IMHO a phenomenal speech: a kind and resonating talk after which one not only wants to stand up and change the world right now &amp;#x1f525; but also maintains the same feeling a week after &amp;#x1f4aa;. Review the slides to: (a) learn Author&amp;rsquo;s points on why it so worth it to spend time on public work, (b) for a pack of actual how-to examples and guidelines on building a public portfolio, (c) for a bunch of interesting points made about a value of work (Author&amp;rsquo;s work, but fairly generalizable IMHO); my favorite is copy-pasted below! I particularly appreciated that all stages of advancement in building online portfolio were addressed, &amp;#x1f476;-steps including!&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2019-01-26-favs-of-rstudio2019-conference/david1_hu5f00ed2e972359acb28247fd03f35312_122675_dd901027802996ef36b01537c8b8b6c6.webp 400w,
               /post/2019-01-26-favs-of-rstudio2019-conference/david1_hu5f00ed2e972359acb28247fd03f35312_122675_1149c4aa3f8c6aea2bbdc7714cb2c279.webp 760w,
               /post/2019-01-26-favs-of-rstudio2019-conference/david1_hu5f00ed2e972359acb28247fd03f35312_122675_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/david1_hu5f00ed2e972359acb28247fd03f35312_122675_dd901027802996ef36b01537c8b8b6c6.webp&#34;
               width=&#34;760&#34;
               height=&#34;511&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;sub&gt;&lt;sup&gt;(Slide 63. from RStudio 2019 conference keynote talk &amp;ldquo;The unreasonable effectiveness of public work&amp;rdquo; by David Robinson on Jan 18, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jesse Mostipak (&lt;a href=&#34;https://www.jessemaegan.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/kierisi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt;) talking about the experience of building R4DS online learning community.&lt;/p&gt;
&lt;p&gt;Some empowering messages came in the lines of this talk - just look at the slides pics below to get the flavor &amp;#x1f64c;. My take-home ones include a description of a data scientist: &amp;ldquo;&lt;em&gt;constantly learning, constantly making mistakes, constantly learning from them&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2019-01-26-favs-of-rstudio2019-conference/jesse_b_hu7016b5e8a85baad5d65205eebd899fa8_2387460_29e1d15ba3a521252e5eb064a6e13c22.webp 400w,
               /post/2019-01-26-favs-of-rstudio2019-conference/jesse_b_hu7016b5e8a85baad5d65205eebd899fa8_2387460_7c9f8eb5b87e3b23ef83f70b6199f58a.webp 760w,
               /post/2019-01-26-favs-of-rstudio2019-conference/jesse_b_hu7016b5e8a85baad5d65205eebd899fa8_2387460_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://example.com/post/2019-01-26-favs-of-rstudio2019-conference/jesse_b_hu7016b5e8a85baad5d65205eebd899fa8_2387460_29e1d15ba3a521252e5eb064a6e13c22.webp&#34;
               width=&#34;760&#34;
               height=&#34;291&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;sub&gt;&lt;sup&gt;(Pictures I took during RStudio 2019 conference talk &amp;ldquo;R4DS online learning community&amp;rdquo; by Jesse Mostipak on Jan 17, 2019 in Austin, TX.)&lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>[in Polish] Aplikacja na studia doktoranckie (Biostatystyka) w USA: notatki nt. procesu rekrutacji</title>
      <link>https://example.com/post/2018-09-02-applying-for-phd-in-usa/</link>
      <pubDate>Sun, 02 Sep 2018 19:17:23 -0400</pubDate>
      <guid>https://example.com/post/2018-09-02-applying-for-phd-in-usa/</guid>
      <description>&lt;p&gt;W 2015 roku zdobylam tytul Magister na kierunku Matematyka na Politechnice Wroclawskiej. W sierpniu 2016 rozpoczelam aplikacje na programy doktoranckie na kierunku Biostatystyka w Stanach Zjednoczonych rozpoczynajace sie jesienia 2017. Dostalam i zaakeptowalam oferte z &lt;a href=&#34;https://www.jhsph.edu/departments/biostatistics/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Departamentu Biostatystyki&lt;/a&gt; na &lt;a href=&#34;https://www.jhsph.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Johns Hopkins Bloomberg School of Public Health&lt;/a&gt; w Baltimore (stan Maryland), oferujacego jeden z 3 najlepszych (ex aequo) programow na kierunku Biostatystyka w USA wg &lt;a href=&#34;https://www.usnews.com/best-graduate-schools/top-science-schools/statistics-rankings&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rankingu usnews.com&lt;/a&gt; z 2018 roku. W notatce opisuje etapy rekrutacji i podaje swoje obserwacje i wskazowki.&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;&lt;/nav&gt;
&lt;/details&gt;
&lt;h1 id=&#34;uwagi-wstepne&#34;&gt;Uwagi wstepne&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w kontekscie aplikacji na kierunek Biostatystyka.&lt;/strong&gt; &lt;em&gt;Spodziewam sie&lt;/em&gt;, ze aplikacje na inne (w szczegolnosci: zblizone tematycznie) programy moga przebiegac &lt;em&gt;podobnie&lt;/em&gt;, jednoczesnie nigdy nie zrobilam porownania. Przykladowa roznica o ktorej wiem, ze istnieje: na programy PhD na kierunku Biostatystyka &lt;em&gt;aplikuje sie ogolnie&lt;/em&gt; na program i po 0-2 latach &lt;em&gt;okresla lub zaweza&lt;/em&gt; obszar badawczy i jednoczesnie decyduje na konkretnych opiekunow naukowych (w tym: promotora/promotorow); typowe dla niektorych innych kierunkow STEM jest z kolei &lt;em&gt;aplikowanie do konkretnego laboratorium (czesto: pod opieke naukowa konkretnego profesora)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w oparciu o tylko i wylacznie moje doswiadczenia&lt;/strong&gt; (za wyjatkiem miejsc, gdzie zaznaczam explicite, ze wiem cos ze slyszenia od innych studentow).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ponizszy opis jest napisany w kontekscie aplikacji na programy rozpoczynajace sie jesienia 2017&lt;/strong&gt;, wypelnianymi zgodnie z wymaganiami i terminami, ktorych pilnowalam aplikujac w 2016. Nie sprawdzilam, czy i co zmienilo sie od tego czasu.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wyodrebniam nastepujace glowne komponenty procesu aplikacji:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wstepny wybor uczelni i zbudowanie planu czasowego procesu aplikacji&lt;/li&gt;
&lt;li&gt;Przygotowanie do egzaminow: GRE + TOEFL&lt;/li&gt;
&lt;li&gt;Przygotowanie Personal Statement&lt;/li&gt;
&lt;li&gt;Zorganizowanie listow rekomendacyjnych&lt;/li&gt;
&lt;li&gt;Networking&lt;/li&gt;
&lt;li&gt;Aplikowanie: wykonanie i nadzorowanie post-procesu&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;1-wstepny-wybor-uczelni-i-zbudowanie-planu-czasowego-timeline-aplikacji&#34;&gt;1. Wstepny wybor uczelni i zbudowanie planu czasowego timeline aplikacji&lt;/h1&gt;
&lt;p&gt;Generalne ramy czasowe.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uczelnie roznia sie datami ostatecznego terminu aplikacji, jednoczesnie daty te  zjezdzaja sie na przestrzeni ok. 1,5 miesiaca: od 1. grudnia roku N do polowy stycznia roku (N+1) na programy rozpoczynajace sie jesienia roku (N+1). 60% terminow to wlasnie 1. grudnia. &amp;#x1f4e3;&lt;/li&gt;
&lt;li&gt;Stad &lt;strong&gt;prace nad aplikacjami zaczynamy &lt;em&gt;najpozniej&lt;/em&gt; 12-14 miesiecy przed&lt;/strong&gt; faktycznym rozpoczeciem studiow.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wstepny wybor uczelni.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wybieralam uczelnie na podstawie: a) rankingow programu Biostatystyka (podzbior &amp;ldquo;Biostatystyka&amp;rdquo;  z &lt;a href=&#34;https://www.usnews.com/best-graduate-schools/top-science-schools/statistics-rankings&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;usnews.com&lt;/a&gt;; w 2016 korzystalam glownie z &lt;a href=&#34;http://www.amstat.org/asa/files/pdfs/OGRP-USNews_BioStatisticsRankings.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tego&lt;/a&gt; dokumentu); b) rozmow z profesorami i studentami w USA w czasie pracy jako Research Assistant na Indiana University w pierwszej polowie 2016; c) przegladania grup naukowych i zainteresowan profesorow na stronach uczelni; d) lokalizacji; tu: zarowno ogolny obszar USA jak i konkretne miasto (przyklad: nie chcialam studiowac w NYC).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bylo mi ciezko ocenic a priori, w jaki sposob moja aplikacja bedzie ewaluowana przez komitety rekrutacyjne na uczelniach w USA.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aplikacja studenta z Polski na Biostatystyke u USA to wciaz egzotyczna sprawa. Komisje rekrutacyjne sa najczesniej niezaznajomione z polskim systemem szkolnictwa wyzszego (gdzie sa np. z chinskimi i hinduskimi), stad ocena &amp;ldquo;5.0&amp;rdquo; z Analizy matematycznej I na Politechnice Wroclawskiej  nie mowi im bardzo duzo na temat tego, co w zwiazku z tym powinnam umiec. (Przyklad: w czasie etapu rekrutacji &amp;ldquo;on site&amp;rdquo; na jednej z uczelni Ivy League, dziekan departamentu Biostatystyki, z ktorym mialam 20-minutowe spotkanie, poprosil mnie o chocby ogolny opis tego &amp;ldquo;jak wygladaly moje studia w Polsce&amp;rdquo; &amp;#x1f47d;).  &lt;br/&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aplikowalam do 16 uczelni&lt;/strong&gt; (relatywnie wielu), &lt;strong&gt;wg nastepujacego schematu&lt;/strong&gt;:  1/3 uczelni na liscie to &amp;ldquo;dream schools&amp;rdquo; - uczelnie z czolowki rankingow programu Biostatystyka; 1/3 to uczelnie &amp;ldquo;safe&amp;rdquo; - spodziewam sie, ze mam spore szanse sie tam dostac; 1/3 to uczelnie &amp;ldquo;po srodku&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dostalam sie / dostalam zaproszenie do 2. etapu rekrutacji od nieco &lt;strong&gt;ponad 50% z uczelni&lt;/strong&gt;, do ktorych aplikowalam (2. etap to zaproszenie na rozmowe &amp;ldquo;on site&amp;rdquo; lub jego odpowiednik dla studentow przebywajacych poza USA: rozmowa telefoniczna z czlonkami komitetu rekrutacyjnego; w kilku przypadkach nie kontynuowalam procesu do 2. etapu wiedzac, ze dostalam sie juz do miejsca wyzej na liscie moich preferencji).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Co interesujace, uczelnie, ktore byly mna zainteresowanie, to niemal dokladnie: polowa uczelni z grupy &amp;ldquo;dream schools&amp;rdquo; + polowa z &amp;ldquo;safe&amp;rdquo; + polowa z &amp;ldquo;po srodku&amp;rdquo; &amp;#x1f44f;&amp;#x1f44d;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Plan czasowy procesu aplikacji powinien zawierac:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Daty &lt;strong&gt;ostatecznego terminu aplikacji&lt;/strong&gt; (&amp;ldquo;deadline&amp;rdquo;) do wybranych uczelni, tzn. daty, po ktorych zamykaja sie systemy online umozliwiajace wykonanie aplikacji.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Liste &lt;strong&gt;wymaganych egzaminow&lt;/strong&gt; i najdalszy termin ich realizacji (np. w Polsce), ktory zapewnia bezpieczne okno czasowe na przeslanie wynikow do uczelni. Najczesciej beda to dwa egzaminy: TOEFL i GRE General.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wyniki TOEFL i GRE General wysylane sa automatycznie do uczelni, ktorych liste zadeklarujemy przy zapisie na egzamin lub ktore dodamy kiedykolwiek pozniej przy uzyciu systemow online do zarzadzania wynikami. Zwyczajnie trzeba przypilnowac, czy dni robocze, ktore organizator daje sobie na a) sprawdzenie egzaminu + b) wyslanie wynikow do uczelni, dodaja nam sie z ostatecznymi terminami aplikacji. &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Okno czasowe na &lt;strong&gt;tlumaczenie przysiegle&lt;/strong&gt; oraz &lt;strong&gt;przeewaluowanie i/lub wyslanie poczta transkryptow ocen&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Przyklady tego, co moze nas &amp;ldquo;zaskoczyc&amp;rdquo;. a) ~5 uczelni wymagalo wyslania tlumaczonych (tl. przysiegly) transkryptow ocen fizycznie na adres uczelni w USA (w kilku przypadkach: w terminie wczesniejszym, niz generalny ostateczny termin aplikacji podany na stronie uczelni). b) ~7 uczelni realizowalo aplikacje przez system &lt;a href=&#34;https://sophas.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOPHAS&lt;/a&gt; - jednolity system aplikacji na wydzialy Zdrowia Publicznego (&amp;ldquo;School of Public Health&amp;rdquo;) w USA, z ktorych korzysta czesc uczelni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SOPHAS jest dla aplikanta wygodny o tyle, ze duza czesc dokumentow ladujemy do systemu tylko raz, niezaleznie od liczby uczelni na ktore aplikujemy via SOPHAS. Z drugiej strony, SOPHAS akceptuje zagraniczne transkrypty ocen tylko i wylacznie po przeewaluowaniu ich na system amerykanski przez World Education Services (&lt;a href=&#34;https://www.wes.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WES&lt;/a&gt;). Musimy wiec wyslac do WES komplet swoich przetlumaczonych (tl. przysiegly &amp;#x1f47c;) transkryptow, a WES je ewaluuje i wysyla wyniki do SOPHAS. (To byl dla mnie najbardziej stresujacy element tego etapu rekrutacji: WES nie zrealizowal ewaluacji moich ocen w oknie czasowym, ktore deklaruje od momentu zmiany statusu mojej sprawy na &amp;ldquo;otrzymalismy twoje transkrypty&amp;rdquo;; pomimo moich prosb, &amp;ldquo;grozb&amp;rdquo; i placzu, dokumenty zostaly wyslane dopiero na kilka dobrych dni po deklarowanym terminie &amp;#x1f422;, szczesliwie dokladnie &amp;ldquo;na styk&amp;rdquo; z ostatecznymi terminami aplikacji do kilku uczelni. &amp;#x1f3a3;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wybor uczelni i organizowanie planu czasowy procesu aplikacji sa ze soba powiazane: specyficzne wymagania i terminy poszczegolnych uczelni wymuszaja plan czasowy, natomiast wymagania czasowe modyfikowaly moje wybory uczelni (przyklad: widzialam, ze nie dam rady czasowo przygotowac sie do egzaminu GRE Mathematics; z drugiej strony, jako ze duza czesc moich dokumentow typowo potrzebnych do aplikacji byla juz w SOPHAS, zaaplikowalam do kilku dodatkowych uczelni via SOPHAS).&lt;/p&gt;
&lt;h1 id=&#34;2-przygotowanie-do-egzaminow-gre-general--toefl&#34;&gt;2. Przygotowanie do egzaminow: GRE General + TOEFL&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GRE General jest niezbedny&lt;/strong&gt; do aplikowania na studia &amp;ldquo;graduate&amp;rdquo; (Masters / PhD) w USA. W nielicznych przypadkach &lt;em&gt;wymagany&lt;/em&gt; jest rowniez GRE specjalistyczny (Stanford: GRE Mathematics Subject Test). &lt;strong&gt;Egzamin jezykowy&lt;/strong&gt; jest wymagany dla absolwentow uczelni, na ktorych jezyk angielski nie jest podstawowym jezykiem wykladowym. W USA wymaganym standardowo egzaminem jezykowym jest TOEFL (w niektorych szkolach zamienny z IELTS, w niektorych nie).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zdawalam GRE General i TOEFL. Oba egzaminy zdawalam w Polsce (najpierw GRE General w Krakowie, tydzien pozniej: TOEFL w Poznaniu).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Przejscie przez przewodnik po typach zadan&lt;/strong&gt; na obu egzaminach &lt;strong&gt;to absolutne minimum&lt;/strong&gt; w przygotowaniach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje przeznaczyc 90-95% czasu przygotowan do obu egzaminow na GRE General.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GRE General sklada sie z ~5 komponentow testujacych dwa obszary: j. angielski i matematyke. Czesc matematyczna jest prosta (poziom matury podstawowej z matematyki), jednoczesnie nalezy zalozyc duzo czasu na przygotowanie sie pod bardzo konkretna forme tego egzaminu. Jest &lt;em&gt;bardzo&lt;/em&gt; malo miejsca na jakiekolwiek pomylki, w szczegolnosci: bledy przy pierwszych zadaniach (poziom trudnosci zadan rosnie z biegiem czasu egzaminu), stad trzeba wyklepac do stanu &amp;ldquo;rozwiazuje z automatu&amp;rdquo; problemy pojawiajace sie na czesci matematycznej. Wlasnosci katow w trojkacie wpisanym i opisanym na okregu &amp;#x1f498;, zadania &amp;ldquo;z dwoma pociagami&amp;rdquo;, te sprawy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GRE General cz. jezykowa sklada sie zadan testujacych umiejetnosc krytycznego myslenia i argumentowania w formie pisemnej oraz z zadan testujacych slownictwo. Czesc testujaca slownictwo jest moim zdaniem zwyczajnie nierobialna i ze swojej perspektywy oceniam, ze nie ma duzej roznicy, czy przeznaczy sie na nauke slowek 10h czy 300h przed egzaminem, tu trzeba isc do kosciola i pomodlic sie o celnosc strzalow w odpowiedziach. Na serio: przygotowanie do GRE General cz. jezykowa jest  czasochlonne. &amp;#x1f610; Pomocne: w internecie sa dostepne roznej dlugosci listy &amp;ldquo;slownictwa na GRE&amp;rdquo; oraz dedykowane aplikacje do nauki &amp;ldquo;slowek na GRE&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Po napisaniu GRE General cz. jezykowa, poziom TOEFL wydaje sie latwy, a sam egzamin - przyjemny &amp;#x1f60c;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje nie zdawac obu egzaminow w jeden weekend; w szczegolnosci GRE jest bardzo wyczerpujacy (mysle, ze to byl najbardziej wyczerpujacy egzamin w moim zyciu; po wyjsciu z sali przez kilka minut zbieralam mysli o tym co to sie robilo zeby zamowic Ubera) &amp;#x1f680;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;3-przygotowanie-personal-statement&#34;&gt;3. Przygotowanie Personal Statement&lt;/h1&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt;Nota bene: transkrypty ocen i wyniki z egzaminow sluza glownie do wyznaczenia punktu odciecia, ponizej ktorego &amp;ldquo;uczelnia generalnie nie rozmawia z potencjalnym studentem&amp;rdquo;.&lt;/span&gt; Latwo wyobrazic sobie, ze punkt odciecia przekracza wielu bardzo dobrych studentow (podpowiadam przypomniec sobie populacje np. Chin i Indii). &lt;span style=&#34;color:red&#34;&gt;To, czym &amp;ldquo;kupujemy&amp;rdquo; sobie przychylnosc komisji rekrutacyjnej i zdobywamy oferte programu, to &lt;strong&gt;kombinacja zawartosci CV, Personal Statement, listow rekomendacyjnych i naszego networkingu&lt;/strong&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Personal Statement (zamiennie: Statement of Purpose) to wazny dokument, ktorego szablon - wersje beta tworzylam przez kilka dni z rzedu.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Szablon mojego Personal Statement mial 2 pelne strony A4 i skladal sie z  nastepujacych paragrafow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;chwytliwe otwarcie, w ktorym wzbudzam zainteresowanie swoja motywacja i indywidualna historia,&lt;/li&gt;
&lt;li&gt;notka biograficzna, skupiajaca sie na doswiadczeniu w badaniach naukowych (poparte konkretnymi przykladami),&lt;/li&gt;
&lt;li&gt;notka biograficzna, skupiajaca sie na cechach osobowosciowych, ktore predestynuja mnie do bycia odnoszacym sukcesy studentem (poparte konkretnymi przykladami),&lt;/li&gt;
&lt;li&gt;motywacja do studiowania kierunku Biostatystyka,&lt;/li&gt;
&lt;li&gt;&amp;ldquo;big-picture&amp;rdquo; tego, co chce osiagnac dzieki studiom PhD - na przestrzeni studiow i calego zycia,&lt;/li&gt;
&lt;li&gt;motywacja do studiowania kierunku Biostatystyka na tej konkretnej uczelni,&lt;/li&gt;
&lt;li&gt;zgrabne zakonczenie.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sugestie:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;W Personal Statement nie ma miejsca na &amp;ldquo;chcialem byc marynarzem chcialem miec tatuaze podrozowac&amp;rdquo;. Wszystko, co tam wrzucamy tytulem osiagniec i aktywnosci, powinno byc poparte/umotywowane konkretnymi wydarzeniami z zycia akademickiego/poza-akademickiego.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;W Personal Statement nie ma miejsca na bycie skromnym. Inni aplikanci nie beda skromni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Warto zgooglowac, jakie elementy &lt;em&gt;powinny zawsze&lt;/em&gt; znalezc sie w tym dokumencie - czesto uczelnie zamieszczaja te infromacje na swoich podstronach dot. rekrutacji. Jednoczesnie sugeruje NIE szukac i NIE &amp;ldquo;inspirowac sie&amp;rdquo; gotowymi dokumentami instniejacymi w sieci; im bardziej &amp;ldquo;twoj&amp;rdquo; jest Personal Statement, tym lepiej.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sugeruje szablon &lt;strong&gt;dac do sprawdzenia 3-5 znajomym&lt;/strong&gt; &amp;#x1f64f; pod katem tresci; wyszlifowana tresciowo wersje sugeruje dac do sprawdzenia pod wzgledem jezykowym dobremu tlumaczowi. Do sprawdzenia (i do tlumaczenia transkryptow) polecam Panie z &lt;a href=&#34;http://www.btcentrum.pl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BT Centrum we Wroclawiu&lt;/a&gt; - absolutnie profesjonale i elastyczne, de facto &amp;ldquo;uratowaly&amp;rdquo; moje aplikacje (a mogly wysmiac mnie w progu za termin, w ktorym potrzebowalam miec gotowe tlumaczenia: &amp;ldquo;na jutro&amp;rdquo; &amp;#x1f429;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;4-listy-rekomendacyjne&#34;&gt;4. Listy rekomendacyjne&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Potrzebowalam &lt;strong&gt;3 listy rekomendacyjne&lt;/strong&gt;. Szczegolny przypadek: SOPHAS (wspomniany wyzej) &lt;em&gt;bardzo mocno&lt;/em&gt; sugerowal zadbanie o co najmniej jeden list pochodzacy od osoby spoza akademickiego srodowiska; w tym przypadku zalaczylam 4 listy rekomendacyjne.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Uwagi:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;W dobrym guscie jest zwrocenie sie z prosba o &lt;em&gt;rozwazenie mozliwosci wystosowania takiego listu&lt;/em&gt; na min. 1 miesiac przed data, na kiedy list ma byc gotowy. Warto w takim pierwszym mejlu zaznaczyc wyraznie, na kiedy list bedziemy potrzebowac.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Listy rekomendacyjne pisane przez profesorow w USA sa zawsze pelne &amp;ldquo;ochow&amp;rdquo; i &amp;ldquo;achow&amp;rdquo;. Choc ciezko mi wyobrazic sobie poproszenie explicite o &amp;ldquo;pelen pochwal list&amp;rdquo;, warto sprobowac zaznaczyc, ze np. ze wzgledu na wysoka konkurencyjnosc uczelni, potrzebujemy &amp;ldquo;silnego&amp;rdquo; listu rekomendacyjnego. (Z tego co rozumiem, wylistowanie aktywnosci aplikanta i jednozdaniowe wyrazenie przekonania, ze to dobry kandydat, to - generalnie rzecz biarac - tresc na slaby list.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;5-networking&#34;&gt;5. Networking&lt;/h1&gt;
&lt;p&gt;Ciezko mi podkreslic wystarczajaco mocno, jak &lt;strong&gt;istotnym elementem aplikacji jest networking&lt;/strong&gt;, tzn. nawiazanie kontaktu z profesorami na wybranych przez nas uczelniach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Faktycznie, &lt;em&gt;dostalam&lt;/em&gt; sie na niektore uczelnie (ze swoich kategorii &amp;ldquo;safe&amp;rdquo; i &amp;ldquo;po srodku&amp;rdquo;), z ktorymi nie nawiazalam wczesniej zadnego bezposredniego kontaktu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Twierdze, ze bardzo trudne byloby dostanie sie do &amp;ldquo;dream school&amp;rdquo; bez nawiazania wczesniej bezposredniego kontaktu. Tu, aplikacja bardzo potrzebuje &amp;ldquo;wsparcia od srodka&amp;rdquo; departamentu, do ktorego chcemy sie dostac.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Przyklady tego, &lt;strong&gt;jak mozna budowac potrzebny networking&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wyjechanie do USA na kilka miesiecy do tymczasowej pracy / na staz na wybrana uczelnie.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pierwszym krokiem do zaproszenia na taki wyjazd moze byc krotki mejl do wybranego profesora, mowiacy: &amp;ldquo;Czesc, jestem bardzo zainteresowany twoja praca o X, sam od dawna czytam i pracuje nad rzeczami zwiazanymi z Y, czy znalazlbys 10 minut na rozmowe na Skajpie? Dostosuje sie do terminu, ktory zaproponujesz.&amp;rdquo;  &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wyjechanie do USA na konferencje / szkole wakacyjna / warsztaty, gdzie beda profesorowie z interesujacej nas uczelni.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nawiazanie kontaktu telefonicznego / mejlowego z profesorami z interesujacej nas uczelni. (Por. wskazowka w podpunkcie wyzej).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;6-aplikowanie&#34;&gt;6. Aplikowanie&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wypelnianie aplikacji jest czasochlonne&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nalezy wziac margines na specjalne przypadki nawet w ramach wykonywania aplikacji w formularzu online. Przyklady: a) z ostatniej strony formularza aplikacyjnego: nie przechodzi platnosc polska karta platnicza; b) z ktorejkolwiek / wielu stron formularza aplikacyjnego: nie jest jasne, co oznacza to pole - musze wyslac mejla z pytaniem do dzialu rekrutacji tej uczelni &amp;#x1f60e;.  &lt;br/&gt;  &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aplikacje sa drogie&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Niektore koszty sa jednorazowe i prawie niezalezne od liczby aplikacji (wyjazd na egzamin TOEFL / GRE). Aplikacja do kazdej kolejnej szkoly generuje  koszt (bezzwrotna oplata aplikacyjna: 30-130 USD, przeslanie wyniku GRE: 20 USD, przeslanie wyniku TOEFL: 20 USD).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mysle, ze calkowity koszt moich aplikacji (w tym: tlumacz przysiegly, dojazdy i noclegi na egzaminy w innych miastach Polski, wyslanie paczek UPS z dokumentami do kilku szkol w USA) to lacznie 7.000-10.000 PLN &amp;#x2614;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://example.com/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://example.com/privacy/</guid>
      <description>&lt;p&gt;Add your privacy policy here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://example.com/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://example.com/terms/</guid>
      <description>&lt;p&gt;Add your terms here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brain connectivity-informed regularization methods for regression</title>
      <link>https://example.com/post/project_mdpeer/</link>
      <pubDate>Wed, 06 Dec 2017 11:54:53 -0400</pubDate>
      <guid>https://example.com/post/project_mdpeer/</guid>
      <description>&lt;p&gt;We propose to estimate association between the brain structure features and a scalar outcome in a regression model while utilizing additional information about structural connectivity between the brain regions.&lt;/p&gt;
&lt;p&gt;Specifically, we propose a novel regularization method &amp;ndash; riPEER (ridgified Partially Empirical Eigenvectors for Regression) &amp;ndash; that defines a regularization penalty term based on the structural connectivity-derived Laplacian matrix.&lt;/p&gt;
&lt;!---
&lt;span style=&#34;color:purple&#34;&gt;**See images citation and/or credit information** [below](#custom)&lt;/span&gt;.
--&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#scientific-problem&#34;&gt;Scientific problem&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#challenges&#34;&gt;Challenges&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proposed-solution&#34;&gt;Proposed solution&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#published-work&#34;&gt;Published work&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
&lt;h3 id=&#34;scientific-problem&#34;&gt;Scientific problem&lt;/h3&gt;
&lt;p&gt;The motivation for the work was to quantify the association between alcohol abuse phenotypes (outcome) and cortical thickness of the brain (covariates) in a study sample of young social-to-heavy drinking males. The data included measurements of average cortical thickness estimated for 68 brain regions.&lt;/p&gt;
&lt;p&gt;This image (see images credit &lt;a href=&#34;#custom&#34;&gt;below&lt;/a&gt;) visualizes process of obtaining cortical thickness measurements from structural MRI images.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_mdpeer/MRI_sequence_hud94671994637836497631a710e744dcb_160345_190cb1bb00563730165979831b93646a.webp 400w,
               /post/project_mdpeer/MRI_sequence_hud94671994637836497631a710e744dcb_160345_5de9217bf34c51eda89f73b20a1581c4.webp 760w,
               /post/project_mdpeer/MRI_sequence_hud94671994637836497631a710e744dcb_160345_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/project_mdpeer/MRI_sequence_hud94671994637836497631a710e744dcb_160345_190cb1bb00563730165979831b93646a.webp&#34;
               width=&#34;699&#34;
               height=&#34;400&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;p&gt;Commonly shared issues in such settings are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;high dimensionality of the data - we typically parcel the brain into tens, or hundreds of units from which we take measurements, and each unit may then correspond to a covariate in the data set,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;correlation of the covariates - measurements from spatially neighbouring or otherwise connected brain regions are likely to be correlated,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;small sample size - brain imaging studies often recruit a few tens of participants only.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;Proposed solution&lt;/h3&gt;
&lt;p&gt;We propose penalized regression method riPEER to estimate a linear model: $$y =  Zb + X\beta + \varepsilon$$ where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y$ - response (&lt;em&gt;here: alcohol abuse phenotypes&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$Z$ - input data matrix (&lt;em&gt;here: cortical thickness measurements&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$X$ - input data matrix (&lt;em&gt;here: demographics data&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\beta$ - regression coefficients, not penalized in estimation process&lt;/li&gt;
&lt;li&gt;$b$ - regression coefficients, penalized in estimation process and for whom there is a prior graph of similarity / graph of connections. available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The riPEER estimation method uses a penalty being a linear combination of a graph-based and ridge penalty terms:
$$
\hat{\beta}, \hat{b}
= \underset{\beta,b}{\text{arg min}} \left[ (y - X\beta - Zb)^T(y - X\beta - Zb)  + \lambda_Qb^TQb +  \lambda_Rb^Tb  \right ]
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Q$ - a graph-originated penalty matrix; typically: a graph Laplacian matrix (&lt;em&gt;here: a graph Laplacian derived from structural connectivity of brain regions&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;$\lambda_Q$ - regularization parameter for a graph-based penalty term,&lt;/li&gt;
&lt;li&gt;$\lambda_R$ - regularization parameter for ridge penalty term.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/project_mdpeer/featured_hu4c8e0795ed81281ef6542e1e535a8949_306484_b5161e80ed6d48e44adb3ef8f3726180.webp 400w,
               /post/project_mdpeer/featured_hu4c8e0795ed81281ef6542e1e535a8949_306484_cd69ab8ea4a45b62a1c57edae538231e.webp 760w,
               /post/project_mdpeer/featured_hu4c8e0795ed81281ef6542e1e535a8949_306484_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/project_mdpeer/featured_hu4c8e0795ed81281ef6542e1e535a8949_306484_b5161e80ed6d48e44adb3ef8f3726180.webp&#34;
               width=&#34;760&#34;
               height=&#34;421&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h5 id=&#34;ripeer-penalty-term&#34;&gt;riPEER penalty term&lt;/h5&gt;
&lt;p&gt;In the riPEER penalty term  $(\lambda_Qb^TQb +  \lambda_Rb^Tb)$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A graph-originated penalty matrix $Q$ allows imposing similarity between coefficients of variables which are &lt;em&gt;connected&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A ridge penalty term, $\lambda_Rb^Tb$, allows for L2 regularization component; in addition, even with very small $\lambda_R$, eliminates computational issues arising from singularity of $Q$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regularization parameters $\lambda_R$, $\lambda_Q$ are estimated automatically as ML estimators of equivalent Linear Mixed Models optimization problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;published-work&#34;&gt;Published work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We published the proposed riPEER method in work &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6583926/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brain connectivity-informed regularization methods for regression&lt;/a&gt; (Karas, M., Brzyski, D., Dzemidzic, M., Goni, J., Kareken, D.A., Randolph, T., Harezlak J. (2017)).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We published the riPEER extension to generalized linear regression, addressing both theoretical and computational issues, in work &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/cjs.11606&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connectivity‐informed adaptive regularization for generalized outcomes&lt;/a&gt; (Brzyski, D., Karas, M., Ances, B.M., Dzemidzic, M., Goni, J., Randolph, T., Harezlak J. (2021)).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software&#34;&gt;Software&lt;/h3&gt;
&lt;p&gt;We provided open-source implementation of the proposed riPEER estimation method in R package mdpeer (&lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN index&lt;/a&gt;). The package provides functions for graph-constrained regression methods in which regularization parameters are selected automatically via estimation of equivalent Linear Mixed Model formulation.&lt;/p&gt;
&lt;p&gt;The R package is accompanied by &lt;a href=&#34;https://cran.r-project.org/web/packages/mdpeer/vignettes/Intro_and_usage_examples.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intro and usage examples&lt;/a&gt; vignette.&lt;/p&gt;
&lt;h3 id=&#34;custom&#34;&gt;&lt;span style=&#34;color:purple&#34;&gt;&lt;strong&gt;Images used in the post &amp;ndash; credit/references&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top left component. Cortical thickness. Resources of Neurorecovery Laboratory at MGH/MIT/HMS Athinoula A. Martinos Center for Biomedical Imaging. Accessed at: &lt;a href=&#34;https://www.nmr.mgh.harvard.edu/neurorecovery/technology.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top middle component. Diffusion MRI Tractography in the brain white matter. Xavier Gigandet et. al. - Gigandet X, Hagmann P, Kurant M, Cammoun L, Meuli R, et al. (2008) Estimating the Confidence Level of White Matter Connections Obtained with MRI Tractography. PLoS ONE 3(12): e4006. doi:10.1371/journal.pone.0004006. Accessed at: &lt;a href=&#34;https://en.wikipedia.org/wiki/Connectome#/media/File:White_Matter_Connections_Obtained_with_MRI_Tractography.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Featured image - top right component. Databases of Statistical Information. Resources of Berkeley Advanced Media Institute
Graduate School of Journalism. Accessed at: &lt;a href=&#34;https://multimedia.journalism.berkeley.edu/tutorials/databases-of-statistical-information/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
(last accessed on Nov 20, 2020).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://example.com/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://example.com/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://example.com/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://example.com/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
